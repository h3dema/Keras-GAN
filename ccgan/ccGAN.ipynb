{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context-Conditional GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
    "from keras.layers import Input, Dense, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(layer_input, filters, f_size=4, bn=True):\n",
    "    \"\"\"Layers used during downsampling\"\"\"\n",
    "    d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(layer_input)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    if bn:\n",
    "        d = BatchNormalization(momentum=0.8)(d)\n",
    "    return d\n",
    "\n",
    "def deconv2d(layer_input, skip_input, filters, f_size=4, dropout_rate=0):\n",
    "    \"\"\"Layers used during upsampling\"\"\"\n",
    "    u = UpSampling2D(size=2)(layer_input)\n",
    "    u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n",
    "    if dropout_rate:\n",
    "        u = Dropout(dropout_rate)(u)\n",
    "    u = BatchNormalization(momentum=0.8)(u)\n",
    "    u = Concatenate()([u, skip_input])\n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(img_shape, gf, channels):\n",
    "    \"\"\"U-Net Generator\"\"\"\n",
    "    img = Input(shape=img_shape)\n",
    "\n",
    "    # Downsampling\n",
    "    d1 = conv2d(img, gf, bn=False)\n",
    "    d2 = conv2d(d1, gf*2)\n",
    "    d3 = conv2d(d2, gf*4)\n",
    "    d4 = conv2d(d3, gf*8)\n",
    "\n",
    "    # Upsampling\n",
    "    u1 = deconv2d(d4, d3, gf*4)\n",
    "    u2 = deconv2d(u1, d2, gf*2)\n",
    "    u3 = deconv2d(u2, d1, gf)\n",
    "\n",
    "    u4 = UpSampling2D(size=2)(u3)\n",
    "    output_img = Conv2D(channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u4)\n",
    "\n",
    "    return Model(img, output_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(img_shape, df, num_classes):\n",
    "\n",
    "    img = Input(shape=img_shape)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(df, kernel_size=4, strides=2, padding='same', input_shape=img_shape))\n",
    "    model.add(LeakyReLU(alpha=0.8))\n",
    "    model.add(Conv2D(df * 2, kernel_size=4, strides=2, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(InstanceNormalization())\n",
    "    model.add(Conv2D(df * 4, kernel_size=4, strides=2, padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(InstanceNormalization())\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    img = Input(shape=img_shape)\n",
    "    features = model(img)\n",
    "\n",
    "    validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(features)\n",
    "\n",
    "    label = Flatten()(features)\n",
    "    label = Dense(num_classes+1, activation=\"softmax\")(label)\n",
    "\n",
    "    return Model(img, [validity, label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(model, model_name):\n",
    "    model_path = \"saved_model/%s.json\" % model_name\n",
    "    weights_path = \"saved_model/%s_weights.hdf5\" % model_name\n",
    "    options = {\"file_arch\": model_path,\n",
    "                \"file_weight\": weights_path}\n",
    "    json_string = model.to_json()\n",
    "    open(options['file_arch'], 'w').write(json_string)\n",
    "    model.save_weights(options['file_weight'])\n",
    "\n",
    "def save_model(G, D):\n",
    "    save(G, \"ccgan_generator\")\n",
    "    save(D, \"ccgan_discriminator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_randomly(imgs, img_rows, mask_height):\n",
    "    y1 = np.random.randint(0, img_rows - mask_height, imgs.shape[0])\n",
    "    y2 = y1 + mask_height\n",
    "    x1 = np.random.randint(0, img_rows - mask_width, imgs.shape[0])\n",
    "    x2 = x1 + mask_width\n",
    "\n",
    "    masked_imgs = np.empty_like(imgs)\n",
    "    for i, img in enumerate(imgs):\n",
    "        masked_img = img.copy()\n",
    "        _y1, _y2, _x1, _x2 = y1[i], y2[i], x1[i], x2[i],\n",
    "        masked_img[_y1:_y2, _x1:_x2, :] = 0\n",
    "        masked_imgs[i] = masked_img\n",
    "\n",
    "    return masked_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(G, epoch, \n",
    "                  imgs, img_rows, mask_height):\n",
    "    r, c = 3, 6\n",
    "\n",
    "    masked_imgs = mask_randomly(imgs, img_rows, mask_height)\n",
    "    gen_imgs = G.predict(masked_imgs)\n",
    "\n",
    "    imgs = (imgs + 1.0) * 0.5\n",
    "    masked_imgs = (masked_imgs + 1.0) * 0.5\n",
    "    gen_imgs = (gen_imgs + 1.0) * 0.5\n",
    "\n",
    "    gen_imgs = np.where(gen_imgs < 0, 0, gen_imgs)\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    for i in range(c):\n",
    "        axs[0,i].imshow(imgs[i, :, :, 0], cmap='gray')\n",
    "        axs[0,i].axis('off')\n",
    "        axs[1,i].imshow(masked_imgs[i, :, :, 0], cmap='gray')\n",
    "        axs[1,i].axis('off')\n",
    "        axs[2,i].imshow(gen_imgs[i, :, :, 0], cmap='gray')\n",
    "        axs[2,i].axis('off')\n",
    "    fig.savefig(\"images/%d.png\" % epoch)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imresize(img, size):\n",
    "    \"\"\"workaroung imresize\"\"\"\n",
    "    from PIL import Image\n",
    "    im = Image.fromarray(np.asarray(img).astype(np.uint8))\n",
    "    new_image = np.array(im.resize(size, Image.BICUBIC))\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(G, D, combined,\n",
    "          img_rows, mask_height,\n",
    "          num_classes,\n",
    "          epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "    # Load the dataset\n",
    "    (X_train, y_train), (_, _) = mnist.load_data()\n",
    "\n",
    "    # Rescale MNIST to 32x32\n",
    "    X_train = np.array([imresize(x, [img_rows, img_cols]) for x in X_train])\n",
    "\n",
    "    # Rescale -1 to 1\n",
    "    X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "    X_train = np.expand_dims(X_train, axis=3)\n",
    "    y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "    # Adversarial ground truths\n",
    "    valid = np.ones((batch_size, 4, 4, 1))\n",
    "    fake = np.zeros((batch_size, 4, 4, 1))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        # Sample half batch of images\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        imgs = X_train[idx]\n",
    "        labels = y_train[idx]\n",
    "\n",
    "        masked_imgs = mask_randomly(imgs, img_rows, mask_height)\n",
    "\n",
    "        # Generate a half batch of new images\n",
    "        gen_imgs = G.predict(masked_imgs)\n",
    "\n",
    "        # One-hot encoding of labels\n",
    "        labels = to_categorical(labels, num_classes=num_classes+1)\n",
    "        fake_labels = to_categorical(np.full((batch_size, 1), num_classes), num_classes=num_classes+1)\n",
    "\n",
    "        # Train the discriminator\n",
    "        d_loss_real = D.train_on_batch(imgs, [valid, labels])\n",
    "        d_loss_fake = D.train_on_batch(gen_imgs, [fake, fake_labels])\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Generator\n",
    "        # ---------------------\n",
    "\n",
    "        # Train the generator\n",
    "        g_loss = combined.train_on_batch(masked_imgs, valid)\n",
    "\n",
    "        # Plot the progress\n",
    "        print (\"%d [D loss: %f, op_acc: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[4], g_loss))\n",
    "\n",
    "        # If at save interval => save generated image samples\n",
    "        if epoch % sample_interval == 0 or epoch == epochs - 1:\n",
    "            # Select a random half batch of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], 6)\n",
    "            imgs = X_train[idx]\n",
    "            sample_images(G, epoch, imgs, img_rows, mask_height)\n",
    "            save_model(G, D)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in ['saved_model', 'images']:\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 32\n",
    "img_cols = 32\n",
    "channels = 1\n",
    "img_shape = (img_rows, img_cols, channels)\n",
    "mask_height = 10\n",
    "mask_width = 10\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of filters in first layer of generator and discriminator\n",
    "gf = 32\n",
    "df = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\henri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# create optimizer\n",
    "optimizer = Adam(0.0002, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 64)        1088      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 128)         131200    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "instance_normalization_1 (In (None, 8, 8, 128)         2         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 256)         524544    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "instance_normalization_2 (In (None, 4, 4, 256)         2         \n",
      "=================================================================\n",
      "Total params: 656,836\n",
      "Trainable params: 656,836\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build and compile the discriminator\n",
    "D = build_discriminator(img_shape, df, num_classes)\n",
    "D.compile(loss=['mse', 'categorical_crossentropy'],\n",
    "    loss_weights=[0.5, 0.5],\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the generator\n",
    "G = build_generator(img_shape, gf, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The generator takes noise as input and generates imgs\n",
    "masked_img = Input(shape=img_shape)\n",
    "gen_img = G(masked_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the combined model we will only train the generator\n",
    "D.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The valid takes generated images as input and determines validity\n",
    "valid, _ = D(gen_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The combined model  (stacked generator and discriminator)\n",
    "# Trains the generator to fool the discriminator\n",
    "combined = Model(masked_img , valid)\n",
    "combined.compile(loss=['mse'],\n",
    "                 optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\henri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\henri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "c:\\users\\henri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 2.676828, op_acc: 31.25%] [G loss: 1.671727]\n",
      "1 [D loss: 2.947555, op_acc: 54.69%] [G loss: 1.411595]\n",
      "2 [D loss: 1.220675, op_acc: 56.25%] [G loss: 0.926958]\n",
      "3 [D loss: 0.798387, op_acc: 59.38%] [G loss: 1.037243]\n",
      "4 [D loss: 0.999775, op_acc: 67.19%] [G loss: 0.807718]\n",
      "5 [D loss: 1.080346, op_acc: 73.44%] [G loss: 0.588819]\n",
      "6 [D loss: 0.899316, op_acc: 64.06%] [G loss: 0.444817]\n",
      "7 [D loss: 0.737623, op_acc: 71.88%] [G loss: 0.962830]\n",
      "8 [D loss: 0.738256, op_acc: 68.75%] [G loss: 0.419260]\n",
      "9 [D loss: 0.568055, op_acc: 71.88%] [G loss: 0.502009]\n",
      "10 [D loss: 0.507391, op_acc: 78.12%] [G loss: 0.508464]\n",
      "11 [D loss: 0.441194, op_acc: 76.56%] [G loss: 0.424369]\n",
      "12 [D loss: 0.492726, op_acc: 78.12%] [G loss: 0.655686]\n",
      "13 [D loss: 0.690747, op_acc: 85.94%] [G loss: 0.862430]\n",
      "14 [D loss: 0.855289, op_acc: 73.44%] [G loss: 0.445141]\n",
      "15 [D loss: 0.617780, op_acc: 75.00%] [G loss: 0.642001]\n",
      "16 [D loss: 0.573249, op_acc: 78.12%] [G loss: 1.003126]\n",
      "17 [D loss: 0.416929, op_acc: 84.38%] [G loss: 1.472773]\n",
      "18 [D loss: 0.426587, op_acc: 84.38%] [G loss: 1.759374]\n",
      "19 [D loss: 0.499204, op_acc: 78.12%] [G loss: 1.678194]\n",
      "20 [D loss: 0.460596, op_acc: 81.25%] [G loss: 3.708257]\n",
      "21 [D loss: 1.048613, op_acc: 81.25%] [G loss: 7.638703]\n",
      "22 [D loss: 1.149260, op_acc: 71.88%] [G loss: 2.460429]\n",
      "23 [D loss: 1.224354, op_acc: 79.69%] [G loss: 2.970385]\n",
      "24 [D loss: 0.851818, op_acc: 82.81%] [G loss: 1.287776]\n",
      "25 [D loss: 0.660586, op_acc: 79.69%] [G loss: 1.258357]\n",
      "26 [D loss: 0.376965, op_acc: 87.50%] [G loss: 1.095713]\n",
      "27 [D loss: 0.333024, op_acc: 87.50%] [G loss: 1.101367]\n",
      "28 [D loss: 0.382934, op_acc: 87.50%] [G loss: 0.992595]\n",
      "29 [D loss: 0.344490, op_acc: 87.50%] [G loss: 0.983211]\n",
      "30 [D loss: 0.387631, op_acc: 90.62%] [G loss: 0.817052]\n",
      "31 [D loss: 0.522523, op_acc: 78.12%] [G loss: 1.286227]\n",
      "32 [D loss: 0.493740, op_acc: 84.38%] [G loss: 0.857244]\n",
      "33 [D loss: 0.510336, op_acc: 76.56%] [G loss: 1.292674]\n",
      "34 [D loss: 0.468802, op_acc: 89.06%] [G loss: 0.912363]\n",
      "35 [D loss: 0.368155, op_acc: 84.38%] [G loss: 1.275218]\n",
      "36 [D loss: 0.320148, op_acc: 95.31%] [G loss: 0.936990]\n",
      "37 [D loss: 0.282041, op_acc: 92.19%] [G loss: 0.973454]\n",
      "38 [D loss: 0.461954, op_acc: 84.38%] [G loss: 1.178035]\n",
      "39 [D loss: 0.448519, op_acc: 84.38%] [G loss: 1.233889]\n",
      "40 [D loss: 0.406269, op_acc: 87.50%] [G loss: 0.897293]\n",
      "41 [D loss: 0.323343, op_acc: 96.88%] [G loss: 1.296645]\n",
      "42 [D loss: 0.652564, op_acc: 78.12%] [G loss: 1.002131]\n",
      "43 [D loss: 0.504449, op_acc: 79.69%] [G loss: 0.969474]\n",
      "44 [D loss: 0.554587, op_acc: 87.50%] [G loss: 0.792303]\n",
      "45 [D loss: 0.642252, op_acc: 76.56%] [G loss: 1.199070]\n",
      "46 [D loss: 0.743316, op_acc: 81.25%] [G loss: 0.594996]\n",
      "47 [D loss: 0.374358, op_acc: 87.50%] [G loss: 1.048249]\n",
      "48 [D loss: 0.597741, op_acc: 81.25%] [G loss: 1.101310]\n",
      "49 [D loss: 0.461531, op_acc: 81.25%] [G loss: 1.062527]\n",
      "50 [D loss: 0.490692, op_acc: 84.38%] [G loss: 1.239932]\n",
      "51 [D loss: 0.644902, op_acc: 75.00%] [G loss: 0.819535]\n",
      "52 [D loss: 0.687175, op_acc: 67.19%] [G loss: 0.856094]\n",
      "53 [D loss: 0.544423, op_acc: 78.12%] [G loss: 0.964237]\n",
      "54 [D loss: 0.551529, op_acc: 78.12%] [G loss: 1.013113]\n",
      "55 [D loss: 0.679641, op_acc: 73.44%] [G loss: 0.944023]\n",
      "56 [D loss: 0.734137, op_acc: 81.25%] [G loss: 0.803049]\n",
      "57 [D loss: 0.730583, op_acc: 73.44%] [G loss: 0.914920]\n",
      "58 [D loss: 0.700505, op_acc: 73.44%] [G loss: 0.633242]\n",
      "59 [D loss: 0.544021, op_acc: 78.12%] [G loss: 0.731237]\n",
      "60 [D loss: 0.660063, op_acc: 68.75%] [G loss: 0.708426]\n",
      "61 [D loss: 0.781645, op_acc: 60.94%] [G loss: 0.734479]\n",
      "62 [D loss: 0.738156, op_acc: 75.00%] [G loss: 0.838838]\n",
      "63 [D loss: 0.845906, op_acc: 65.62%] [G loss: 0.645793]\n",
      "64 [D loss: 0.734002, op_acc: 71.88%] [G loss: 0.794222]\n",
      "65 [D loss: 0.922758, op_acc: 56.25%] [G loss: 0.568085]\n",
      "66 [D loss: 0.548821, op_acc: 82.81%] [G loss: 0.909116]\n",
      "67 [D loss: 0.573781, op_acc: 82.81%] [G loss: 0.723716]\n",
      "68 [D loss: 0.608826, op_acc: 67.19%] [G loss: 0.782520]\n",
      "69 [D loss: 0.376251, op_acc: 87.50%] [G loss: 0.838950]\n",
      "70 [D loss: 0.757559, op_acc: 64.06%] [G loss: 0.560562]\n",
      "71 [D loss: 0.705551, op_acc: 67.19%] [G loss: 0.614336]\n",
      "72 [D loss: 0.754124, op_acc: 70.31%] [G loss: 0.534643]\n",
      "73 [D loss: 0.664967, op_acc: 70.31%] [G loss: 0.492808]\n",
      "74 [D loss: 0.769547, op_acc: 57.81%] [G loss: 0.442974]\n",
      "75 [D loss: 0.552635, op_acc: 73.44%] [G loss: 0.498470]\n",
      "76 [D loss: 0.533697, op_acc: 79.69%] [G loss: 0.524338]\n",
      "77 [D loss: 0.407586, op_acc: 87.50%] [G loss: 0.588554]\n",
      "78 [D loss: 0.402492, op_acc: 90.62%] [G loss: 0.569197]\n",
      "79 [D loss: 0.494925, op_acc: 82.81%] [G loss: 0.649229]\n",
      "80 [D loss: 0.468525, op_acc: 85.94%] [G loss: 0.565020]\n",
      "81 [D loss: 0.412550, op_acc: 84.38%] [G loss: 0.593607]\n",
      "82 [D loss: 0.484821, op_acc: 85.94%] [G loss: 0.591334]\n",
      "83 [D loss: 0.642336, op_acc: 76.56%] [G loss: 0.490574]\n",
      "84 [D loss: 0.525875, op_acc: 76.56%] [G loss: 0.547934]\n",
      "85 [D loss: 0.688933, op_acc: 65.62%] [G loss: 0.500449]\n",
      "86 [D loss: 0.492623, op_acc: 76.56%] [G loss: 0.456229]\n",
      "87 [D loss: 0.620538, op_acc: 60.94%] [G loss: 0.489741]\n",
      "88 [D loss: 0.428944, op_acc: 84.38%] [G loss: 0.473545]\n",
      "89 [D loss: 0.581455, op_acc: 70.31%] [G loss: 0.461383]\n",
      "90 [D loss: 0.864069, op_acc: 53.12%] [G loss: 0.508365]\n",
      "91 [D loss: 0.490747, op_acc: 81.25%] [G loss: 0.432393]\n",
      "92 [D loss: 0.527377, op_acc: 70.31%] [G loss: 0.560481]\n",
      "93 [D loss: 0.593107, op_acc: 73.44%] [G loss: 0.472439]\n",
      "94 [D loss: 0.610551, op_acc: 65.62%] [G loss: 0.456213]\n",
      "95 [D loss: 0.535246, op_acc: 76.56%] [G loss: 0.428013]\n",
      "96 [D loss: 0.562433, op_acc: 70.31%] [G loss: 0.553839]\n",
      "97 [D loss: 0.501552, op_acc: 75.00%] [G loss: 0.491237]\n",
      "98 [D loss: 0.501017, op_acc: 76.56%] [G loss: 0.412696]\n",
      "99 [D loss: 0.623194, op_acc: 67.19%] [G loss: 0.509639]\n",
      "100 [D loss: 0.529263, op_acc: 73.44%] [G loss: 0.511836]\n",
      "101 [D loss: 0.630210, op_acc: 70.31%] [G loss: 0.433153]\n",
      "102 [D loss: 0.560455, op_acc: 70.31%] [G loss: 0.426456]\n",
      "103 [D loss: 0.643915, op_acc: 64.06%] [G loss: 0.402779]\n",
      "104 [D loss: 0.755601, op_acc: 67.19%] [G loss: 0.534529]\n",
      "105 [D loss: 0.679182, op_acc: 70.31%] [G loss: 0.434928]\n",
      "106 [D loss: 0.711403, op_acc: 64.06%] [G loss: 0.391054]\n",
      "107 [D loss: 0.775396, op_acc: 56.25%] [G loss: 0.470924]\n",
      "108 [D loss: 0.608469, op_acc: 64.06%] [G loss: 0.400171]\n",
      "109 [D loss: 0.675963, op_acc: 62.50%] [G loss: 0.433453]\n",
      "110 [D loss: 0.477957, op_acc: 75.00%] [G loss: 0.383372]\n",
      "111 [D loss: 0.835183, op_acc: 54.69%] [G loss: 0.471040]\n",
      "112 [D loss: 0.613553, op_acc: 57.81%] [G loss: 0.456406]\n",
      "113 [D loss: 0.518037, op_acc: 73.44%] [G loss: 0.380284]\n",
      "114 [D loss: 0.512302, op_acc: 65.62%] [G loss: 0.510239]\n",
      "115 [D loss: 0.567718, op_acc: 71.88%] [G loss: 0.442822]\n",
      "116 [D loss: 0.484164, op_acc: 79.69%] [G loss: 0.399729]\n",
      "117 [D loss: 0.519283, op_acc: 73.44%] [G loss: 0.491019]\n",
      "118 [D loss: 0.647356, op_acc: 59.38%] [G loss: 0.363673]\n",
      "119 [D loss: 0.569397, op_acc: 70.31%] [G loss: 0.381699]\n",
      "120 [D loss: 0.571190, op_acc: 67.19%] [G loss: 0.477855]\n",
      "121 [D loss: 0.605164, op_acc: 75.00%] [G loss: 0.371958]\n",
      "122 [D loss: 0.541488, op_acc: 73.44%] [G loss: 0.453431]\n",
      "123 [D loss: 0.557425, op_acc: 71.88%] [G loss: 0.433273]\n",
      "124 [D loss: 0.459657, op_acc: 79.69%] [G loss: 0.437537]\n",
      "125 [D loss: 0.503336, op_acc: 70.31%] [G loss: 0.425138]\n",
      "126 [D loss: 0.456228, op_acc: 81.25%] [G loss: 0.511949]\n",
      "127 [D loss: 0.611499, op_acc: 67.19%] [G loss: 0.376075]\n",
      "128 [D loss: 0.540848, op_acc: 73.44%] [G loss: 0.458933]\n",
      "129 [D loss: 0.627122, op_acc: 54.69%] [G loss: 0.374906]\n",
      "130 [D loss: 0.511197, op_acc: 75.00%] [G loss: 0.439549]\n",
      "131 [D loss: 0.626294, op_acc: 67.19%] [G loss: 0.433755]\n",
      "132 [D loss: 0.560725, op_acc: 68.75%] [G loss: 0.384735]\n",
      "133 [D loss: 0.602256, op_acc: 57.81%] [G loss: 0.453415]\n",
      "134 [D loss: 0.575490, op_acc: 82.81%] [G loss: 0.426938]\n",
      "135 [D loss: 0.666065, op_acc: 68.75%] [G loss: 0.382778]\n",
      "136 [D loss: 0.533268, op_acc: 76.56%] [G loss: 0.420949]\n",
      "137 [D loss: 0.463273, op_acc: 82.81%] [G loss: 0.393765]\n",
      "138 [D loss: 0.583655, op_acc: 65.62%] [G loss: 0.455838]\n",
      "139 [D loss: 0.659347, op_acc: 65.62%] [G loss: 0.358593]\n",
      "140 [D loss: 0.500709, op_acc: 73.44%] [G loss: 0.473015]\n",
      "141 [D loss: 0.567783, op_acc: 70.31%] [G loss: 0.313569]\n",
      "142 [D loss: 0.432354, op_acc: 79.69%] [G loss: 0.424048]\n",
      "143 [D loss: 0.692062, op_acc: 59.38%] [G loss: 0.381452]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144 [D loss: 0.549511, op_acc: 75.00%] [G loss: 0.403488]\n",
      "145 [D loss: 0.495174, op_acc: 81.25%] [G loss: 0.442974]\n",
      "146 [D loss: 0.459040, op_acc: 79.69%] [G loss: 0.349668]\n",
      "147 [D loss: 0.565326, op_acc: 70.31%] [G loss: 0.478392]\n",
      "148 [D loss: 0.612672, op_acc: 70.31%] [G loss: 0.422355]\n",
      "149 [D loss: 0.499508, op_acc: 81.25%] [G loss: 0.383089]\n",
      "150 [D loss: 0.662975, op_acc: 64.06%] [G loss: 0.436297]\n",
      "151 [D loss: 0.567225, op_acc: 67.19%] [G loss: 0.339511]\n",
      "152 [D loss: 0.480788, op_acc: 71.88%] [G loss: 0.432686]\n",
      "153 [D loss: 0.527470, op_acc: 70.31%] [G loss: 0.469522]\n",
      "154 [D loss: 0.579658, op_acc: 68.75%] [G loss: 0.411361]\n",
      "155 [D loss: 0.562804, op_acc: 71.88%] [G loss: 0.365664]\n",
      "156 [D loss: 0.549312, op_acc: 68.75%] [G loss: 0.426484]\n",
      "157 [D loss: 0.614819, op_acc: 62.50%] [G loss: 0.398174]\n",
      "158 [D loss: 0.527271, op_acc: 78.12%] [G loss: 0.408960]\n",
      "159 [D loss: 0.583362, op_acc: 68.75%] [G loss: 0.434061]\n",
      "160 [D loss: 0.541418, op_acc: 73.44%] [G loss: 0.386245]\n",
      "161 [D loss: 0.511671, op_acc: 76.56%] [G loss: 0.423369]\n",
      "162 [D loss: 0.446948, op_acc: 75.00%] [G loss: 0.378132]\n",
      "163 [D loss: 0.481946, op_acc: 78.12%] [G loss: 0.472576]\n",
      "164 [D loss: 0.433712, op_acc: 82.81%] [G loss: 0.443332]\n",
      "165 [D loss: 0.476521, op_acc: 85.94%] [G loss: 0.458721]\n",
      "166 [D loss: 0.442347, op_acc: 82.81%] [G loss: 0.353324]\n",
      "167 [D loss: 0.430776, op_acc: 89.06%] [G loss: 0.422745]\n",
      "168 [D loss: 0.655947, op_acc: 65.62%] [G loss: 0.344011]\n",
      "169 [D loss: 0.440710, op_acc: 84.38%] [G loss: 0.359277]\n",
      "170 [D loss: 0.693014, op_acc: 59.38%] [G loss: 0.409545]\n",
      "171 [D loss: 0.501102, op_acc: 79.69%] [G loss: 0.358434]\n",
      "172 [D loss: 0.540098, op_acc: 68.75%] [G loss: 0.404956]\n",
      "173 [D loss: 0.471068, op_acc: 85.94%] [G loss: 0.380983]\n",
      "174 [D loss: 0.410694, op_acc: 82.81%] [G loss: 0.442947]\n",
      "175 [D loss: 0.400546, op_acc: 87.50%] [G loss: 0.407794]\n",
      "176 [D loss: 0.407115, op_acc: 82.81%] [G loss: 0.378372]\n",
      "177 [D loss: 0.434107, op_acc: 75.00%] [G loss: 0.412601]\n",
      "178 [D loss: 0.512917, op_acc: 79.69%] [G loss: 0.425250]\n",
      "179 [D loss: 0.546728, op_acc: 65.62%] [G loss: 0.397898]\n",
      "180 [D loss: 0.378161, op_acc: 87.50%] [G loss: 0.372757]\n",
      "181 [D loss: 0.414280, op_acc: 84.38%] [G loss: 0.423412]\n",
      "182 [D loss: 0.444212, op_acc: 84.38%] [G loss: 0.427695]\n",
      "183 [D loss: 0.491392, op_acc: 79.69%] [G loss: 0.408823]\n",
      "184 [D loss: 0.430586, op_acc: 81.25%] [G loss: 0.439457]\n",
      "185 [D loss: 0.414250, op_acc: 87.50%] [G loss: 0.444259]\n",
      "186 [D loss: 0.451873, op_acc: 85.94%] [G loss: 0.397067]\n",
      "187 [D loss: 0.409350, op_acc: 84.38%] [G loss: 0.397558]\n",
      "188 [D loss: 0.487154, op_acc: 73.44%] [G loss: 0.480054]\n",
      "189 [D loss: 0.403527, op_acc: 87.50%] [G loss: 0.415115]\n",
      "190 [D loss: 0.531347, op_acc: 75.00%] [G loss: 0.361520]\n",
      "191 [D loss: 0.431748, op_acc: 82.81%] [G loss: 0.421946]\n",
      "192 [D loss: 0.422264, op_acc: 85.94%] [G loss: 0.425319]\n",
      "193 [D loss: 0.430158, op_acc: 87.50%] [G loss: 0.385404]\n",
      "194 [D loss: 0.463479, op_acc: 76.56%] [G loss: 0.416552]\n",
      "195 [D loss: 0.398108, op_acc: 82.81%] [G loss: 0.387206]\n",
      "196 [D loss: 0.568640, op_acc: 73.44%] [G loss: 0.431360]\n",
      "197 [D loss: 0.503305, op_acc: 79.69%] [G loss: 0.459451]\n",
      "198 [D loss: 0.478586, op_acc: 79.69%] [G loss: 0.418553]\n",
      "199 [D loss: 0.419100, op_acc: 82.81%] [G loss: 0.347089]\n",
      "200 [D loss: 0.552589, op_acc: 65.62%] [G loss: 0.535911]\n",
      "201 [D loss: 0.513961, op_acc: 78.12%] [G loss: 0.347445]\n",
      "202 [D loss: 0.508842, op_acc: 73.44%] [G loss: 0.389110]\n",
      "203 [D loss: 0.482593, op_acc: 78.12%] [G loss: 0.439727]\n",
      "204 [D loss: 0.659991, op_acc: 56.25%] [G loss: 0.358267]\n",
      "205 [D loss: 0.465891, op_acc: 79.69%] [G loss: 0.347140]\n",
      "206 [D loss: 0.616051, op_acc: 71.88%] [G loss: 0.397285]\n",
      "207 [D loss: 0.594594, op_acc: 67.19%] [G loss: 0.368180]\n",
      "208 [D loss: 0.531142, op_acc: 71.88%] [G loss: 0.348952]\n",
      "209 [D loss: 0.556456, op_acc: 65.62%] [G loss: 0.392932]\n",
      "210 [D loss: 0.465179, op_acc: 82.81%] [G loss: 0.401442]\n",
      "211 [D loss: 0.527474, op_acc: 75.00%] [G loss: 0.382619]\n",
      "212 [D loss: 0.498438, op_acc: 76.56%] [G loss: 0.380490]\n",
      "213 [D loss: 0.447150, op_acc: 82.81%] [G loss: 0.426671]\n",
      "214 [D loss: 0.512674, op_acc: 78.12%] [G loss: 0.414489]\n",
      "215 [D loss: 0.385177, op_acc: 92.19%] [G loss: 0.412755]\n",
      "216 [D loss: 0.434374, op_acc: 84.38%] [G loss: 0.410067]\n",
      "217 [D loss: 0.394860, op_acc: 85.94%] [G loss: 0.403302]\n",
      "218 [D loss: 0.529116, op_acc: 67.19%] [G loss: 0.345811]\n",
      "219 [D loss: 0.510309, op_acc: 76.56%] [G loss: 0.376675]\n",
      "220 [D loss: 0.448761, op_acc: 79.69%] [G loss: 0.364652]\n",
      "221 [D loss: 0.500389, op_acc: 79.69%] [G loss: 0.376142]\n",
      "222 [D loss: 0.499485, op_acc: 73.44%] [G loss: 0.387013]\n",
      "223 [D loss: 0.395409, op_acc: 85.94%] [G loss: 0.415227]\n",
      "224 [D loss: 0.519578, op_acc: 81.25%] [G loss: 0.330636]\n",
      "225 [D loss: 0.502061, op_acc: 70.31%] [G loss: 0.384472]\n",
      "226 [D loss: 0.444506, op_acc: 76.56%] [G loss: 0.371366]\n",
      "227 [D loss: 0.587101, op_acc: 65.62%] [G loss: 0.333512]\n",
      "228 [D loss: 0.381997, op_acc: 85.94%] [G loss: 0.376625]\n",
      "229 [D loss: 0.537319, op_acc: 75.00%] [G loss: 0.401834]\n",
      "230 [D loss: 0.430408, op_acc: 81.25%] [G loss: 0.362298]\n",
      "231 [D loss: 0.531974, op_acc: 79.69%] [G loss: 0.378026]\n",
      "232 [D loss: 0.445965, op_acc: 82.81%] [G loss: 0.381843]\n",
      "233 [D loss: 0.447152, op_acc: 87.50%] [G loss: 0.389941]\n",
      "234 [D loss: 0.541146, op_acc: 70.31%] [G loss: 0.350180]\n",
      "235 [D loss: 0.502818, op_acc: 75.00%] [G loss: 0.361702]\n",
      "236 [D loss: 0.522233, op_acc: 71.88%] [G loss: 0.370591]\n",
      "237 [D loss: 0.488472, op_acc: 75.00%] [G loss: 0.393833]\n",
      "238 [D loss: 0.450952, op_acc: 79.69%] [G loss: 0.345574]\n",
      "239 [D loss: 0.437701, op_acc: 78.12%] [G loss: 0.365277]\n",
      "240 [D loss: 0.502877, op_acc: 68.75%] [G loss: 0.414056]\n",
      "241 [D loss: 0.414308, op_acc: 82.81%] [G loss: 0.352615]\n",
      "242 [D loss: 0.504022, op_acc: 75.00%] [G loss: 0.423210]\n",
      "243 [D loss: 0.538296, op_acc: 76.56%] [G loss: 0.355269]\n",
      "244 [D loss: 0.429886, op_acc: 79.69%] [G loss: 0.408135]\n",
      "245 [D loss: 0.418113, op_acc: 84.38%] [G loss: 0.461873]\n",
      "246 [D loss: 0.387147, op_acc: 84.38%] [G loss: 0.371252]\n",
      "247 [D loss: 0.488152, op_acc: 79.69%] [G loss: 0.378172]\n",
      "248 [D loss: 0.450956, op_acc: 78.12%] [G loss: 0.402732]\n",
      "249 [D loss: 0.507832, op_acc: 79.69%] [G loss: 0.385955]\n",
      "250 [D loss: 0.477499, op_acc: 75.00%] [G loss: 0.318256]\n",
      "251 [D loss: 0.437191, op_acc: 81.25%] [G loss: 0.359611]\n",
      "252 [D loss: 0.548555, op_acc: 62.50%] [G loss: 0.409857]\n",
      "253 [D loss: 0.411280, op_acc: 82.81%] [G loss: 0.354135]\n",
      "254 [D loss: 0.589450, op_acc: 67.19%] [G loss: 0.374982]\n",
      "255 [D loss: 0.498039, op_acc: 81.25%] [G loss: 0.358918]\n",
      "256 [D loss: 0.387080, op_acc: 87.50%] [G loss: 0.373346]\n",
      "257 [D loss: 0.312421, op_acc: 90.62%] [G loss: 0.359238]\n",
      "258 [D loss: 0.450284, op_acc: 76.56%] [G loss: 0.393689]\n",
      "259 [D loss: 0.466185, op_acc: 78.12%] [G loss: 0.346195]\n",
      "260 [D loss: 0.438264, op_acc: 76.56%] [G loss: 0.383196]\n",
      "261 [D loss: 0.356900, op_acc: 87.50%] [G loss: 0.412933]\n",
      "262 [D loss: 0.419549, op_acc: 79.69%] [G loss: 0.385205]\n",
      "263 [D loss: 0.460877, op_acc: 81.25%] [G loss: 0.431189]\n",
      "264 [D loss: 0.406845, op_acc: 81.25%] [G loss: 0.306679]\n",
      "265 [D loss: 0.446934, op_acc: 79.69%] [G loss: 0.392885]\n",
      "266 [D loss: 0.490114, op_acc: 75.00%] [G loss: 0.414646]\n",
      "267 [D loss: 0.456357, op_acc: 75.00%] [G loss: 0.366788]\n",
      "268 [D loss: 0.501570, op_acc: 75.00%] [G loss: 0.335654]\n",
      "269 [D loss: 0.382322, op_acc: 81.25%] [G loss: 0.401200]\n",
      "270 [D loss: 0.372290, op_acc: 79.69%] [G loss: 0.380431]\n",
      "271 [D loss: 0.492367, op_acc: 75.00%] [G loss: 0.411752]\n",
      "272 [D loss: 0.348984, op_acc: 90.62%] [G loss: 0.347909]\n",
      "273 [D loss: 0.483426, op_acc: 81.25%] [G loss: 0.396573]\n",
      "274 [D loss: 0.621567, op_acc: 60.94%] [G loss: 0.412767]\n",
      "275 [D loss: 0.423715, op_acc: 82.81%] [G loss: 0.325468]\n",
      "276 [D loss: 0.470056, op_acc: 70.31%] [G loss: 0.374933]\n",
      "277 [D loss: 0.364076, op_acc: 89.06%] [G loss: 0.355304]\n",
      "278 [D loss: 0.503748, op_acc: 75.00%] [G loss: 0.342024]\n",
      "279 [D loss: 0.517684, op_acc: 81.25%] [G loss: 0.388205]\n",
      "280 [D loss: 0.501488, op_acc: 78.12%] [G loss: 0.400269]\n",
      "281 [D loss: 0.438302, op_acc: 82.81%] [G loss: 0.367372]\n",
      "282 [D loss: 0.364110, op_acc: 90.62%] [G loss: 0.370436]\n",
      "283 [D loss: 0.426385, op_acc: 76.56%] [G loss: 0.397814]\n",
      "284 [D loss: 0.450113, op_acc: 81.25%] [G loss: 0.349632]\n",
      "285 [D loss: 0.419304, op_acc: 81.25%] [G loss: 0.388944]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286 [D loss: 0.534046, op_acc: 71.88%] [G loss: 0.372910]\n",
      "287 [D loss: 0.537879, op_acc: 67.19%] [G loss: 0.359787]\n",
      "288 [D loss: 0.489184, op_acc: 71.88%] [G loss: 0.323519]\n",
      "289 [D loss: 0.370990, op_acc: 89.06%] [G loss: 0.386663]\n",
      "290 [D loss: 0.498720, op_acc: 71.88%] [G loss: 0.399097]\n",
      "291 [D loss: 0.393178, op_acc: 82.81%] [G loss: 0.349669]\n",
      "292 [D loss: 0.476386, op_acc: 70.31%] [G loss: 0.426485]\n",
      "293 [D loss: 0.394634, op_acc: 81.25%] [G loss: 0.397008]\n",
      "294 [D loss: 0.406294, op_acc: 82.81%] [G loss: 0.332845]\n",
      "295 [D loss: 0.480516, op_acc: 79.69%] [G loss: 0.382449]\n",
      "296 [D loss: 0.561146, op_acc: 57.81%] [G loss: 0.346764]\n",
      "297 [D loss: 0.437053, op_acc: 79.69%] [G loss: 0.339082]\n",
      "298 [D loss: 0.430487, op_acc: 78.12%] [G loss: 0.324237]\n",
      "299 [D loss: 0.477995, op_acc: 75.00%] [G loss: 0.377062]\n",
      "300 [D loss: 0.585205, op_acc: 73.44%] [G loss: 0.333932]\n",
      "301 [D loss: 0.419304, op_acc: 78.12%] [G loss: 0.379560]\n",
      "302 [D loss: 0.418406, op_acc: 81.25%] [G loss: 0.359296]\n",
      "303 [D loss: 0.332576, op_acc: 89.06%] [G loss: 0.375419]\n",
      "304 [D loss: 0.436849, op_acc: 70.31%] [G loss: 0.400037]\n",
      "305 [D loss: 0.434038, op_acc: 89.06%] [G loss: 0.406553]\n",
      "306 [D loss: 0.313617, op_acc: 90.62%] [G loss: 0.365233]\n",
      "307 [D loss: 0.400793, op_acc: 78.12%] [G loss: 0.364033]\n",
      "308 [D loss: 0.432234, op_acc: 82.81%] [G loss: 0.415316]\n",
      "309 [D loss: 0.412972, op_acc: 81.25%] [G loss: 0.348339]\n",
      "310 [D loss: 0.483209, op_acc: 76.56%] [G loss: 0.342424]\n",
      "311 [D loss: 0.491606, op_acc: 73.44%] [G loss: 0.364350]\n",
      "312 [D loss: 0.500389, op_acc: 84.38%] [G loss: 0.386210]\n",
      "313 [D loss: 0.396017, op_acc: 82.81%] [G loss: 0.285508]\n",
      "314 [D loss: 0.415469, op_acc: 75.00%] [G loss: 0.443214]\n",
      "315 [D loss: 0.359751, op_acc: 89.06%] [G loss: 0.393324]\n",
      "316 [D loss: 0.393614, op_acc: 82.81%] [G loss: 0.370183]\n",
      "317 [D loss: 0.401970, op_acc: 84.38%] [G loss: 0.406486]\n",
      "318 [D loss: 0.320186, op_acc: 92.19%] [G loss: 0.364833]\n",
      "319 [D loss: 0.287779, op_acc: 92.19%] [G loss: 0.384860]\n",
      "320 [D loss: 0.401632, op_acc: 84.38%] [G loss: 0.406604]\n",
      "321 [D loss: 0.440509, op_acc: 78.12%] [G loss: 0.381353]\n",
      "322 [D loss: 0.422857, op_acc: 75.00%] [G loss: 0.382944]\n",
      "323 [D loss: 0.481417, op_acc: 79.69%] [G loss: 0.337230]\n",
      "324 [D loss: 0.565241, op_acc: 71.88%] [G loss: 0.366605]\n",
      "325 [D loss: 0.441972, op_acc: 81.25%] [G loss: 0.357536]\n",
      "326 [D loss: 0.523654, op_acc: 67.19%] [G loss: 0.376309]\n",
      "327 [D loss: 0.543856, op_acc: 68.75%] [G loss: 0.420006]\n",
      "328 [D loss: 0.373670, op_acc: 84.38%] [G loss: 0.376981]\n",
      "329 [D loss: 0.374424, op_acc: 84.38%] [G loss: 0.392963]\n",
      "330 [D loss: 0.467532, op_acc: 73.44%] [G loss: 0.350844]\n",
      "331 [D loss: 0.534932, op_acc: 71.88%] [G loss: 0.340541]\n",
      "332 [D loss: 0.484231, op_acc: 76.56%] [G loss: 0.409160]\n",
      "333 [D loss: 0.405812, op_acc: 79.69%] [G loss: 0.311090]\n",
      "334 [D loss: 0.443215, op_acc: 65.62%] [G loss: 0.345497]\n",
      "335 [D loss: 0.459509, op_acc: 78.12%] [G loss: 0.382856]\n",
      "336 [D loss: 0.400563, op_acc: 85.94%] [G loss: 0.371541]\n",
      "337 [D loss: 0.427252, op_acc: 79.69%] [G loss: 0.324432]\n",
      "338 [D loss: 0.409294, op_acc: 84.38%] [G loss: 0.384629]\n",
      "339 [D loss: 0.396814, op_acc: 84.38%] [G loss: 0.394368]\n",
      "340 [D loss: 0.404461, op_acc: 78.12%] [G loss: 0.350191]\n",
      "341 [D loss: 0.453325, op_acc: 76.56%] [G loss: 0.366781]\n",
      "342 [D loss: 0.478471, op_acc: 76.56%] [G loss: 0.412242]\n",
      "343 [D loss: 0.376925, op_acc: 79.69%] [G loss: 0.394785]\n",
      "344 [D loss: 0.374319, op_acc: 87.50%] [G loss: 0.379841]\n",
      "345 [D loss: 0.386987, op_acc: 82.81%] [G loss: 0.417313]\n",
      "346 [D loss: 0.354801, op_acc: 90.62%] [G loss: 0.360557]\n",
      "347 [D loss: 0.346642, op_acc: 84.38%] [G loss: 0.380603]\n",
      "348 [D loss: 0.356507, op_acc: 87.50%] [G loss: 0.369691]\n",
      "349 [D loss: 0.475367, op_acc: 70.31%] [G loss: 0.321462]\n",
      "350 [D loss: 0.483239, op_acc: 67.19%] [G loss: 0.367441]\n",
      "351 [D loss: 0.470874, op_acc: 78.12%] [G loss: 0.295907]\n",
      "352 [D loss: 0.568356, op_acc: 64.06%] [G loss: 0.390380]\n",
      "353 [D loss: 0.535914, op_acc: 75.00%] [G loss: 0.311909]\n",
      "354 [D loss: 0.387190, op_acc: 81.25%] [G loss: 0.346158]\n",
      "355 [D loss: 0.441140, op_acc: 78.12%] [G loss: 0.335887]\n",
      "356 [D loss: 0.449358, op_acc: 73.44%] [G loss: 0.343970]\n",
      "357 [D loss: 0.367059, op_acc: 85.94%] [G loss: 0.345131]\n",
      "358 [D loss: 0.418049, op_acc: 79.69%] [G loss: 0.367718]\n",
      "359 [D loss: 0.503539, op_acc: 73.44%] [G loss: 0.405558]\n",
      "360 [D loss: 0.401847, op_acc: 78.12%] [G loss: 0.377897]\n",
      "361 [D loss: 0.514076, op_acc: 71.88%] [G loss: 0.334623]\n",
      "362 [D loss: 0.471040, op_acc: 78.12%] [G loss: 0.333243]\n",
      "363 [D loss: 0.374479, op_acc: 78.12%] [G loss: 0.385329]\n",
      "364 [D loss: 0.389795, op_acc: 79.69%] [G loss: 0.331579]\n",
      "365 [D loss: 0.406776, op_acc: 81.25%] [G loss: 0.362937]\n",
      "366 [D loss: 0.482496, op_acc: 71.88%] [G loss: 0.312106]\n",
      "367 [D loss: 0.450318, op_acc: 71.88%] [G loss: 0.364011]\n",
      "368 [D loss: 0.492780, op_acc: 71.88%] [G loss: 0.343842]\n",
      "369 [D loss: 0.517847, op_acc: 71.88%] [G loss: 0.367688]\n",
      "370 [D loss: 0.524513, op_acc: 64.06%] [G loss: 0.318046]\n",
      "371 [D loss: 0.390199, op_acc: 82.81%] [G loss: 0.331021]\n",
      "372 [D loss: 0.493834, op_acc: 78.12%] [G loss: 0.366598]\n",
      "373 [D loss: 0.402214, op_acc: 81.25%] [G loss: 0.360523]\n",
      "374 [D loss: 0.550066, op_acc: 79.69%] [G loss: 0.396431]\n",
      "375 [D loss: 0.355781, op_acc: 81.25%] [G loss: 0.346358]\n",
      "376 [D loss: 0.462430, op_acc: 78.12%] [G loss: 0.300706]\n",
      "377 [D loss: 0.455361, op_acc: 71.88%] [G loss: 0.331407]\n",
      "378 [D loss: 0.429285, op_acc: 78.12%] [G loss: 0.374279]\n",
      "379 [D loss: 0.467028, op_acc: 71.88%] [G loss: 0.348490]\n",
      "380 [D loss: 0.452084, op_acc: 81.25%] [G loss: 0.354335]\n",
      "381 [D loss: 0.528047, op_acc: 68.75%] [G loss: 0.370278]\n",
      "382 [D loss: 0.415025, op_acc: 81.25%] [G loss: 0.316590]\n",
      "383 [D loss: 0.492017, op_acc: 75.00%] [G loss: 0.381562]\n",
      "384 [D loss: 0.543770, op_acc: 73.44%] [G loss: 0.361508]\n",
      "385 [D loss: 0.377020, op_acc: 85.94%] [G loss: 0.331254]\n",
      "386 [D loss: 0.385324, op_acc: 81.25%] [G loss: 0.380646]\n",
      "387 [D loss: 0.533815, op_acc: 65.62%] [G loss: 0.322396]\n",
      "388 [D loss: 0.497029, op_acc: 78.12%] [G loss: 0.333040]\n",
      "389 [D loss: 0.485022, op_acc: 71.88%] [G loss: 0.355086]\n",
      "390 [D loss: 0.447101, op_acc: 78.12%] [G loss: 0.359373]\n",
      "391 [D loss: 0.388104, op_acc: 84.38%] [G loss: 0.348199]\n",
      "392 [D loss: 0.539471, op_acc: 65.62%] [G loss: 0.365933]\n",
      "393 [D loss: 0.362065, op_acc: 87.50%] [G loss: 0.294081]\n",
      "394 [D loss: 0.462328, op_acc: 70.31%] [G loss: 0.400655]\n",
      "395 [D loss: 0.395006, op_acc: 82.81%] [G loss: 0.334208]\n",
      "396 [D loss: 0.421855, op_acc: 79.69%] [G loss: 0.347575]\n",
      "397 [D loss: 0.381288, op_acc: 84.38%] [G loss: 0.368227]\n",
      "398 [D loss: 0.402762, op_acc: 81.25%] [G loss: 0.370983]\n",
      "399 [D loss: 0.486327, op_acc: 75.00%] [G loss: 0.389531]\n",
      "400 [D loss: 0.318994, op_acc: 93.75%] [G loss: 0.366562]\n",
      "401 [D loss: 0.443333, op_acc: 78.12%] [G loss: 0.377156]\n",
      "402 [D loss: 0.386870, op_acc: 82.81%] [G loss: 0.356919]\n",
      "403 [D loss: 0.408083, op_acc: 81.25%] [G loss: 0.371171]\n",
      "404 [D loss: 0.359437, op_acc: 85.94%] [G loss: 0.329855]\n",
      "405 [D loss: 0.397054, op_acc: 79.69%] [G loss: 0.371437]\n",
      "406 [D loss: 0.426440, op_acc: 85.94%] [G loss: 0.373834]\n",
      "407 [D loss: 0.443674, op_acc: 90.62%] [G loss: 0.372577]\n",
      "408 [D loss: 0.433574, op_acc: 79.69%] [G loss: 0.374794]\n",
      "409 [D loss: 0.433363, op_acc: 79.69%] [G loss: 0.386584]\n",
      "410 [D loss: 0.448635, op_acc: 75.00%] [G loss: 0.306063]\n",
      "411 [D loss: 0.508268, op_acc: 75.00%] [G loss: 0.345961]\n",
      "412 [D loss: 0.444273, op_acc: 78.12%] [G loss: 0.363205]\n",
      "413 [D loss: 0.471137, op_acc: 78.12%] [G loss: 0.308218]\n",
      "414 [D loss: 0.347364, op_acc: 87.50%] [G loss: 0.363634]\n",
      "415 [D loss: 0.464653, op_acc: 81.25%] [G loss: 0.421482]\n",
      "416 [D loss: 0.398912, op_acc: 85.94%] [G loss: 0.353468]\n",
      "417 [D loss: 0.426050, op_acc: 84.38%] [G loss: 0.382964]\n",
      "418 [D loss: 0.374529, op_acc: 82.81%] [G loss: 0.392111]\n",
      "419 [D loss: 0.509101, op_acc: 81.25%] [G loss: 0.382058]\n",
      "420 [D loss: 0.446575, op_acc: 79.69%] [G loss: 0.335500]\n",
      "421 [D loss: 0.362643, op_acc: 82.81%] [G loss: 0.363694]\n",
      "422 [D loss: 0.434608, op_acc: 78.12%] [G loss: 0.309318]\n",
      "423 [D loss: 0.473091, op_acc: 73.44%] [G loss: 0.307448]\n",
      "424 [D loss: 0.564047, op_acc: 60.94%] [G loss: 0.380884]\n",
      "425 [D loss: 0.467911, op_acc: 76.56%] [G loss: 0.362518]\n",
      "426 [D loss: 0.382030, op_acc: 87.50%] [G loss: 0.345241]\n",
      "427 [D loss: 0.366441, op_acc: 84.38%] [G loss: 0.342327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428 [D loss: 0.385368, op_acc: 89.06%] [G loss: 0.361320]\n",
      "429 [D loss: 0.412907, op_acc: 79.69%] [G loss: 0.357937]\n",
      "430 [D loss: 0.447280, op_acc: 76.56%] [G loss: 0.396408]\n",
      "431 [D loss: 0.373880, op_acc: 79.69%] [G loss: 0.377474]\n",
      "432 [D loss: 0.349013, op_acc: 89.06%] [G loss: 0.343092]\n",
      "433 [D loss: 0.493239, op_acc: 81.25%] [G loss: 0.377026]\n",
      "434 [D loss: 0.348400, op_acc: 89.06%] [G loss: 0.377136]\n",
      "435 [D loss: 0.471647, op_acc: 73.44%] [G loss: 0.346729]\n",
      "436 [D loss: 0.422575, op_acc: 75.00%] [G loss: 0.345771]\n",
      "437 [D loss: 0.330769, op_acc: 87.50%] [G loss: 0.350416]\n",
      "438 [D loss: 0.450146, op_acc: 79.69%] [G loss: 0.336176]\n",
      "439 [D loss: 0.444957, op_acc: 76.56%] [G loss: 0.391175]\n",
      "440 [D loss: 0.448035, op_acc: 76.56%] [G loss: 0.374538]\n",
      "441 [D loss: 0.462653, op_acc: 76.56%] [G loss: 0.294840]\n",
      "442 [D loss: 0.439095, op_acc: 81.25%] [G loss: 0.370970]\n",
      "443 [D loss: 0.503340, op_acc: 73.44%] [G loss: 0.334834]\n",
      "444 [D loss: 0.371364, op_acc: 85.94%] [G loss: 0.334781]\n",
      "445 [D loss: 0.557277, op_acc: 67.19%] [G loss: 0.341579]\n",
      "446 [D loss: 0.350337, op_acc: 85.94%] [G loss: 0.353547]\n",
      "447 [D loss: 0.406520, op_acc: 84.38%] [G loss: 0.405329]\n",
      "448 [D loss: 0.440448, op_acc: 78.12%] [G loss: 0.346706]\n",
      "449 [D loss: 0.386213, op_acc: 82.81%] [G loss: 0.303586]\n",
      "450 [D loss: 0.318705, op_acc: 87.50%] [G loss: 0.387423]\n",
      "451 [D loss: 0.382519, op_acc: 89.06%] [G loss: 0.408116]\n",
      "452 [D loss: 0.451334, op_acc: 81.25%] [G loss: 0.326286]\n",
      "453 [D loss: 0.405094, op_acc: 79.69%] [G loss: 0.343497]\n",
      "454 [D loss: 0.390207, op_acc: 84.38%] [G loss: 0.311087]\n",
      "455 [D loss: 0.376406, op_acc: 87.50%] [G loss: 0.397598]\n",
      "456 [D loss: 0.376206, op_acc: 84.38%] [G loss: 0.392148]\n",
      "457 [D loss: 0.390357, op_acc: 84.38%] [G loss: 0.392660]\n",
      "458 [D loss: 0.317524, op_acc: 92.19%] [G loss: 0.400243]\n",
      "459 [D loss: 0.429812, op_acc: 81.25%] [G loss: 0.387011]\n",
      "460 [D loss: 0.433586, op_acc: 79.69%] [G loss: 0.357216]\n",
      "461 [D loss: 0.339590, op_acc: 92.19%] [G loss: 0.357821]\n",
      "462 [D loss: 0.364651, op_acc: 85.94%] [G loss: 0.393405]\n",
      "463 [D loss: 0.484371, op_acc: 73.44%] [G loss: 0.343812]\n",
      "464 [D loss: 0.373307, op_acc: 82.81%] [G loss: 0.296676]\n",
      "465 [D loss: 0.378797, op_acc: 87.50%] [G loss: 0.372799]\n",
      "466 [D loss: 0.397608, op_acc: 85.94%] [G loss: 0.292964]\n",
      "467 [D loss: 0.472905, op_acc: 82.81%] [G loss: 0.310108]\n",
      "468 [D loss: 0.416787, op_acc: 84.38%] [G loss: 0.354465]\n",
      "469 [D loss: 0.346356, op_acc: 85.94%] [G loss: 0.387061]\n",
      "470 [D loss: 0.398837, op_acc: 84.38%] [G loss: 0.337084]\n",
      "471 [D loss: 0.329515, op_acc: 87.50%] [G loss: 0.382395]\n",
      "472 [D loss: 0.411637, op_acc: 87.50%] [G loss: 0.383302]\n",
      "473 [D loss: 0.383602, op_acc: 82.81%] [G loss: 0.336764]\n",
      "474 [D loss: 0.409523, op_acc: 81.25%] [G loss: 0.363274]\n",
      "475 [D loss: 0.445629, op_acc: 76.56%] [G loss: 0.365212]\n",
      "476 [D loss: 0.340318, op_acc: 92.19%] [G loss: 0.365346]\n",
      "477 [D loss: 0.540036, op_acc: 64.06%] [G loss: 0.377053]\n",
      "478 [D loss: 0.380746, op_acc: 82.81%] [G loss: 0.357442]\n",
      "479 [D loss: 0.387639, op_acc: 84.38%] [G loss: 0.363437]\n",
      "480 [D loss: 0.383967, op_acc: 81.25%] [G loss: 0.345033]\n",
      "481 [D loss: 0.416132, op_acc: 81.25%] [G loss: 0.323912]\n",
      "482 [D loss: 0.456476, op_acc: 78.12%] [G loss: 0.352152]\n",
      "483 [D loss: 0.375411, op_acc: 85.94%] [G loss: 0.349275]\n",
      "484 [D loss: 0.402017, op_acc: 75.00%] [G loss: 0.315646]\n",
      "485 [D loss: 0.449755, op_acc: 81.25%] [G loss: 0.355844]\n",
      "486 [D loss: 0.458081, op_acc: 76.56%] [G loss: 0.337520]\n",
      "487 [D loss: 0.494624, op_acc: 76.56%] [G loss: 0.332615]\n",
      "488 [D loss: 0.451095, op_acc: 82.81%] [G loss: 0.330359]\n",
      "489 [D loss: 0.433399, op_acc: 68.75%] [G loss: 0.326623]\n",
      "490 [D loss: 0.332228, op_acc: 87.50%] [G loss: 0.351748]\n",
      "491 [D loss: 0.410344, op_acc: 81.25%] [G loss: 0.365689]\n",
      "492 [D loss: 0.454279, op_acc: 76.56%] [G loss: 0.352180]\n",
      "493 [D loss: 0.416919, op_acc: 76.56%] [G loss: 0.385482]\n",
      "494 [D loss: 0.381196, op_acc: 84.38%] [G loss: 0.363597]\n",
      "495 [D loss: 0.453547, op_acc: 73.44%] [G loss: 0.341921]\n",
      "496 [D loss: 0.376484, op_acc: 85.94%] [G loss: 0.334271]\n",
      "497 [D loss: 0.533615, op_acc: 70.31%] [G loss: 0.316294]\n",
      "498 [D loss: 0.481199, op_acc: 81.25%] [G loss: 0.297691]\n",
      "499 [D loss: 0.371754, op_acc: 82.81%] [G loss: 0.387179]\n",
      "500 [D loss: 0.514763, op_acc: 76.56%] [G loss: 0.346055]\n",
      "501 [D loss: 0.400874, op_acc: 85.94%] [G loss: 0.309514]\n",
      "502 [D loss: 0.426938, op_acc: 75.00%] [G loss: 0.365102]\n",
      "503 [D loss: 0.315714, op_acc: 89.06%] [G loss: 0.333126]\n",
      "504 [D loss: 0.391213, op_acc: 79.69%] [G loss: 0.385915]\n",
      "505 [D loss: 0.476688, op_acc: 79.69%] [G loss: 0.374416]\n",
      "506 [D loss: 0.344954, op_acc: 90.62%] [G loss: 0.290220]\n",
      "507 [D loss: 0.429340, op_acc: 82.81%] [G loss: 0.315328]\n",
      "508 [D loss: 0.310569, op_acc: 90.62%] [G loss: 0.345689]\n",
      "509 [D loss: 0.384210, op_acc: 81.25%] [G loss: 0.338745]\n",
      "510 [D loss: 0.377372, op_acc: 84.38%] [G loss: 0.365349]\n",
      "511 [D loss: 0.391407, op_acc: 84.38%] [G loss: 0.300395]\n",
      "512 [D loss: 0.366762, op_acc: 82.81%] [G loss: 0.328971]\n",
      "513 [D loss: 0.368376, op_acc: 79.69%] [G loss: 0.405111]\n",
      "514 [D loss: 0.361217, op_acc: 87.50%] [G loss: 0.371461]\n",
      "515 [D loss: 0.395873, op_acc: 84.38%] [G loss: 0.364569]\n",
      "516 [D loss: 0.380225, op_acc: 85.94%] [G loss: 0.331958]\n",
      "517 [D loss: 0.284985, op_acc: 95.31%] [G loss: 0.357358]\n",
      "518 [D loss: 0.450877, op_acc: 84.38%] [G loss: 0.356277]\n",
      "519 [D loss: 0.446097, op_acc: 79.69%] [G loss: 0.314323]\n",
      "520 [D loss: 0.509841, op_acc: 70.31%] [G loss: 0.301392]\n",
      "521 [D loss: 0.474193, op_acc: 73.44%] [G loss: 0.357382]\n",
      "522 [D loss: 0.355631, op_acc: 82.81%] [G loss: 0.312215]\n",
      "523 [D loss: 0.453222, op_acc: 79.69%] [G loss: 0.281307]\n",
      "524 [D loss: 0.482843, op_acc: 75.00%] [G loss: 0.367352]\n",
      "525 [D loss: 0.415592, op_acc: 78.12%] [G loss: 0.318638]\n",
      "526 [D loss: 0.469093, op_acc: 75.00%] [G loss: 0.347084]\n",
      "527 [D loss: 0.339725, op_acc: 84.38%] [G loss: 0.316429]\n",
      "528 [D loss: 0.396770, op_acc: 84.38%] [G loss: 0.377938]\n",
      "529 [D loss: 0.376700, op_acc: 84.38%] [G loss: 0.353571]\n",
      "530 [D loss: 0.488767, op_acc: 79.69%] [G loss: 0.347238]\n",
      "531 [D loss: 0.299462, op_acc: 93.75%] [G loss: 0.322638]\n",
      "532 [D loss: 0.302574, op_acc: 87.50%] [G loss: 0.337953]\n",
      "533 [D loss: 0.349414, op_acc: 84.38%] [G loss: 0.361747]\n",
      "534 [D loss: 0.376117, op_acc: 84.38%] [G loss: 0.371671]\n",
      "535 [D loss: 0.407540, op_acc: 81.25%] [G loss: 0.308939]\n",
      "536 [D loss: 0.394936, op_acc: 79.69%] [G loss: 0.320971]\n",
      "537 [D loss: 0.326307, op_acc: 87.50%] [G loss: 0.341650]\n",
      "538 [D loss: 0.397312, op_acc: 82.81%] [G loss: 0.351396]\n",
      "539 [D loss: 0.383085, op_acc: 82.81%] [G loss: 0.335467]\n",
      "540 [D loss: 0.377497, op_acc: 85.94%] [G loss: 0.355078]\n",
      "541 [D loss: 0.367975, op_acc: 82.81%] [G loss: 0.366495]\n",
      "542 [D loss: 0.380424, op_acc: 79.69%] [G loss: 0.335113]\n",
      "543 [D loss: 0.344390, op_acc: 81.25%] [G loss: 0.317428]\n",
      "544 [D loss: 0.371770, op_acc: 82.81%] [G loss: 0.327988]\n",
      "545 [D loss: 0.333371, op_acc: 85.94%] [G loss: 0.348956]\n",
      "546 [D loss: 0.371340, op_acc: 87.50%] [G loss: 0.346883]\n",
      "547 [D loss: 0.426863, op_acc: 79.69%] [G loss: 0.364827]\n",
      "548 [D loss: 0.353506, op_acc: 87.50%] [G loss: 0.340306]\n",
      "549 [D loss: 0.424087, op_acc: 78.12%] [G loss: 0.339251]\n",
      "550 [D loss: 0.531543, op_acc: 75.00%] [G loss: 0.354713]\n",
      "551 [D loss: 0.460938, op_acc: 76.56%] [G loss: 0.295276]\n",
      "552 [D loss: 0.403286, op_acc: 76.56%] [G loss: 0.341974]\n",
      "553 [D loss: 0.384030, op_acc: 84.38%] [G loss: 0.356535]\n",
      "554 [D loss: 0.362298, op_acc: 82.81%] [G loss: 0.372083]\n",
      "555 [D loss: 0.399581, op_acc: 84.38%] [G loss: 0.325390]\n",
      "556 [D loss: 0.358021, op_acc: 89.06%] [G loss: 0.313253]\n",
      "557 [D loss: 0.344325, op_acc: 87.50%] [G loss: 0.327647]\n",
      "558 [D loss: 0.391782, op_acc: 76.56%] [G loss: 0.365810]\n",
      "559 [D loss: 0.310039, op_acc: 90.62%] [G loss: 0.347857]\n",
      "560 [D loss: 0.344958, op_acc: 84.38%] [G loss: 0.332337]\n",
      "561 [D loss: 0.303898, op_acc: 92.19%] [G loss: 0.361794]\n",
      "562 [D loss: 0.256145, op_acc: 95.31%] [G loss: 0.342466]\n",
      "563 [D loss: 0.371491, op_acc: 84.38%] [G loss: 0.329656]\n",
      "564 [D loss: 0.428933, op_acc: 82.81%] [G loss: 0.398503]\n",
      "565 [D loss: 0.379109, op_acc: 82.81%] [G loss: 0.311827]\n",
      "566 [D loss: 0.312306, op_acc: 92.19%] [G loss: 0.334444]\n",
      "567 [D loss: 0.407668, op_acc: 81.25%] [G loss: 0.362080]\n",
      "568 [D loss: 0.319785, op_acc: 90.62%] [G loss: 0.339080]\n",
      "569 [D loss: 0.419041, op_acc: 81.25%] [G loss: 0.341344]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570 [D loss: 0.419237, op_acc: 76.56%] [G loss: 0.371504]\n",
      "571 [D loss: 0.463718, op_acc: 82.81%] [G loss: 0.327895]\n",
      "572 [D loss: 0.420543, op_acc: 84.38%] [G loss: 0.367606]\n",
      "573 [D loss: 0.429042, op_acc: 81.25%] [G loss: 0.378522]\n",
      "574 [D loss: 0.311504, op_acc: 95.31%] [G loss: 0.359273]\n",
      "575 [D loss: 0.407380, op_acc: 82.81%] [G loss: 0.301345]\n",
      "576 [D loss: 0.354230, op_acc: 84.38%] [G loss: 0.324064]\n",
      "577 [D loss: 0.360825, op_acc: 85.94%] [G loss: 0.347558]\n",
      "578 [D loss: 0.420466, op_acc: 81.25%] [G loss: 0.356771]\n",
      "579 [D loss: 0.346693, op_acc: 85.94%] [G loss: 0.315554]\n",
      "580 [D loss: 0.446649, op_acc: 79.69%] [G loss: 0.297146]\n",
      "581 [D loss: 0.382430, op_acc: 81.25%] [G loss: 0.352832]\n",
      "582 [D loss: 0.456333, op_acc: 76.56%] [G loss: 0.378993]\n",
      "583 [D loss: 0.399171, op_acc: 79.69%] [G loss: 0.336598]\n",
      "584 [D loss: 0.439979, op_acc: 76.56%] [G loss: 0.305463]\n",
      "585 [D loss: 0.345398, op_acc: 82.81%] [G loss: 0.313305]\n",
      "586 [D loss: 0.454225, op_acc: 73.44%] [G loss: 0.342131]\n",
      "587 [D loss: 0.436855, op_acc: 84.38%] [G loss: 0.328981]\n",
      "588 [D loss: 0.480565, op_acc: 75.00%] [G loss: 0.322593]\n",
      "589 [D loss: 0.321580, op_acc: 85.94%] [G loss: 0.360773]\n",
      "590 [D loss: 0.323283, op_acc: 92.19%] [G loss: 0.346002]\n",
      "591 [D loss: 0.406033, op_acc: 81.25%] [G loss: 0.352327]\n",
      "592 [D loss: 0.376674, op_acc: 84.38%] [G loss: 0.315810]\n",
      "593 [D loss: 0.438736, op_acc: 78.12%] [G loss: 0.349028]\n",
      "594 [D loss: 0.341235, op_acc: 85.94%] [G loss: 0.398717]\n",
      "595 [D loss: 0.432796, op_acc: 87.50%] [G loss: 0.371683]\n",
      "596 [D loss: 0.290053, op_acc: 92.19%] [G loss: 0.346340]\n",
      "597 [D loss: 0.373090, op_acc: 85.94%] [G loss: 0.329811]\n",
      "598 [D loss: 0.347828, op_acc: 85.94%] [G loss: 0.360430]\n",
      "599 [D loss: 0.392494, op_acc: 82.81%] [G loss: 0.349153]\n",
      "600 [D loss: 0.360105, op_acc: 90.62%] [G loss: 0.312961]\n",
      "601 [D loss: 0.290007, op_acc: 90.62%] [G loss: 0.351927]\n",
      "602 [D loss: 0.353045, op_acc: 85.94%] [G loss: 0.377839]\n",
      "603 [D loss: 0.389429, op_acc: 81.25%] [G loss: 0.334630]\n",
      "604 [D loss: 0.365872, op_acc: 87.50%] [G loss: 0.323213]\n",
      "605 [D loss: 0.435611, op_acc: 84.38%] [G loss: 0.353380]\n",
      "606 [D loss: 0.406838, op_acc: 82.81%] [G loss: 0.307466]\n",
      "607 [D loss: 0.364890, op_acc: 89.06%] [G loss: 0.310910]\n",
      "608 [D loss: 0.398701, op_acc: 78.12%] [G loss: 0.371838]\n",
      "609 [D loss: 0.363308, op_acc: 89.06%] [G loss: 0.333356]\n",
      "610 [D loss: 0.357832, op_acc: 89.06%] [G loss: 0.332875]\n",
      "611 [D loss: 0.339228, op_acc: 81.25%] [G loss: 0.352969]\n",
      "612 [D loss: 0.365360, op_acc: 84.38%] [G loss: 0.385193]\n",
      "613 [D loss: 0.317429, op_acc: 87.50%] [G loss: 0.302280]\n",
      "614 [D loss: 0.442262, op_acc: 78.12%] [G loss: 0.347185]\n",
      "615 [D loss: 0.355084, op_acc: 82.81%] [G loss: 0.344549]\n",
      "616 [D loss: 0.370860, op_acc: 90.62%] [G loss: 0.340397]\n",
      "617 [D loss: 0.399632, op_acc: 85.94%] [G loss: 0.329514]\n",
      "618 [D loss: 0.350258, op_acc: 89.06%] [G loss: 0.350767]\n",
      "619 [D loss: 0.369954, op_acc: 87.50%] [G loss: 0.353088]\n",
      "620 [D loss: 0.409368, op_acc: 82.81%] [G loss: 0.352283]\n",
      "621 [D loss: 0.312420, op_acc: 90.62%] [G loss: 0.333290]\n",
      "622 [D loss: 0.443974, op_acc: 73.44%] [G loss: 0.354558]\n",
      "623 [D loss: 0.341855, op_acc: 85.94%] [G loss: 0.289257]\n",
      "624 [D loss: 0.311940, op_acc: 87.50%] [G loss: 0.344105]\n",
      "625 [D loss: 0.398836, op_acc: 84.38%] [G loss: 0.336809]\n",
      "626 [D loss: 0.391434, op_acc: 82.81%] [G loss: 0.346397]\n",
      "627 [D loss: 0.307901, op_acc: 95.31%] [G loss: 0.322148]\n",
      "628 [D loss: 0.421314, op_acc: 82.81%] [G loss: 0.343590]\n",
      "629 [D loss: 0.330353, op_acc: 84.38%] [G loss: 0.365240]\n",
      "630 [D loss: 0.399932, op_acc: 79.69%] [G loss: 0.369659]\n",
      "631 [D loss: 0.350562, op_acc: 85.94%] [G loss: 0.369344]\n",
      "632 [D loss: 0.334940, op_acc: 89.06%] [G loss: 0.373337]\n",
      "633 [D loss: 0.318871, op_acc: 89.06%] [G loss: 0.332173]\n",
      "634 [D loss: 0.380887, op_acc: 84.38%] [G loss: 0.329515]\n",
      "635 [D loss: 0.360270, op_acc: 82.81%] [G loss: 0.330092]\n",
      "636 [D loss: 0.441376, op_acc: 78.12%] [G loss: 0.338070]\n",
      "637 [D loss: 0.402716, op_acc: 84.38%] [G loss: 0.365106]\n",
      "638 [D loss: 0.401290, op_acc: 85.94%] [G loss: 0.347406]\n",
      "639 [D loss: 0.467630, op_acc: 75.00%] [G loss: 0.336312]\n",
      "640 [D loss: 0.351415, op_acc: 85.94%] [G loss: 0.294474]\n",
      "641 [D loss: 0.420002, op_acc: 84.38%] [G loss: 0.342541]\n",
      "642 [D loss: 0.339726, op_acc: 90.62%] [G loss: 0.351949]\n",
      "643 [D loss: 0.449429, op_acc: 78.12%] [G loss: 0.337068]\n",
      "644 [D loss: 0.447052, op_acc: 79.69%] [G loss: 0.332624]\n",
      "645 [D loss: 0.378045, op_acc: 84.38%] [G loss: 0.290801]\n",
      "646 [D loss: 0.408895, op_acc: 81.25%] [G loss: 0.305017]\n",
      "647 [D loss: 0.343749, op_acc: 92.19%] [G loss: 0.337556]\n",
      "648 [D loss: 0.432768, op_acc: 76.56%] [G loss: 0.358072]\n",
      "649 [D loss: 0.323775, op_acc: 89.06%] [G loss: 0.311450]\n",
      "650 [D loss: 0.377754, op_acc: 82.81%] [G loss: 0.357811]\n",
      "651 [D loss: 0.408135, op_acc: 78.12%] [G loss: 0.399753]\n",
      "652 [D loss: 0.271050, op_acc: 90.62%] [G loss: 0.324219]\n",
      "653 [D loss: 0.394572, op_acc: 82.81%] [G loss: 0.348806]\n",
      "654 [D loss: 0.435158, op_acc: 79.69%] [G loss: 0.334298]\n",
      "655 [D loss: 0.313880, op_acc: 85.94%] [G loss: 0.289883]\n",
      "656 [D loss: 0.388056, op_acc: 85.94%] [G loss: 0.329930]\n",
      "657 [D loss: 0.369724, op_acc: 82.81%] [G loss: 0.333557]\n",
      "658 [D loss: 0.427716, op_acc: 79.69%] [G loss: 0.364168]\n",
      "659 [D loss: 0.366998, op_acc: 89.06%] [G loss: 0.304302]\n",
      "660 [D loss: 0.416064, op_acc: 71.88%] [G loss: 0.365921]\n",
      "661 [D loss: 0.315621, op_acc: 87.50%] [G loss: 0.343354]\n",
      "662 [D loss: 0.324417, op_acc: 85.94%] [G loss: 0.356937]\n",
      "663 [D loss: 0.321671, op_acc: 84.38%] [G loss: 0.339276]\n",
      "664 [D loss: 0.453299, op_acc: 81.25%] [G loss: 0.315366]\n",
      "665 [D loss: 0.417464, op_acc: 78.12%] [G loss: 0.326134]\n",
      "666 [D loss: 0.402798, op_acc: 82.81%] [G loss: 0.352419]\n",
      "667 [D loss: 0.360124, op_acc: 85.94%] [G loss: 0.343244]\n",
      "668 [D loss: 0.399001, op_acc: 87.50%] [G loss: 0.323484]\n",
      "669 [D loss: 0.368029, op_acc: 85.94%] [G loss: 0.340254]\n",
      "670 [D loss: 0.436648, op_acc: 78.12%] [G loss: 0.312807]\n",
      "671 [D loss: 0.424752, op_acc: 85.94%] [G loss: 0.356219]\n",
      "672 [D loss: 0.346444, op_acc: 92.19%] [G loss: 0.380849]\n",
      "673 [D loss: 0.404648, op_acc: 84.38%] [G loss: 0.399546]\n",
      "674 [D loss: 0.302490, op_acc: 93.75%] [G loss: 0.301580]\n",
      "675 [D loss: 0.340512, op_acc: 84.38%] [G loss: 0.298148]\n",
      "676 [D loss: 0.298459, op_acc: 85.94%] [G loss: 0.347759]\n",
      "677 [D loss: 0.360603, op_acc: 87.50%] [G loss: 0.358540]\n",
      "678 [D loss: 0.396844, op_acc: 82.81%] [G loss: 0.338645]\n",
      "679 [D loss: 0.273199, op_acc: 90.62%] [G loss: 0.335417]\n",
      "680 [D loss: 0.397638, op_acc: 82.81%] [G loss: 0.352050]\n",
      "681 [D loss: 0.366234, op_acc: 82.81%] [G loss: 0.334847]\n",
      "682 [D loss: 0.334604, op_acc: 92.19%] [G loss: 0.368380]\n",
      "683 [D loss: 0.416563, op_acc: 78.12%] [G loss: 0.341741]\n",
      "684 [D loss: 0.307104, op_acc: 87.50%] [G loss: 0.331162]\n",
      "685 [D loss: 0.392481, op_acc: 79.69%] [G loss: 0.350693]\n",
      "686 [D loss: 0.360949, op_acc: 79.69%] [G loss: 0.307017]\n",
      "687 [D loss: 0.373451, op_acc: 87.50%] [G loss: 0.308473]\n",
      "688 [D loss: 0.416952, op_acc: 81.25%] [G loss: 0.326058]\n",
      "689 [D loss: 0.434022, op_acc: 76.56%] [G loss: 0.346435]\n",
      "690 [D loss: 0.440471, op_acc: 81.25%] [G loss: 0.330213]\n",
      "691 [D loss: 0.399988, op_acc: 85.94%] [G loss: 0.305410]\n",
      "692 [D loss: 0.324253, op_acc: 90.62%] [G loss: 0.324875]\n",
      "693 [D loss: 0.421378, op_acc: 71.88%] [G loss: 0.324937]\n",
      "694 [D loss: 0.370621, op_acc: 89.06%] [G loss: 0.341015]\n",
      "695 [D loss: 0.382344, op_acc: 87.50%] [G loss: 0.343640]\n",
      "696 [D loss: 0.412410, op_acc: 78.12%] [G loss: 0.391133]\n",
      "697 [D loss: 0.449327, op_acc: 81.25%] [G loss: 0.355781]\n",
      "698 [D loss: 0.360772, op_acc: 85.94%] [G loss: 0.309488]\n",
      "699 [D loss: 0.237392, op_acc: 98.44%] [G loss: 0.314697]\n",
      "700 [D loss: 0.409506, op_acc: 81.25%] [G loss: 0.352059]\n",
      "701 [D loss: 0.322459, op_acc: 92.19%] [G loss: 0.317709]\n",
      "702 [D loss: 0.363509, op_acc: 81.25%] [G loss: 0.330181]\n",
      "703 [D loss: 0.436216, op_acc: 73.44%] [G loss: 0.344096]\n",
      "704 [D loss: 0.330608, op_acc: 87.50%] [G loss: 0.320525]\n",
      "705 [D loss: 0.350964, op_acc: 82.81%] [G loss: 0.316472]\n",
      "706 [D loss: 0.389659, op_acc: 76.56%] [G loss: 0.311057]\n",
      "707 [D loss: 0.435919, op_acc: 76.56%] [G loss: 0.345472]\n",
      "708 [D loss: 0.377710, op_acc: 84.38%] [G loss: 0.323938]\n",
      "709 [D loss: 0.356466, op_acc: 87.50%] [G loss: 0.299732]\n",
      "710 [D loss: 0.418766, op_acc: 82.81%] [G loss: 0.320234]\n",
      "711 [D loss: 0.351881, op_acc: 82.81%] [G loss: 0.325384]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712 [D loss: 0.390970, op_acc: 81.25%] [G loss: 0.309487]\n",
      "713 [D loss: 0.426624, op_acc: 81.25%] [G loss: 0.350085]\n",
      "714 [D loss: 0.334272, op_acc: 89.06%] [G loss: 0.329459]\n",
      "715 [D loss: 0.406388, op_acc: 85.94%] [G loss: 0.357799]\n",
      "716 [D loss: 0.317319, op_acc: 87.50%] [G loss: 0.363737]\n",
      "717 [D loss: 0.333738, op_acc: 89.06%] [G loss: 0.327116]\n",
      "718 [D loss: 0.267913, op_acc: 93.75%] [G loss: 0.335252]\n",
      "719 [D loss: 0.271004, op_acc: 93.75%] [G loss: 0.363568]\n",
      "720 [D loss: 0.345810, op_acc: 85.94%] [G loss: 0.335959]\n",
      "721 [D loss: 0.404103, op_acc: 79.69%] [G loss: 0.312357]\n",
      "722 [D loss: 0.353455, op_acc: 81.25%] [G loss: 0.333791]\n",
      "723 [D loss: 0.341444, op_acc: 89.06%] [G loss: 0.320295]\n",
      "724 [D loss: 0.388035, op_acc: 81.25%] [G loss: 0.375857]\n",
      "725 [D loss: 0.438845, op_acc: 81.25%] [G loss: 0.297488]\n",
      "726 [D loss: 0.352249, op_acc: 87.50%] [G loss: 0.338629]\n",
      "727 [D loss: 0.276190, op_acc: 90.62%] [G loss: 0.322765]\n",
      "728 [D loss: 0.396304, op_acc: 79.69%] [G loss: 0.340408]\n",
      "729 [D loss: 0.335331, op_acc: 90.62%] [G loss: 0.334907]\n",
      "730 [D loss: 0.376210, op_acc: 84.38%] [G loss: 0.342070]\n",
      "731 [D loss: 0.344741, op_acc: 87.50%] [G loss: 0.340469]\n",
      "732 [D loss: 0.354205, op_acc: 79.69%] [G loss: 0.330403]\n",
      "733 [D loss: 0.284243, op_acc: 92.19%] [G loss: 0.308809]\n",
      "734 [D loss: 0.407551, op_acc: 76.56%] [G loss: 0.361830]\n",
      "735 [D loss: 0.393296, op_acc: 87.50%] [G loss: 0.326067]\n",
      "736 [D loss: 0.344958, op_acc: 85.94%] [G loss: 0.317509]\n",
      "737 [D loss: 0.332771, op_acc: 85.94%] [G loss: 0.342370]\n",
      "738 [D loss: 0.369089, op_acc: 84.38%] [G loss: 0.328528]\n",
      "739 [D loss: 0.415830, op_acc: 78.12%] [G loss: 0.337679]\n",
      "740 [D loss: 0.429805, op_acc: 75.00%] [G loss: 0.328208]\n",
      "741 [D loss: 0.295165, op_acc: 89.06%] [G loss: 0.334136]\n",
      "742 [D loss: 0.346330, op_acc: 89.06%] [G loss: 0.339850]\n",
      "743 [D loss: 0.447640, op_acc: 79.69%] [G loss: 0.338809]\n",
      "744 [D loss: 0.294500, op_acc: 89.06%] [G loss: 0.323436]\n",
      "745 [D loss: 0.367754, op_acc: 87.50%] [G loss: 0.357079]\n",
      "746 [D loss: 0.460686, op_acc: 81.25%] [G loss: 0.326758]\n",
      "747 [D loss: 0.353425, op_acc: 85.94%] [G loss: 0.320193]\n",
      "748 [D loss: 0.397882, op_acc: 82.81%] [G loss: 0.317712]\n",
      "749 [D loss: 0.366772, op_acc: 79.69%] [G loss: 0.308851]\n",
      "750 [D loss: 0.343378, op_acc: 82.81%] [G loss: 0.312890]\n",
      "751 [D loss: 0.413098, op_acc: 78.12%] [G loss: 0.336658]\n",
      "752 [D loss: 0.435775, op_acc: 79.69%] [G loss: 0.316376]\n",
      "753 [D loss: 0.420073, op_acc: 79.69%] [G loss: 0.327303]\n",
      "754 [D loss: 0.323426, op_acc: 87.50%] [G loss: 0.302591]\n",
      "755 [D loss: 0.378171, op_acc: 76.56%] [G loss: 0.318793]\n",
      "756 [D loss: 0.369195, op_acc: 84.38%] [G loss: 0.355402]\n",
      "757 [D loss: 0.364354, op_acc: 81.25%] [G loss: 0.356424]\n",
      "758 [D loss: 0.330935, op_acc: 89.06%] [G loss: 0.316734]\n",
      "759 [D loss: 0.417197, op_acc: 85.94%] [G loss: 0.359700]\n",
      "760 [D loss: 0.298595, op_acc: 89.06%] [G loss: 0.330859]\n",
      "761 [D loss: 0.343435, op_acc: 92.19%] [G loss: 0.332503]\n",
      "762 [D loss: 0.397702, op_acc: 81.25%] [G loss: 0.344387]\n",
      "763 [D loss: 0.353052, op_acc: 84.38%] [G loss: 0.319024]\n",
      "764 [D loss: 0.364342, op_acc: 82.81%] [G loss: 0.276163]\n",
      "765 [D loss: 0.316812, op_acc: 89.06%] [G loss: 0.343325]\n",
      "766 [D loss: 0.298058, op_acc: 92.19%] [G loss: 0.349863]\n",
      "767 [D loss: 0.350813, op_acc: 87.50%] [G loss: 0.352667]\n",
      "768 [D loss: 0.295224, op_acc: 92.19%] [G loss: 0.340616]\n",
      "769 [D loss: 0.401259, op_acc: 84.38%] [G loss: 0.340203]\n",
      "770 [D loss: 0.349385, op_acc: 84.38%] [G loss: 0.324927]\n",
      "771 [D loss: 0.320124, op_acc: 82.81%] [G loss: 0.339346]\n",
      "772 [D loss: 0.495606, op_acc: 85.94%] [G loss: 0.367241]\n",
      "773 [D loss: 0.345611, op_acc: 85.94%] [G loss: 0.326900]\n",
      "774 [D loss: 0.377623, op_acc: 78.12%] [G loss: 0.339332]\n",
      "775 [D loss: 0.346994, op_acc: 82.81%] [G loss: 0.332419]\n",
      "776 [D loss: 0.464467, op_acc: 75.00%] [G loss: 0.349665]\n",
      "777 [D loss: 0.310803, op_acc: 87.50%] [G loss: 0.365118]\n",
      "778 [D loss: 0.389457, op_acc: 81.25%] [G loss: 0.322279]\n",
      "779 [D loss: 0.310679, op_acc: 85.94%] [G loss: 0.344997]\n",
      "780 [D loss: 0.499769, op_acc: 73.44%] [G loss: 0.335116]\n",
      "781 [D loss: 0.307301, op_acc: 92.19%] [G loss: 0.354969]\n",
      "782 [D loss: 0.393358, op_acc: 85.94%] [G loss: 0.326505]\n",
      "783 [D loss: 0.403835, op_acc: 75.00%] [G loss: 0.331146]\n",
      "784 [D loss: 0.305395, op_acc: 93.75%] [G loss: 0.330124]\n",
      "785 [D loss: 0.276843, op_acc: 90.62%] [G loss: 0.359090]\n",
      "786 [D loss: 0.352777, op_acc: 89.06%] [G loss: 0.352671]\n",
      "787 [D loss: 0.373830, op_acc: 78.12%] [G loss: 0.333374]\n",
      "788 [D loss: 0.377001, op_acc: 79.69%] [G loss: 0.325637]\n",
      "789 [D loss: 0.429633, op_acc: 78.12%] [G loss: 0.325263]\n",
      "790 [D loss: 0.409185, op_acc: 78.12%] [G loss: 0.333887]\n",
      "791 [D loss: 0.390513, op_acc: 81.25%] [G loss: 0.334554]\n",
      "792 [D loss: 0.552955, op_acc: 68.75%] [G loss: 0.329891]\n",
      "793 [D loss: 0.388167, op_acc: 78.12%] [G loss: 0.317385]\n",
      "794 [D loss: 0.287907, op_acc: 89.06%] [G loss: 0.317583]\n",
      "795 [D loss: 0.396799, op_acc: 76.56%] [G loss: 0.356561]\n",
      "796 [D loss: 0.321521, op_acc: 89.06%] [G loss: 0.342579]\n",
      "797 [D loss: 0.291051, op_acc: 89.06%] [G loss: 0.351512]\n",
      "798 [D loss: 0.429627, op_acc: 82.81%] [G loss: 0.333913]\n",
      "799 [D loss: 0.370092, op_acc: 84.38%] [G loss: 0.360397]\n",
      "800 [D loss: 0.371519, op_acc: 84.38%] [G loss: 0.397548]\n",
      "801 [D loss: 0.371111, op_acc: 81.25%] [G loss: 0.355851]\n",
      "802 [D loss: 0.373458, op_acc: 84.38%] [G loss: 0.319765]\n",
      "803 [D loss: 0.432334, op_acc: 76.56%] [G loss: 0.353226]\n",
      "804 [D loss: 0.381498, op_acc: 76.56%] [G loss: 0.302356]\n",
      "805 [D loss: 0.415344, op_acc: 84.38%] [G loss: 0.316820]\n",
      "806 [D loss: 0.350840, op_acc: 85.94%] [G loss: 0.294793]\n",
      "807 [D loss: 0.360859, op_acc: 85.94%] [G loss: 0.310585]\n",
      "808 [D loss: 0.390647, op_acc: 79.69%] [G loss: 0.317667]\n",
      "809 [D loss: 0.385281, op_acc: 82.81%] [G loss: 0.375990]\n",
      "810 [D loss: 0.393764, op_acc: 78.12%] [G loss: 0.352438]\n",
      "811 [D loss: 0.405473, op_acc: 79.69%] [G loss: 0.318686]\n",
      "812 [D loss: 0.387029, op_acc: 82.81%] [G loss: 0.297096]\n",
      "813 [D loss: 0.417286, op_acc: 79.69%] [G loss: 0.357620]\n",
      "814 [D loss: 0.415716, op_acc: 78.12%] [G loss: 0.344996]\n",
      "815 [D loss: 0.307330, op_acc: 90.62%] [G loss: 0.304700]\n",
      "816 [D loss: 0.433867, op_acc: 85.94%] [G loss: 0.348594]\n",
      "817 [D loss: 0.352659, op_acc: 87.50%] [G loss: 0.355791]\n",
      "818 [D loss: 0.309227, op_acc: 92.19%] [G loss: 0.352057]\n",
      "819 [D loss: 0.379350, op_acc: 79.69%] [G loss: 0.331955]\n",
      "820 [D loss: 0.354822, op_acc: 79.69%] [G loss: 0.297853]\n",
      "821 [D loss: 0.311926, op_acc: 89.06%] [G loss: 0.353347]\n",
      "822 [D loss: 0.367747, op_acc: 81.25%] [G loss: 0.365359]\n",
      "823 [D loss: 0.331397, op_acc: 89.06%] [G loss: 0.324980]\n",
      "824 [D loss: 0.358774, op_acc: 87.50%] [G loss: 0.341734]\n",
      "825 [D loss: 0.338078, op_acc: 87.50%] [G loss: 0.328525]\n",
      "826 [D loss: 0.341008, op_acc: 85.94%] [G loss: 0.329379]\n",
      "827 [D loss: 0.402291, op_acc: 84.38%] [G loss: 0.364495]\n",
      "828 [D loss: 0.316589, op_acc: 90.62%] [G loss: 0.331405]\n",
      "829 [D loss: 0.440596, op_acc: 76.56%] [G loss: 0.324594]\n",
      "830 [D loss: 0.322745, op_acc: 84.38%] [G loss: 0.337589]\n",
      "831 [D loss: 0.340952, op_acc: 84.38%] [G loss: 0.317638]\n",
      "832 [D loss: 0.312577, op_acc: 90.62%] [G loss: 0.336641]\n",
      "833 [D loss: 0.348549, op_acc: 85.94%] [G loss: 0.370720]\n",
      "834 [D loss: 0.295691, op_acc: 87.50%] [G loss: 0.354720]\n",
      "835 [D loss: 0.331599, op_acc: 90.62%] [G loss: 0.359649]\n",
      "836 [D loss: 0.333238, op_acc: 85.94%] [G loss: 0.344356]\n",
      "837 [D loss: 0.359319, op_acc: 87.50%] [G loss: 0.301067]\n",
      "838 [D loss: 0.403226, op_acc: 84.38%] [G loss: 0.334704]\n",
      "839 [D loss: 0.352397, op_acc: 84.38%] [G loss: 0.335870]\n",
      "840 [D loss: 0.347940, op_acc: 85.94%] [G loss: 0.336267]\n",
      "841 [D loss: 0.410801, op_acc: 81.25%] [G loss: 0.339982]\n",
      "842 [D loss: 0.409895, op_acc: 82.81%] [G loss: 0.349356]\n",
      "843 [D loss: 0.339120, op_acc: 84.38%] [G loss: 0.360455]\n",
      "844 [D loss: 0.326173, op_acc: 87.50%] [G loss: 0.369544]\n",
      "845 [D loss: 0.305883, op_acc: 87.50%] [G loss: 0.342703]\n",
      "846 [D loss: 0.394566, op_acc: 76.56%] [G loss: 0.365158]\n",
      "847 [D loss: 0.331939, op_acc: 90.62%] [G loss: 0.346499]\n",
      "848 [D loss: 0.333879, op_acc: 89.06%] [G loss: 0.338029]\n",
      "849 [D loss: 0.381633, op_acc: 82.81%] [G loss: 0.359314]\n",
      "850 [D loss: 0.365831, op_acc: 84.38%] [G loss: 0.361347]\n",
      "851 [D loss: 0.311878, op_acc: 87.50%] [G loss: 0.331186]\n",
      "852 [D loss: 0.285492, op_acc: 93.75%] [G loss: 0.331047]\n",
      "853 [D loss: 0.345245, op_acc: 84.38%] [G loss: 0.370415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "854 [D loss: 0.292148, op_acc: 93.75%] [G loss: 0.317868]\n",
      "855 [D loss: 0.407934, op_acc: 81.25%] [G loss: 0.334060]\n",
      "856 [D loss: 0.311047, op_acc: 89.06%] [G loss: 0.332444]\n",
      "857 [D loss: 0.435412, op_acc: 81.25%] [G loss: 0.298812]\n",
      "858 [D loss: 0.480603, op_acc: 73.44%] [G loss: 0.339033]\n",
      "859 [D loss: 0.344647, op_acc: 84.38%] [G loss: 0.340912]\n",
      "860 [D loss: 0.368446, op_acc: 85.94%] [G loss: 0.338781]\n",
      "861 [D loss: 0.430444, op_acc: 78.12%] [G loss: 0.316930]\n",
      "862 [D loss: 0.464887, op_acc: 78.12%] [G loss: 0.353835]\n",
      "863 [D loss: 0.372987, op_acc: 79.69%] [G loss: 0.334446]\n",
      "864 [D loss: 0.338984, op_acc: 84.38%] [G loss: 0.372750]\n",
      "865 [D loss: 0.330809, op_acc: 85.94%] [G loss: 0.397696]\n",
      "866 [D loss: 0.404198, op_acc: 79.69%] [G loss: 0.353364]\n",
      "867 [D loss: 0.422009, op_acc: 79.69%] [G loss: 0.345532]\n",
      "868 [D loss: 0.444327, op_acc: 75.00%] [G loss: 0.369440]\n",
      "869 [D loss: 0.395462, op_acc: 82.81%] [G loss: 0.359474]\n",
      "870 [D loss: 0.317486, op_acc: 89.06%] [G loss: 0.367290]\n",
      "871 [D loss: 0.294447, op_acc: 92.19%] [G loss: 0.328304]\n",
      "872 [D loss: 0.385313, op_acc: 81.25%] [G loss: 0.324496]\n",
      "873 [D loss: 0.368274, op_acc: 87.50%] [G loss: 0.342052]\n",
      "874 [D loss: 0.438778, op_acc: 78.12%] [G loss: 0.294854]\n",
      "875 [D loss: 0.486419, op_acc: 67.19%] [G loss: 0.370875]\n",
      "876 [D loss: 0.455572, op_acc: 76.56%] [G loss: 0.310638]\n",
      "877 [D loss: 0.394805, op_acc: 76.56%] [G loss: 0.333503]\n",
      "878 [D loss: 0.338062, op_acc: 92.19%] [G loss: 0.334648]\n",
      "879 [D loss: 0.361592, op_acc: 84.38%] [G loss: 0.334712]\n",
      "880 [D loss: 0.434367, op_acc: 79.69%] [G loss: 0.324228]\n",
      "881 [D loss: 0.355024, op_acc: 90.62%] [G loss: 0.344161]\n",
      "882 [D loss: 0.410799, op_acc: 79.69%] [G loss: 0.375049]\n",
      "883 [D loss: 0.336452, op_acc: 85.94%] [G loss: 0.370536]\n",
      "884 [D loss: 0.311442, op_acc: 92.19%] [G loss: 0.368016]\n",
      "885 [D loss: 0.281115, op_acc: 93.75%] [G loss: 0.347503]\n",
      "886 [D loss: 0.348993, op_acc: 82.81%] [G loss: 0.373475]\n",
      "887 [D loss: 0.309201, op_acc: 90.62%] [G loss: 0.338608]\n",
      "888 [D loss: 0.400964, op_acc: 78.12%] [G loss: 0.354156]\n",
      "889 [D loss: 0.383742, op_acc: 84.38%] [G loss: 0.312771]\n",
      "890 [D loss: 0.402402, op_acc: 85.94%] [G loss: 0.353825]\n",
      "891 [D loss: 0.370923, op_acc: 84.38%] [G loss: 0.361130]\n",
      "892 [D loss: 0.376668, op_acc: 84.38%] [G loss: 0.311657]\n",
      "893 [D loss: 0.383300, op_acc: 79.69%] [G loss: 0.327763]\n",
      "894 [D loss: 0.475973, op_acc: 76.56%] [G loss: 0.316292]\n",
      "895 [D loss: 0.479715, op_acc: 71.88%] [G loss: 0.335752]\n",
      "896 [D loss: 0.458234, op_acc: 71.88%] [G loss: 0.307435]\n",
      "897 [D loss: 0.459821, op_acc: 71.88%] [G loss: 0.300846]\n",
      "898 [D loss: 0.440475, op_acc: 71.88%] [G loss: 0.313289]\n",
      "899 [D loss: 0.355178, op_acc: 82.81%] [G loss: 0.342996]\n",
      "900 [D loss: 0.306790, op_acc: 90.62%] [G loss: 0.327074]\n",
      "901 [D loss: 0.343716, op_acc: 81.25%] [G loss: 0.327259]\n",
      "902 [D loss: 0.391818, op_acc: 79.69%] [G loss: 0.325619]\n",
      "903 [D loss: 0.340213, op_acc: 84.38%] [G loss: 0.331995]\n",
      "904 [D loss: 0.380776, op_acc: 87.50%] [G loss: 0.334765]\n",
      "905 [D loss: 0.323120, op_acc: 92.19%] [G loss: 0.315619]\n",
      "906 [D loss: 0.340575, op_acc: 84.38%] [G loss: 0.349782]\n",
      "907 [D loss: 0.466182, op_acc: 68.75%] [G loss: 0.324260]\n",
      "908 [D loss: 0.321212, op_acc: 92.19%] [G loss: 0.342075]\n",
      "909 [D loss: 0.428528, op_acc: 78.12%] [G loss: 0.350995]\n",
      "910 [D loss: 0.275061, op_acc: 92.19%] [G loss: 0.321718]\n",
      "911 [D loss: 0.364713, op_acc: 81.25%] [G loss: 0.355801]\n",
      "912 [D loss: 0.378788, op_acc: 78.12%] [G loss: 0.300608]\n",
      "913 [D loss: 0.306617, op_acc: 87.50%] [G loss: 0.289856]\n",
      "914 [D loss: 0.486838, op_acc: 73.44%] [G loss: 0.381140]\n",
      "915 [D loss: 0.496231, op_acc: 67.19%] [G loss: 0.337187]\n",
      "916 [D loss: 0.367838, op_acc: 84.38%] [G loss: 0.298556]\n",
      "917 [D loss: 0.382157, op_acc: 85.94%] [G loss: 0.327420]\n",
      "918 [D loss: 0.473678, op_acc: 71.88%] [G loss: 0.322642]\n",
      "919 [D loss: 0.367849, op_acc: 84.38%] [G loss: 0.311250]\n",
      "920 [D loss: 0.394703, op_acc: 79.69%] [G loss: 0.314291]\n",
      "921 [D loss: 0.283826, op_acc: 90.62%] [G loss: 0.334886]\n",
      "922 [D loss: 0.374585, op_acc: 84.38%] [G loss: 0.360202]\n",
      "923 [D loss: 0.373458, op_acc: 79.69%] [G loss: 0.336560]\n",
      "924 [D loss: 0.355395, op_acc: 87.50%] [G loss: 0.341434]\n",
      "925 [D loss: 0.358052, op_acc: 82.81%] [G loss: 0.390025]\n",
      "926 [D loss: 0.343141, op_acc: 84.38%] [G loss: 0.356521]\n",
      "927 [D loss: 0.270047, op_acc: 96.88%] [G loss: 0.308269]\n",
      "928 [D loss: 0.444058, op_acc: 79.69%] [G loss: 0.319287]\n",
      "929 [D loss: 0.449191, op_acc: 71.88%] [G loss: 0.327928]\n",
      "930 [D loss: 0.350275, op_acc: 84.38%] [G loss: 0.371045]\n",
      "931 [D loss: 0.279977, op_acc: 87.50%] [G loss: 0.354459]\n",
      "932 [D loss: 0.311018, op_acc: 85.94%] [G loss: 0.323700]\n",
      "933 [D loss: 0.449218, op_acc: 75.00%] [G loss: 0.327254]\n",
      "934 [D loss: 0.337220, op_acc: 87.50%] [G loss: 0.302312]\n",
      "935 [D loss: 0.322371, op_acc: 90.62%] [G loss: 0.326022]\n",
      "936 [D loss: 0.421268, op_acc: 79.69%] [G loss: 0.331344]\n",
      "937 [D loss: 0.366027, op_acc: 78.12%] [G loss: 0.338570]\n",
      "938 [D loss: 0.361769, op_acc: 81.25%] [G loss: 0.345899]\n",
      "939 [D loss: 0.365790, op_acc: 81.25%] [G loss: 0.342549]\n",
      "940 [D loss: 0.324149, op_acc: 85.94%] [G loss: 0.320630]\n",
      "941 [D loss: 0.410941, op_acc: 84.38%] [G loss: 0.377877]\n",
      "942 [D loss: 0.344167, op_acc: 89.06%] [G loss: 0.372204]\n",
      "943 [D loss: 0.401876, op_acc: 79.69%] [G loss: 0.334396]\n",
      "944 [D loss: 0.281152, op_acc: 95.31%] [G loss: 0.308993]\n",
      "945 [D loss: 0.394921, op_acc: 79.69%] [G loss: 0.324708]\n",
      "946 [D loss: 0.406074, op_acc: 84.38%] [G loss: 0.323266]\n",
      "947 [D loss: 0.363802, op_acc: 82.81%] [G loss: 0.328692]\n",
      "948 [D loss: 0.334113, op_acc: 89.06%] [G loss: 0.330424]\n",
      "949 [D loss: 0.321164, op_acc: 85.94%] [G loss: 0.317105]\n",
      "950 [D loss: 0.294646, op_acc: 90.62%] [G loss: 0.339840]\n",
      "951 [D loss: 0.369423, op_acc: 81.25%] [G loss: 0.383117]\n",
      "952 [D loss: 0.276443, op_acc: 92.19%] [G loss: 0.344525]\n",
      "953 [D loss: 0.372947, op_acc: 81.25%] [G loss: 0.374262]\n",
      "954 [D loss: 0.361113, op_acc: 82.81%] [G loss: 0.334939]\n",
      "955 [D loss: 0.348369, op_acc: 84.38%] [G loss: 0.298953]\n",
      "956 [D loss: 0.411036, op_acc: 75.00%] [G loss: 0.282609]\n",
      "957 [D loss: 0.395249, op_acc: 84.38%] [G loss: 0.321490]\n",
      "958 [D loss: 0.497999, op_acc: 73.44%] [G loss: 0.360867]\n",
      "959 [D loss: 0.424206, op_acc: 87.50%] [G loss: 0.354352]\n",
      "960 [D loss: 0.309448, op_acc: 89.06%] [G loss: 0.340981]\n",
      "961 [D loss: 0.265139, op_acc: 92.19%] [G loss: 0.344836]\n",
      "962 [D loss: 0.239764, op_acc: 92.19%] [G loss: 0.348491]\n",
      "963 [D loss: 0.315821, op_acc: 89.06%] [G loss: 0.380340]\n",
      "964 [D loss: 0.331838, op_acc: 90.62%] [G loss: 0.357938]\n",
      "965 [D loss: 0.452647, op_acc: 73.44%] [G loss: 0.345408]\n",
      "966 [D loss: 0.357659, op_acc: 84.38%] [G loss: 0.323875]\n",
      "967 [D loss: 0.399850, op_acc: 75.00%] [G loss: 0.324943]\n",
      "968 [D loss: 0.440502, op_acc: 68.75%] [G loss: 0.315663]\n",
      "969 [D loss: 0.467205, op_acc: 75.00%] [G loss: 0.329615]\n",
      "970 [D loss: 0.409267, op_acc: 84.38%] [G loss: 0.319448]\n",
      "971 [D loss: 0.435793, op_acc: 78.12%] [G loss: 0.343750]\n",
      "972 [D loss: 0.387293, op_acc: 81.25%] [G loss: 0.331865]\n",
      "973 [D loss: 0.370395, op_acc: 89.06%] [G loss: 0.343532]\n",
      "974 [D loss: 0.412268, op_acc: 78.12%] [G loss: 0.340372]\n",
      "975 [D loss: 0.355335, op_acc: 89.06%] [G loss: 0.346959]\n",
      "976 [D loss: 0.459118, op_acc: 70.31%] [G loss: 0.357573]\n",
      "977 [D loss: 0.362796, op_acc: 84.38%] [G loss: 0.316196]\n",
      "978 [D loss: 0.328533, op_acc: 82.81%] [G loss: 0.296476]\n",
      "979 [D loss: 0.354816, op_acc: 84.38%] [G loss: 0.360077]\n",
      "980 [D loss: 0.383463, op_acc: 81.25%] [G loss: 0.323448]\n",
      "981 [D loss: 0.432543, op_acc: 76.56%] [G loss: 0.335097]\n",
      "982 [D loss: 0.317664, op_acc: 89.06%] [G loss: 0.336139]\n",
      "983 [D loss: 0.403126, op_acc: 68.75%] [G loss: 0.314184]\n",
      "984 [D loss: 0.385842, op_acc: 81.25%] [G loss: 0.322667]\n",
      "985 [D loss: 0.413600, op_acc: 76.56%] [G loss: 0.366855]\n",
      "986 [D loss: 0.510659, op_acc: 71.88%] [G loss: 0.407370]\n",
      "987 [D loss: 0.350198, op_acc: 82.81%] [G loss: 0.324441]\n",
      "988 [D loss: 0.328316, op_acc: 87.50%] [G loss: 0.328451]\n",
      "989 [D loss: 0.312074, op_acc: 85.94%] [G loss: 0.345654]\n",
      "990 [D loss: 0.379657, op_acc: 87.50%] [G loss: 0.344332]\n",
      "991 [D loss: 0.380894, op_acc: 85.94%] [G loss: 0.324977]\n",
      "992 [D loss: 0.354170, op_acc: 84.38%] [G loss: 0.306676]\n",
      "993 [D loss: 0.334459, op_acc: 89.06%] [G loss: 0.324015]\n",
      "994 [D loss: 0.459202, op_acc: 68.75%] [G loss: 0.352727]\n",
      "995 [D loss: 0.452480, op_acc: 71.88%] [G loss: 0.293394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996 [D loss: 0.426977, op_acc: 82.81%] [G loss: 0.281326]\n",
      "997 [D loss: 0.508968, op_acc: 68.75%] [G loss: 0.318910]\n",
      "998 [D loss: 0.364740, op_acc: 85.94%] [G loss: 0.348163]\n",
      "999 [D loss: 0.362082, op_acc: 81.25%] [G loss: 0.345899]\n",
      "1000 [D loss: 0.273422, op_acc: 90.62%] [G loss: 0.307688]\n",
      "1001 [D loss: 0.321303, op_acc: 85.94%] [G loss: 0.321662]\n",
      "1002 [D loss: 0.286394, op_acc: 90.62%] [G loss: 0.329871]\n",
      "1003 [D loss: 0.259886, op_acc: 92.19%] [G loss: 0.345966]\n",
      "1004 [D loss: 0.290940, op_acc: 90.62%] [G loss: 0.368656]\n",
      "1005 [D loss: 0.339314, op_acc: 89.06%] [G loss: 0.344230]\n",
      "1006 [D loss: 0.304697, op_acc: 85.94%] [G loss: 0.344922]\n",
      "1007 [D loss: 0.333272, op_acc: 85.94%] [G loss: 0.321070]\n",
      "1008 [D loss: 0.317688, op_acc: 87.50%] [G loss: 0.338804]\n",
      "1009 [D loss: 0.390131, op_acc: 82.81%] [G loss: 0.337109]\n",
      "1010 [D loss: 0.374043, op_acc: 82.81%] [G loss: 0.319607]\n",
      "1011 [D loss: 0.413273, op_acc: 87.50%] [G loss: 0.338276]\n",
      "1012 [D loss: 0.414755, op_acc: 76.56%] [G loss: 0.308109]\n",
      "1013 [D loss: 0.416726, op_acc: 82.81%] [G loss: 0.331321]\n",
      "1014 [D loss: 0.318556, op_acc: 89.06%] [G loss: 0.363526]\n",
      "1015 [D loss: 0.326720, op_acc: 82.81%] [G loss: 0.333128]\n",
      "1016 [D loss: 0.364805, op_acc: 82.81%] [G loss: 0.323040]\n",
      "1017 [D loss: 0.297103, op_acc: 89.06%] [G loss: 0.337314]\n",
      "1018 [D loss: 0.425381, op_acc: 73.44%] [G loss: 0.360856]\n",
      "1019 [D loss: 0.275483, op_acc: 87.50%] [G loss: 0.324723]\n",
      "1020 [D loss: 0.389185, op_acc: 84.38%] [G loss: 0.315243]\n",
      "1021 [D loss: 0.400363, op_acc: 81.25%] [G loss: 0.330447]\n",
      "1022 [D loss: 0.373011, op_acc: 87.50%] [G loss: 0.325597]\n",
      "1023 [D loss: 0.330529, op_acc: 85.94%] [G loss: 0.329419]\n",
      "1024 [D loss: 0.326115, op_acc: 89.06%] [G loss: 0.314368]\n",
      "1025 [D loss: 0.273313, op_acc: 93.75%] [G loss: 0.341243]\n",
      "1026 [D loss: 0.403841, op_acc: 78.12%] [G loss: 0.342256]\n",
      "1027 [D loss: 0.424884, op_acc: 81.25%] [G loss: 0.408998]\n",
      "1028 [D loss: 0.446645, op_acc: 75.00%] [G loss: 0.367103]\n",
      "1029 [D loss: 0.360132, op_acc: 85.94%] [G loss: 0.326154]\n",
      "1030 [D loss: 0.328580, op_acc: 85.94%] [G loss: 0.312573]\n",
      "1031 [D loss: 0.267424, op_acc: 92.19%] [G loss: 0.322443]\n",
      "1032 [D loss: 0.390305, op_acc: 89.06%] [G loss: 0.360687]\n",
      "1033 [D loss: 0.415329, op_acc: 84.38%] [G loss: 0.343414]\n",
      "1034 [D loss: 0.358146, op_acc: 81.25%] [G loss: 0.309581]\n",
      "1035 [D loss: 0.410874, op_acc: 79.69%] [G loss: 0.327407]\n",
      "1036 [D loss: 0.365913, op_acc: 82.81%] [G loss: 0.323374]\n",
      "1037 [D loss: 0.245007, op_acc: 95.31%] [G loss: 0.326997]\n",
      "1038 [D loss: 0.443509, op_acc: 78.12%] [G loss: 0.362904]\n",
      "1039 [D loss: 0.479774, op_acc: 71.88%] [G loss: 0.344371]\n",
      "1040 [D loss: 0.293459, op_acc: 89.06%] [G loss: 0.311944]\n",
      "1041 [D loss: 0.453145, op_acc: 84.38%] [G loss: 0.361776]\n",
      "1042 [D loss: 0.392012, op_acc: 78.12%] [G loss: 0.333175]\n",
      "1043 [D loss: 0.353277, op_acc: 84.38%] [G loss: 0.297757]\n",
      "1044 [D loss: 0.375593, op_acc: 81.25%] [G loss: 0.343505]\n",
      "1045 [D loss: 0.325469, op_acc: 87.50%] [G loss: 0.330319]\n",
      "1046 [D loss: 0.331733, op_acc: 84.38%] [G loss: 0.327487]\n",
      "1047 [D loss: 0.350121, op_acc: 81.25%] [G loss: 0.370088]\n",
      "1048 [D loss: 0.294628, op_acc: 90.62%] [G loss: 0.373190]\n",
      "1049 [D loss: 0.372285, op_acc: 79.69%] [G loss: 0.323177]\n",
      "1050 [D loss: 0.233311, op_acc: 95.31%] [G loss: 0.326520]\n",
      "1051 [D loss: 0.370231, op_acc: 82.81%] [G loss: 0.366173]\n",
      "1052 [D loss: 0.384926, op_acc: 79.69%] [G loss: 0.365946]\n",
      "1053 [D loss: 0.334831, op_acc: 89.06%] [G loss: 0.316256]\n",
      "1054 [D loss: 0.336998, op_acc: 81.25%] [G loss: 0.335614]\n",
      "1055 [D loss: 0.274551, op_acc: 93.75%] [G loss: 0.328350]\n",
      "1056 [D loss: 0.299801, op_acc: 85.94%] [G loss: 0.355542]\n",
      "1057 [D loss: 0.407765, op_acc: 79.69%] [G loss: 0.341102]\n",
      "1058 [D loss: 0.428207, op_acc: 79.69%] [G loss: 0.318036]\n",
      "1059 [D loss: 0.305209, op_acc: 90.62%] [G loss: 0.302643]\n",
      "1060 [D loss: 0.346317, op_acc: 84.38%] [G loss: 0.339745]\n",
      "1061 [D loss: 0.295676, op_acc: 90.62%] [G loss: 0.313613]\n",
      "1062 [D loss: 0.379081, op_acc: 79.69%] [G loss: 0.346702]\n",
      "1063 [D loss: 0.305293, op_acc: 87.50%] [G loss: 0.382408]\n",
      "1064 [D loss: 0.408829, op_acc: 82.81%] [G loss: 0.353196]\n",
      "1065 [D loss: 0.351157, op_acc: 85.94%] [G loss: 0.339827]\n",
      "1066 [D loss: 0.285042, op_acc: 89.06%] [G loss: 0.343118]\n",
      "1067 [D loss: 0.274108, op_acc: 92.19%] [G loss: 0.345140]\n",
      "1068 [D loss: 0.296031, op_acc: 92.19%] [G loss: 0.380194]\n",
      "1069 [D loss: 0.299976, op_acc: 85.94%] [G loss: 0.370293]\n",
      "1070 [D loss: 0.317245, op_acc: 87.50%] [G loss: 0.333300]\n",
      "1071 [D loss: 0.414214, op_acc: 82.81%] [G loss: 0.353854]\n",
      "1072 [D loss: 0.364709, op_acc: 84.38%] [G loss: 0.330424]\n",
      "1073 [D loss: 0.397357, op_acc: 79.69%] [G loss: 0.305143]\n",
      "1074 [D loss: 0.349298, op_acc: 85.94%] [G loss: 0.354209]\n",
      "1075 [D loss: 0.348120, op_acc: 84.38%] [G loss: 0.328522]\n",
      "1076 [D loss: 0.246372, op_acc: 95.31%] [G loss: 0.343883]\n",
      "1077 [D loss: 0.336443, op_acc: 81.25%] [G loss: 0.362608]\n",
      "1078 [D loss: 0.388451, op_acc: 79.69%] [G loss: 0.318081]\n",
      "1079 [D loss: 0.326338, op_acc: 85.94%] [G loss: 0.302989]\n",
      "1080 [D loss: 0.305062, op_acc: 90.62%] [G loss: 0.318227]\n",
      "1081 [D loss: 0.382311, op_acc: 81.25%] [G loss: 0.334227]\n",
      "1082 [D loss: 0.396238, op_acc: 75.00%] [G loss: 0.366082]\n",
      "1083 [D loss: 0.407143, op_acc: 82.81%] [G loss: 0.356355]\n",
      "1084 [D loss: 0.388442, op_acc: 81.25%] [G loss: 0.322518]\n",
      "1085 [D loss: 0.360093, op_acc: 81.25%] [G loss: 0.333965]\n",
      "1086 [D loss: 0.352633, op_acc: 85.94%] [G loss: 0.335194]\n",
      "1087 [D loss: 0.343754, op_acc: 84.38%] [G loss: 0.345486]\n",
      "1088 [D loss: 0.379831, op_acc: 89.06%] [G loss: 0.337621]\n",
      "1089 [D loss: 0.337615, op_acc: 82.81%] [G loss: 0.344163]\n",
      "1090 [D loss: 0.415188, op_acc: 79.69%] [G loss: 0.349390]\n",
      "1091 [D loss: 0.308363, op_acc: 90.62%] [G loss: 0.352238]\n",
      "1092 [D loss: 0.320394, op_acc: 89.06%] [G loss: 0.369798]\n",
      "1093 [D loss: 0.307587, op_acc: 92.19%] [G loss: 0.334842]\n",
      "1094 [D loss: 0.315416, op_acc: 89.06%] [G loss: 0.375386]\n",
      "1095 [D loss: 0.370469, op_acc: 84.38%] [G loss: 0.343628]\n",
      "1096 [D loss: 0.257756, op_acc: 92.19%] [G loss: 0.349085]\n",
      "1097 [D loss: 0.319861, op_acc: 84.38%] [G loss: 0.311005]\n",
      "1098 [D loss: 0.313902, op_acc: 85.94%] [G loss: 0.323376]\n",
      "1099 [D loss: 0.307077, op_acc: 84.38%] [G loss: 0.341355]\n",
      "1100 [D loss: 0.400167, op_acc: 85.94%] [G loss: 0.373503]\n",
      "1101 [D loss: 0.343797, op_acc: 82.81%] [G loss: 0.340554]\n",
      "1102 [D loss: 0.331429, op_acc: 84.38%] [G loss: 0.356080]\n",
      "1103 [D loss: 0.310498, op_acc: 85.94%] [G loss: 0.336212]\n",
      "1104 [D loss: 0.248233, op_acc: 92.19%] [G loss: 0.330288]\n",
      "1105 [D loss: 0.427688, op_acc: 76.56%] [G loss: 0.357587]\n",
      "1106 [D loss: 0.344870, op_acc: 82.81%] [G loss: 0.346999]\n",
      "1107 [D loss: 0.316203, op_acc: 87.50%] [G loss: 0.357031]\n",
      "1108 [D loss: 0.332570, op_acc: 87.50%] [G loss: 0.363191]\n",
      "1109 [D loss: 0.291899, op_acc: 87.50%] [G loss: 0.365675]\n",
      "1110 [D loss: 0.397681, op_acc: 87.50%] [G loss: 0.357755]\n",
      "1111 [D loss: 0.336220, op_acc: 89.06%] [G loss: 0.352019]\n",
      "1112 [D loss: 0.315930, op_acc: 89.06%] [G loss: 0.347093]\n",
      "1113 [D loss: 0.343325, op_acc: 85.94%] [G loss: 0.332951]\n",
      "1114 [D loss: 0.298182, op_acc: 90.62%] [G loss: 0.327860]\n",
      "1115 [D loss: 0.383147, op_acc: 70.31%] [G loss: 0.323006]\n",
      "1116 [D loss: 0.455715, op_acc: 76.56%] [G loss: 0.334164]\n",
      "1117 [D loss: 0.328726, op_acc: 84.38%] [G loss: 0.334014]\n",
      "1118 [D loss: 0.272367, op_acc: 89.06%] [G loss: 0.331365]\n",
      "1119 [D loss: 0.483729, op_acc: 70.31%] [G loss: 0.349970]\n",
      "1120 [D loss: 0.307514, op_acc: 90.62%] [G loss: 0.339359]\n",
      "1121 [D loss: 0.319954, op_acc: 84.38%] [G loss: 0.334634]\n",
      "1122 [D loss: 0.297639, op_acc: 89.06%] [G loss: 0.369706]\n",
      "1123 [D loss: 0.294873, op_acc: 87.50%] [G loss: 0.357016]\n",
      "1124 [D loss: 0.380324, op_acc: 78.12%] [G loss: 0.326665]\n",
      "1125 [D loss: 0.284676, op_acc: 92.19%] [G loss: 0.329494]\n",
      "1126 [D loss: 0.374570, op_acc: 81.25%] [G loss: 0.354393]\n",
      "1127 [D loss: 0.379807, op_acc: 85.94%] [G loss: 0.354589]\n",
      "1128 [D loss: 0.337552, op_acc: 85.94%] [G loss: 0.365610]\n",
      "1129 [D loss: 0.357388, op_acc: 79.69%] [G loss: 0.341051]\n",
      "1130 [D loss: 0.265817, op_acc: 96.88%] [G loss: 0.330591]\n",
      "1131 [D loss: 0.331728, op_acc: 89.06%] [G loss: 0.353546]\n",
      "1132 [D loss: 0.409337, op_acc: 79.69%] [G loss: 0.384427]\n",
      "1133 [D loss: 0.423675, op_acc: 76.56%] [G loss: 0.374486]\n",
      "1134 [D loss: 0.314077, op_acc: 84.38%] [G loss: 0.313883]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1135 [D loss: 0.443074, op_acc: 76.56%] [G loss: 0.339443]\n",
      "1136 [D loss: 0.341494, op_acc: 79.69%] [G loss: 0.319024]\n",
      "1137 [D loss: 0.277163, op_acc: 92.19%] [G loss: 0.322618]\n",
      "1138 [D loss: 0.324063, op_acc: 85.94%] [G loss: 0.335967]\n",
      "1139 [D loss: 0.357613, op_acc: 82.81%] [G loss: 0.339520]\n",
      "1140 [D loss: 0.273925, op_acc: 90.62%] [G loss: 0.308953]\n",
      "1141 [D loss: 0.387498, op_acc: 76.56%] [G loss: 0.363448]\n",
      "1142 [D loss: 0.310534, op_acc: 89.06%] [G loss: 0.324784]\n",
      "1143 [D loss: 0.301041, op_acc: 89.06%] [G loss: 0.324898]\n",
      "1144 [D loss: 0.403982, op_acc: 82.81%] [G loss: 0.344674]\n",
      "1145 [D loss: 0.379972, op_acc: 81.25%] [G loss: 0.344685]\n",
      "1146 [D loss: 0.414627, op_acc: 84.38%] [G loss: 0.325668]\n",
      "1147 [D loss: 0.330299, op_acc: 81.25%] [G loss: 0.315217]\n",
      "1148 [D loss: 0.415079, op_acc: 81.25%] [G loss: 0.340588]\n",
      "1149 [D loss: 0.358617, op_acc: 85.94%] [G loss: 0.355919]\n",
      "1150 [D loss: 0.351548, op_acc: 81.25%] [G loss: 0.361765]\n",
      "1151 [D loss: 0.280604, op_acc: 93.75%] [G loss: 0.335824]\n",
      "1152 [D loss: 0.405127, op_acc: 82.81%] [G loss: 0.348821]\n",
      "1153 [D loss: 0.313964, op_acc: 84.38%] [G loss: 0.341567]\n",
      "1154 [D loss: 0.353979, op_acc: 84.38%] [G loss: 0.366503]\n",
      "1155 [D loss: 0.349701, op_acc: 82.81%] [G loss: 0.364664]\n",
      "1156 [D loss: 0.413953, op_acc: 81.25%] [G loss: 0.356018]\n",
      "1157 [D loss: 0.433646, op_acc: 76.56%] [G loss: 0.320339]\n",
      "1158 [D loss: 0.369476, op_acc: 79.69%] [G loss: 0.307064]\n",
      "1159 [D loss: 0.353173, op_acc: 81.25%] [G loss: 0.316035]\n",
      "1160 [D loss: 0.358078, op_acc: 81.25%] [G loss: 0.341789]\n",
      "1161 [D loss: 0.476483, op_acc: 76.56%] [G loss: 0.322874]\n",
      "1162 [D loss: 0.343866, op_acc: 87.50%] [G loss: 0.328057]\n",
      "1163 [D loss: 0.356130, op_acc: 87.50%] [G loss: 0.347288]\n",
      "1164 [D loss: 0.340421, op_acc: 82.81%] [G loss: 0.338964]\n",
      "1165 [D loss: 0.394685, op_acc: 81.25%] [G loss: 0.362445]\n",
      "1166 [D loss: 0.282726, op_acc: 89.06%] [G loss: 0.342581]\n",
      "1167 [D loss: 0.372995, op_acc: 82.81%] [G loss: 0.358580]\n",
      "1168 [D loss: 0.312532, op_acc: 87.50%] [G loss: 0.377424]\n",
      "1169 [D loss: 0.420742, op_acc: 75.00%] [G loss: 0.331318]\n",
      "1170 [D loss: 0.378080, op_acc: 73.44%] [G loss: 0.322878]\n",
      "1171 [D loss: 0.414591, op_acc: 76.56%] [G loss: 0.338371]\n",
      "1172 [D loss: 0.279855, op_acc: 90.62%] [G loss: 0.343996]\n",
      "1173 [D loss: 0.317175, op_acc: 87.50%] [G loss: 0.321813]\n",
      "1174 [D loss: 0.411251, op_acc: 79.69%] [G loss: 0.344886]\n",
      "1175 [D loss: 0.381127, op_acc: 81.25%] [G loss: 0.335005]\n",
      "1176 [D loss: 0.376122, op_acc: 78.12%] [G loss: 0.328644]\n",
      "1177 [D loss: 0.474594, op_acc: 73.44%] [G loss: 0.348294]\n",
      "1178 [D loss: 0.275899, op_acc: 93.75%] [G loss: 0.341212]\n",
      "1179 [D loss: 0.366535, op_acc: 78.12%] [G loss: 0.352408]\n",
      "1180 [D loss: 0.324512, op_acc: 85.94%] [G loss: 0.358277]\n",
      "1181 [D loss: 0.437703, op_acc: 70.31%] [G loss: 0.309339]\n",
      "1182 [D loss: 0.243925, op_acc: 96.88%] [G loss: 0.310403]\n",
      "1183 [D loss: 0.320619, op_acc: 85.94%] [G loss: 0.352699]\n",
      "1184 [D loss: 0.325684, op_acc: 84.38%] [G loss: 0.340002]\n",
      "1185 [D loss: 0.392003, op_acc: 78.12%] [G loss: 0.339628]\n",
      "1186 [D loss: 0.326310, op_acc: 87.50%] [G loss: 0.339024]\n",
      "1187 [D loss: 0.374598, op_acc: 85.94%] [G loss: 0.337717]\n",
      "1188 [D loss: 0.432213, op_acc: 79.69%] [G loss: 0.332231]\n",
      "1189 [D loss: 0.375008, op_acc: 79.69%] [G loss: 0.321490]\n",
      "1190 [D loss: 0.348530, op_acc: 82.81%] [G loss: 0.370403]\n",
      "1191 [D loss: 0.318396, op_acc: 89.06%] [G loss: 0.367324]\n",
      "1192 [D loss: 0.506358, op_acc: 78.12%] [G loss: 0.354906]\n",
      "1193 [D loss: 0.406543, op_acc: 79.69%] [G loss: 0.319681]\n",
      "1194 [D loss: 0.336469, op_acc: 84.38%] [G loss: 0.369785]\n",
      "1195 [D loss: 0.293562, op_acc: 89.06%] [G loss: 0.336209]\n",
      "1196 [D loss: 0.438149, op_acc: 78.12%] [G loss: 0.340373]\n",
      "1197 [D loss: 0.333258, op_acc: 87.50%] [G loss: 0.363462]\n",
      "1198 [D loss: 0.374547, op_acc: 81.25%] [G loss: 0.348837]\n",
      "1199 [D loss: 0.289709, op_acc: 93.75%] [G loss: 0.334259]\n",
      "1200 [D loss: 0.322095, op_acc: 87.50%] [G loss: 0.360753]\n",
      "1201 [D loss: 0.346532, op_acc: 87.50%] [G loss: 0.349760]\n",
      "1202 [D loss: 0.334920, op_acc: 85.94%] [G loss: 0.348107]\n",
      "1203 [D loss: 0.311991, op_acc: 85.94%] [G loss: 0.350625]\n",
      "1204 [D loss: 0.238145, op_acc: 93.75%] [G loss: 0.355008]\n",
      "1205 [D loss: 0.299971, op_acc: 90.62%] [G loss: 0.349136]\n",
      "1206 [D loss: 0.369013, op_acc: 78.12%] [G loss: 0.338542]\n",
      "1207 [D loss: 0.380513, op_acc: 84.38%] [G loss: 0.381045]\n",
      "1208 [D loss: 0.321733, op_acc: 87.50%] [G loss: 0.312777]\n",
      "1209 [D loss: 0.350713, op_acc: 85.94%] [G loss: 0.332002]\n",
      "1210 [D loss: 0.327266, op_acc: 84.38%] [G loss: 0.336783]\n",
      "1211 [D loss: 0.361964, op_acc: 84.38%] [G loss: 0.369507]\n",
      "1212 [D loss: 0.332211, op_acc: 84.38%] [G loss: 0.352877]\n",
      "1213 [D loss: 0.416598, op_acc: 78.12%] [G loss: 0.355950]\n",
      "1214 [D loss: 0.384750, op_acc: 78.12%] [G loss: 0.372782]\n",
      "1215 [D loss: 0.370527, op_acc: 75.00%] [G loss: 0.361390]\n",
      "1216 [D loss: 0.319411, op_acc: 87.50%] [G loss: 0.316803]\n",
      "1217 [D loss: 0.389048, op_acc: 84.38%] [G loss: 0.301366]\n",
      "1218 [D loss: 0.343156, op_acc: 79.69%] [G loss: 0.326825]\n",
      "1219 [D loss: 0.372730, op_acc: 81.25%] [G loss: 0.361139]\n",
      "1220 [D loss: 0.331542, op_acc: 85.94%] [G loss: 0.338148]\n",
      "1221 [D loss: 0.402989, op_acc: 81.25%] [G loss: 0.333384]\n",
      "1222 [D loss: 0.369863, op_acc: 81.25%] [G loss: 0.358986]\n",
      "1223 [D loss: 0.376676, op_acc: 79.69%] [G loss: 0.371106]\n",
      "1224 [D loss: 0.316281, op_acc: 87.50%] [G loss: 0.379304]\n",
      "1225 [D loss: 0.387636, op_acc: 82.81%] [G loss: 0.353691]\n",
      "1226 [D loss: 0.281233, op_acc: 92.19%] [G loss: 0.359618]\n",
      "1227 [D loss: 0.314002, op_acc: 82.81%] [G loss: 0.362397]\n",
      "1228 [D loss: 0.283475, op_acc: 89.06%] [G loss: 0.340131]\n",
      "1229 [D loss: 0.473535, op_acc: 75.00%] [G loss: 0.368463]\n",
      "1230 [D loss: 0.256250, op_acc: 92.19%] [G loss: 0.334943]\n",
      "1231 [D loss: 0.304085, op_acc: 90.62%] [G loss: 0.337802]\n",
      "1232 [D loss: 0.481360, op_acc: 65.62%] [G loss: 0.338906]\n",
      "1233 [D loss: 0.329631, op_acc: 87.50%] [G loss: 0.320315]\n",
      "1234 [D loss: 0.567084, op_acc: 64.06%] [G loss: 0.350393]\n",
      "1235 [D loss: 0.448802, op_acc: 73.44%] [G loss: 0.319676]\n",
      "1236 [D loss: 0.284584, op_acc: 90.62%] [G loss: 0.350310]\n",
      "1237 [D loss: 0.333311, op_acc: 89.06%] [G loss: 0.337158]\n",
      "1238 [D loss: 0.283886, op_acc: 89.06%] [G loss: 0.381553]\n",
      "1239 [D loss: 0.308943, op_acc: 89.06%] [G loss: 0.380583]\n",
      "1240 [D loss: 0.262030, op_acc: 95.31%] [G loss: 0.357106]\n",
      "1241 [D loss: 0.260339, op_acc: 95.31%] [G loss: 0.346031]\n",
      "1242 [D loss: 0.349754, op_acc: 82.81%] [G loss: 0.365916]\n",
      "1243 [D loss: 0.329763, op_acc: 87.50%] [G loss: 0.362120]\n",
      "1244 [D loss: 0.357577, op_acc: 85.94%] [G loss: 0.350592]\n",
      "1245 [D loss: 0.413199, op_acc: 84.38%] [G loss: 0.366345]\n",
      "1246 [D loss: 0.394501, op_acc: 78.12%] [G loss: 0.334792]\n",
      "1247 [D loss: 0.326099, op_acc: 84.38%] [G loss: 0.325340]\n",
      "1248 [D loss: 0.417704, op_acc: 76.56%] [G loss: 0.330840]\n",
      "1249 [D loss: 0.461538, op_acc: 75.00%] [G loss: 0.354052]\n",
      "1250 [D loss: 0.435874, op_acc: 81.25%] [G loss: 0.372164]\n",
      "1251 [D loss: 0.326286, op_acc: 84.38%] [G loss: 0.353666]\n",
      "1252 [D loss: 0.317990, op_acc: 85.94%] [G loss: 0.333422]\n",
      "1253 [D loss: 0.276387, op_acc: 89.06%] [G loss: 0.345599]\n",
      "1254 [D loss: 0.445079, op_acc: 75.00%] [G loss: 0.352335]\n",
      "1255 [D loss: 0.378203, op_acc: 79.69%] [G loss: 0.326137]\n",
      "1256 [D loss: 0.360775, op_acc: 79.69%] [G loss: 0.358713]\n",
      "1257 [D loss: 0.294449, op_acc: 89.06%] [G loss: 0.337704]\n",
      "1258 [D loss: 0.475881, op_acc: 75.00%] [G loss: 0.346876]\n",
      "1259 [D loss: 0.391795, op_acc: 85.94%] [G loss: 0.346161]\n",
      "1260 [D loss: 0.331763, op_acc: 85.94%] [G loss: 0.324210]\n",
      "1261 [D loss: 0.326889, op_acc: 85.94%] [G loss: 0.338550]\n",
      "1262 [D loss: 0.349794, op_acc: 82.81%] [G loss: 0.336880]\n",
      "1263 [D loss: 0.330239, op_acc: 85.94%] [G loss: 0.347201]\n",
      "1264 [D loss: 0.407360, op_acc: 79.69%] [G loss: 0.378896]\n",
      "1265 [D loss: 0.394899, op_acc: 76.56%] [G loss: 0.390839]\n",
      "1266 [D loss: 0.384638, op_acc: 87.50%] [G loss: 0.366633]\n",
      "1267 [D loss: 0.366252, op_acc: 78.12%] [G loss: 0.369518]\n",
      "1268 [D loss: 0.307089, op_acc: 87.50%] [G loss: 0.354931]\n",
      "1269 [D loss: 0.411483, op_acc: 71.88%] [G loss: 0.330305]\n",
      "1270 [D loss: 0.448029, op_acc: 73.44%] [G loss: 0.336504]\n",
      "1271 [D loss: 0.293810, op_acc: 90.62%] [G loss: 0.332484]\n",
      "1272 [D loss: 0.407804, op_acc: 82.81%] [G loss: 0.360438]\n",
      "1273 [D loss: 0.388542, op_acc: 76.56%] [G loss: 0.345900]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1274 [D loss: 0.350192, op_acc: 84.38%] [G loss: 0.337320]\n",
      "1275 [D loss: 0.413027, op_acc: 73.44%] [G loss: 0.369451]\n",
      "1276 [D loss: 0.278838, op_acc: 87.50%] [G loss: 0.354280]\n",
      "1277 [D loss: 0.354619, op_acc: 81.25%] [G loss: 0.342962]\n",
      "1278 [D loss: 0.388665, op_acc: 82.81%] [G loss: 0.327611]\n",
      "1279 [D loss: 0.454622, op_acc: 76.56%] [G loss: 0.334105]\n",
      "1280 [D loss: 0.432471, op_acc: 79.69%] [G loss: 0.353529]\n",
      "1281 [D loss: 0.399998, op_acc: 78.12%] [G loss: 0.354165]\n",
      "1282 [D loss: 0.292500, op_acc: 90.62%] [G loss: 0.334062]\n",
      "1283 [D loss: 0.375449, op_acc: 76.56%] [G loss: 0.350695]\n",
      "1284 [D loss: 0.306951, op_acc: 84.38%] [G loss: 0.367468]\n",
      "1285 [D loss: 0.380610, op_acc: 78.12%] [G loss: 0.366368]\n",
      "1286 [D loss: 0.335400, op_acc: 87.50%] [G loss: 0.388227]\n",
      "1287 [D loss: 0.289197, op_acc: 92.19%] [G loss: 0.378597]\n",
      "1288 [D loss: 0.349274, op_acc: 82.81%] [G loss: 0.392054]\n",
      "1289 [D loss: 0.309312, op_acc: 87.50%] [G loss: 0.345844]\n",
      "1290 [D loss: 0.364528, op_acc: 85.94%] [G loss: 0.334104]\n",
      "1291 [D loss: 0.363457, op_acc: 82.81%] [G loss: 0.346946]\n",
      "1292 [D loss: 0.418261, op_acc: 79.69%] [G loss: 0.342098]\n",
      "1293 [D loss: 0.392482, op_acc: 79.69%] [G loss: 0.349424]\n",
      "1294 [D loss: 0.338477, op_acc: 85.94%] [G loss: 0.337747]\n",
      "1295 [D loss: 0.339412, op_acc: 84.38%] [G loss: 0.386470]\n",
      "1296 [D loss: 0.324082, op_acc: 87.50%] [G loss: 0.326132]\n",
      "1297 [D loss: 0.338020, op_acc: 84.38%] [G loss: 0.346956]\n",
      "1298 [D loss: 0.340015, op_acc: 81.25%] [G loss: 0.338293]\n",
      "1299 [D loss: 0.352106, op_acc: 84.38%] [G loss: 0.344937]\n",
      "1300 [D loss: 0.336580, op_acc: 85.94%] [G loss: 0.369985]\n",
      "1301 [D loss: 0.313853, op_acc: 84.38%] [G loss: 0.352204]\n",
      "1302 [D loss: 0.387795, op_acc: 79.69%] [G loss: 0.334319]\n",
      "1303 [D loss: 0.330858, op_acc: 90.62%] [G loss: 0.358737]\n",
      "1304 [D loss: 0.354526, op_acc: 79.69%] [G loss: 0.339113]\n",
      "1305 [D loss: 0.328992, op_acc: 84.38%] [G loss: 0.347811]\n",
      "1306 [D loss: 0.313215, op_acc: 89.06%] [G loss: 0.333164]\n",
      "1307 [D loss: 0.387185, op_acc: 79.69%] [G loss: 0.341706]\n",
      "1308 [D loss: 0.395295, op_acc: 78.12%] [G loss: 0.333884]\n",
      "1309 [D loss: 0.387495, op_acc: 84.38%] [G loss: 0.364820]\n",
      "1310 [D loss: 0.378796, op_acc: 85.94%] [G loss: 0.356954]\n",
      "1311 [D loss: 0.360225, op_acc: 82.81%] [G loss: 0.378314]\n",
      "1312 [D loss: 0.316877, op_acc: 82.81%] [G loss: 0.373419]\n",
      "1313 [D loss: 0.245695, op_acc: 95.31%] [G loss: 0.369214]\n",
      "1314 [D loss: 0.350632, op_acc: 85.94%] [G loss: 0.415624]\n",
      "1315 [D loss: 0.336274, op_acc: 84.38%] [G loss: 0.388658]\n",
      "1316 [D loss: 0.380879, op_acc: 87.50%] [G loss: 0.365865]\n",
      "1317 [D loss: 0.308744, op_acc: 89.06%] [G loss: 0.353637]\n",
      "1318 [D loss: 0.290417, op_acc: 90.62%] [G loss: 0.339765]\n",
      "1319 [D loss: 0.351645, op_acc: 87.50%] [G loss: 0.332875]\n",
      "1320 [D loss: 0.360877, op_acc: 79.69%] [G loss: 0.353438]\n",
      "1321 [D loss: 0.327595, op_acc: 85.94%] [G loss: 0.361904]\n",
      "1322 [D loss: 0.331417, op_acc: 89.06%] [G loss: 0.338875]\n",
      "1323 [D loss: 0.313356, op_acc: 87.50%] [G loss: 0.340309]\n",
      "1324 [D loss: 0.462545, op_acc: 76.56%] [G loss: 0.356408]\n",
      "1325 [D loss: 0.355665, op_acc: 84.38%] [G loss: 0.374969]\n",
      "1326 [D loss: 0.335394, op_acc: 82.81%] [G loss: 0.379679]\n",
      "1327 [D loss: 0.366846, op_acc: 79.69%] [G loss: 0.356679]\n",
      "1328 [D loss: 0.311364, op_acc: 85.94%] [G loss: 0.366005]\n",
      "1329 [D loss: 0.393538, op_acc: 81.25%] [G loss: 0.390634]\n",
      "1330 [D loss: 0.366294, op_acc: 82.81%] [G loss: 0.375498]\n",
      "1331 [D loss: 0.333864, op_acc: 82.81%] [G loss: 0.383515]\n",
      "1332 [D loss: 0.377059, op_acc: 81.25%] [G loss: 0.342559]\n",
      "1333 [D loss: 0.316870, op_acc: 87.50%] [G loss: 0.374872]\n",
      "1334 [D loss: 0.456202, op_acc: 73.44%] [G loss: 0.382102]\n",
      "1335 [D loss: 0.397966, op_acc: 78.12%] [G loss: 0.411172]\n",
      "1336 [D loss: 0.383969, op_acc: 78.12%] [G loss: 0.345156]\n",
      "1337 [D loss: 0.343316, op_acc: 84.38%] [G loss: 0.397074]\n",
      "1338 [D loss: 0.321743, op_acc: 85.94%] [G loss: 0.374144]\n",
      "1339 [D loss: 0.322310, op_acc: 85.94%] [G loss: 0.351613]\n",
      "1340 [D loss: 0.329347, op_acc: 81.25%] [G loss: 0.378663]\n",
      "1341 [D loss: 0.398242, op_acc: 73.44%] [G loss: 0.359930]\n",
      "1342 [D loss: 0.299789, op_acc: 90.62%] [G loss: 0.320295]\n",
      "1343 [D loss: 0.330241, op_acc: 82.81%] [G loss: 0.350498]\n",
      "1344 [D loss: 0.356002, op_acc: 79.69%] [G loss: 0.366533]\n",
      "1345 [D loss: 0.377248, op_acc: 82.81%] [G loss: 0.361593]\n",
      "1346 [D loss: 0.343419, op_acc: 89.06%] [G loss: 0.334527]\n",
      "1347 [D loss: 0.282912, op_acc: 90.62%] [G loss: 0.354053]\n",
      "1348 [D loss: 0.303749, op_acc: 89.06%] [G loss: 0.375925]\n",
      "1349 [D loss: 0.251788, op_acc: 93.75%] [G loss: 0.404499]\n",
      "1350 [D loss: 0.306722, op_acc: 84.38%] [G loss: 0.388211]\n",
      "1351 [D loss: 0.347182, op_acc: 89.06%] [G loss: 0.391125]\n",
      "1352 [D loss: 0.353800, op_acc: 85.94%] [G loss: 0.367332]\n",
      "1353 [D loss: 0.304793, op_acc: 82.81%] [G loss: 0.385913]\n",
      "1354 [D loss: 0.313471, op_acc: 82.81%] [G loss: 0.380129]\n",
      "1355 [D loss: 0.286121, op_acc: 92.19%] [G loss: 0.365520]\n",
      "1356 [D loss: 0.370414, op_acc: 78.12%] [G loss: 0.380955]\n",
      "1357 [D loss: 0.448322, op_acc: 78.12%] [G loss: 0.355359]\n",
      "1358 [D loss: 0.347645, op_acc: 79.69%] [G loss: 0.352423]\n",
      "1359 [D loss: 0.322323, op_acc: 89.06%] [G loss: 0.361146]\n",
      "1360 [D loss: 0.279454, op_acc: 92.19%] [G loss: 0.350465]\n",
      "1361 [D loss: 0.271457, op_acc: 92.19%] [G loss: 0.335979]\n",
      "1362 [D loss: 0.440941, op_acc: 71.88%] [G loss: 0.409587]\n",
      "1363 [D loss: 0.315539, op_acc: 89.06%] [G loss: 0.304928]\n",
      "1364 [D loss: 0.351699, op_acc: 82.81%] [G loss: 0.343599]\n",
      "1365 [D loss: 0.323533, op_acc: 81.25%] [G loss: 0.373769]\n",
      "1366 [D loss: 0.310354, op_acc: 84.38%] [G loss: 0.365369]\n",
      "1367 [D loss: 0.380222, op_acc: 76.56%] [G loss: 0.429216]\n",
      "1368 [D loss: 0.252306, op_acc: 89.06%] [G loss: 0.381868]\n",
      "1369 [D loss: 0.411286, op_acc: 78.12%] [G loss: 0.392612]\n",
      "1370 [D loss: 0.338106, op_acc: 84.38%] [G loss: 0.355840]\n",
      "1371 [D loss: 0.220986, op_acc: 96.88%] [G loss: 0.372910]\n",
      "1372 [D loss: 0.412543, op_acc: 71.88%] [G loss: 0.397299]\n",
      "1373 [D loss: 0.374048, op_acc: 78.12%] [G loss: 0.360231]\n",
      "1374 [D loss: 0.390022, op_acc: 78.12%] [G loss: 0.379446]\n",
      "1375 [D loss: 0.326321, op_acc: 84.38%] [G loss: 0.367057]\n",
      "1376 [D loss: 0.370483, op_acc: 79.69%] [G loss: 0.373293]\n",
      "1377 [D loss: 0.353835, op_acc: 87.50%] [G loss: 0.379198]\n",
      "1378 [D loss: 0.363766, op_acc: 81.25%] [G loss: 0.401248]\n",
      "1379 [D loss: 0.337757, op_acc: 85.94%] [G loss: 0.357586]\n",
      "1380 [D loss: 0.329752, op_acc: 82.81%] [G loss: 0.386764]\n",
      "1381 [D loss: 0.449877, op_acc: 75.00%] [G loss: 0.358467]\n",
      "1382 [D loss: 0.309675, op_acc: 89.06%] [G loss: 0.337476]\n",
      "1383 [D loss: 0.333659, op_acc: 84.38%] [G loss: 0.349448]\n",
      "1384 [D loss: 0.452613, op_acc: 75.00%] [G loss: 0.386371]\n",
      "1385 [D loss: 0.304754, op_acc: 84.38%] [G loss: 0.367771]\n",
      "1386 [D loss: 0.374547, op_acc: 82.81%] [G loss: 0.354128]\n",
      "1387 [D loss: 0.360212, op_acc: 82.81%] [G loss: 0.368296]\n",
      "1388 [D loss: 0.354479, op_acc: 87.50%] [G loss: 0.340130]\n",
      "1389 [D loss: 0.413642, op_acc: 76.56%] [G loss: 0.351674]\n",
      "1390 [D loss: 0.316908, op_acc: 85.94%] [G loss: 0.377136]\n",
      "1391 [D loss: 0.327147, op_acc: 92.19%] [G loss: 0.364022]\n",
      "1392 [D loss: 0.296050, op_acc: 82.81%] [G loss: 0.372081]\n",
      "1393 [D loss: 0.366324, op_acc: 87.50%] [G loss: 0.383872]\n",
      "1394 [D loss: 0.302078, op_acc: 85.94%] [G loss: 0.389443]\n",
      "1395 [D loss: 0.338949, op_acc: 87.50%] [G loss: 0.367460]\n",
      "1396 [D loss: 0.314926, op_acc: 82.81%] [G loss: 0.342416]\n",
      "1397 [D loss: 0.319562, op_acc: 84.38%] [G loss: 0.405272]\n",
      "1398 [D loss: 0.261091, op_acc: 90.62%] [G loss: 0.395347]\n",
      "1399 [D loss: 0.344689, op_acc: 84.38%] [G loss: 0.340106]\n",
      "1400 [D loss: 0.349541, op_acc: 85.94%] [G loss: 0.409022]\n",
      "1401 [D loss: 0.270361, op_acc: 92.19%] [G loss: 0.382732]\n",
      "1402 [D loss: 0.436966, op_acc: 68.75%] [G loss: 0.381749]\n",
      "1403 [D loss: 0.270554, op_acc: 92.19%] [G loss: 0.348365]\n",
      "1404 [D loss: 0.318627, op_acc: 85.94%] [G loss: 0.386592]\n",
      "1405 [D loss: 0.405433, op_acc: 76.56%] [G loss: 0.411610]\n",
      "1406 [D loss: 0.309062, op_acc: 92.19%] [G loss: 0.357418]\n",
      "1407 [D loss: 0.415116, op_acc: 75.00%] [G loss: 0.390911]\n",
      "1408 [D loss: 0.360009, op_acc: 81.25%] [G loss: 0.411091]\n",
      "1409 [D loss: 0.298456, op_acc: 89.06%] [G loss: 0.409365]\n",
      "1410 [D loss: 0.332960, op_acc: 84.38%] [G loss: 0.346231]\n",
      "1411 [D loss: 0.275736, op_acc: 89.06%] [G loss: 0.371824]\n",
      "1412 [D loss: 0.371172, op_acc: 87.50%] [G loss: 0.393497]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1413 [D loss: 0.274784, op_acc: 92.19%] [G loss: 0.395615]\n",
      "1414 [D loss: 0.322541, op_acc: 82.81%] [G loss: 0.428146]\n",
      "1415 [D loss: 0.274689, op_acc: 89.06%] [G loss: 0.380277]\n",
      "1416 [D loss: 0.282820, op_acc: 89.06%] [G loss: 0.399259]\n",
      "1417 [D loss: 0.385553, op_acc: 79.69%] [G loss: 0.394950]\n",
      "1418 [D loss: 0.380851, op_acc: 82.81%] [G loss: 0.375431]\n",
      "1419 [D loss: 0.382817, op_acc: 75.00%] [G loss: 0.362918]\n",
      "1420 [D loss: 0.440444, op_acc: 79.69%] [G loss: 0.393589]\n",
      "1421 [D loss: 0.335979, op_acc: 84.38%] [G loss: 0.366757]\n",
      "1422 [D loss: 0.350186, op_acc: 84.38%] [G loss: 0.398906]\n",
      "1423 [D loss: 0.356590, op_acc: 82.81%] [G loss: 0.432338]\n",
      "1424 [D loss: 0.353548, op_acc: 85.94%] [G loss: 0.389507]\n",
      "1425 [D loss: 0.331655, op_acc: 87.50%] [G loss: 0.385637]\n",
      "1426 [D loss: 0.350077, op_acc: 78.12%] [G loss: 0.412911]\n",
      "1427 [D loss: 0.331873, op_acc: 81.25%] [G loss: 0.368471]\n",
      "1428 [D loss: 0.412686, op_acc: 78.12%] [G loss: 0.407224]\n",
      "1429 [D loss: 0.356118, op_acc: 79.69%] [G loss: 0.395420]\n",
      "1430 [D loss: 0.262429, op_acc: 93.75%] [G loss: 0.390240]\n",
      "1431 [D loss: 0.338583, op_acc: 85.94%] [G loss: 0.391405]\n",
      "1432 [D loss: 0.330267, op_acc: 81.25%] [G loss: 0.388646]\n",
      "1433 [D loss: 0.254275, op_acc: 87.50%] [G loss: 0.408072]\n",
      "1434 [D loss: 0.372266, op_acc: 76.56%] [G loss: 0.400773]\n",
      "1435 [D loss: 0.305888, op_acc: 89.06%] [G loss: 0.381732]\n",
      "1436 [D loss: 0.264802, op_acc: 89.06%] [G loss: 0.390580]\n",
      "1437 [D loss: 0.280738, op_acc: 90.62%] [G loss: 0.402182]\n",
      "1438 [D loss: 0.295019, op_acc: 90.62%] [G loss: 0.419754]\n",
      "1439 [D loss: 0.355044, op_acc: 84.38%] [G loss: 0.458094]\n",
      "1440 [D loss: 0.307684, op_acc: 89.06%] [G loss: 0.413568]\n",
      "1441 [D loss: 0.372971, op_acc: 84.38%] [G loss: 0.396316]\n",
      "1442 [D loss: 0.321687, op_acc: 79.69%] [G loss: 0.454648]\n",
      "1443 [D loss: 0.314959, op_acc: 85.94%] [G loss: 0.419383]\n",
      "1444 [D loss: 0.389664, op_acc: 79.69%] [G loss: 0.369471]\n",
      "1445 [D loss: 0.288903, op_acc: 92.19%] [G loss: 0.392429]\n",
      "1446 [D loss: 0.320476, op_acc: 82.81%] [G loss: 0.453893]\n",
      "1447 [D loss: 0.318750, op_acc: 84.38%] [G loss: 0.392659]\n",
      "1448 [D loss: 0.348382, op_acc: 85.94%] [G loss: 0.421951]\n",
      "1449 [D loss: 0.533362, op_acc: 70.31%] [G loss: 0.431843]\n",
      "1450 [D loss: 0.358170, op_acc: 81.25%] [G loss: 0.390818]\n",
      "1451 [D loss: 0.357287, op_acc: 84.38%] [G loss: 0.361100]\n",
      "1452 [D loss: 0.275552, op_acc: 87.50%] [G loss: 0.420378]\n",
      "1453 [D loss: 0.371973, op_acc: 73.44%] [G loss: 0.405073]\n",
      "1454 [D loss: 0.393216, op_acc: 79.69%] [G loss: 0.354849]\n",
      "1455 [D loss: 0.309230, op_acc: 85.94%] [G loss: 0.346019]\n",
      "1456 [D loss: 0.386012, op_acc: 78.12%] [G loss: 0.410559]\n",
      "1457 [D loss: 0.342884, op_acc: 81.25%] [G loss: 0.390306]\n",
      "1458 [D loss: 0.374164, op_acc: 82.81%] [G loss: 0.400769]\n",
      "1459 [D loss: 0.324464, op_acc: 87.50%] [G loss: 0.397791]\n",
      "1460 [D loss: 0.265450, op_acc: 92.19%] [G loss: 0.438753]\n",
      "1461 [D loss: 0.413357, op_acc: 81.25%] [G loss: 0.487335]\n",
      "1462 [D loss: 0.283783, op_acc: 85.94%] [G loss: 0.396497]\n",
      "1463 [D loss: 0.356010, op_acc: 78.12%] [G loss: 0.455242]\n",
      "1464 [D loss: 0.299822, op_acc: 85.94%] [G loss: 0.380552]\n",
      "1465 [D loss: 0.381406, op_acc: 81.25%] [G loss: 0.407138]\n",
      "1466 [D loss: 0.350652, op_acc: 84.38%] [G loss: 0.355045]\n",
      "1467 [D loss: 0.419657, op_acc: 73.44%] [G loss: 0.381701]\n",
      "1468 [D loss: 0.311004, op_acc: 87.50%] [G loss: 0.433009]\n",
      "1469 [D loss: 0.511990, op_acc: 68.75%] [G loss: 0.452467]\n",
      "1470 [D loss: 0.403782, op_acc: 82.81%] [G loss: 0.406713]\n",
      "1471 [D loss: 0.340190, op_acc: 84.38%] [G loss: 0.437950]\n",
      "1472 [D loss: 0.278838, op_acc: 89.06%] [G loss: 0.425442]\n",
      "1473 [D loss: 0.305148, op_acc: 82.81%] [G loss: 0.407891]\n",
      "1474 [D loss: 0.383329, op_acc: 76.56%] [G loss: 0.417672]\n",
      "1475 [D loss: 0.417280, op_acc: 70.31%] [G loss: 0.395062]\n",
      "1476 [D loss: 0.443408, op_acc: 71.88%] [G loss: 0.373794]\n",
      "1477 [D loss: 0.314726, op_acc: 84.38%] [G loss: 0.391333]\n",
      "1478 [D loss: 0.279937, op_acc: 89.06%] [G loss: 0.396464]\n",
      "1479 [D loss: 0.427674, op_acc: 76.56%] [G loss: 0.411827]\n",
      "1480 [D loss: 0.280490, op_acc: 93.75%] [G loss: 0.414247]\n",
      "1481 [D loss: 0.369143, op_acc: 81.25%] [G loss: 0.395646]\n",
      "1482 [D loss: 0.274014, op_acc: 89.06%] [G loss: 0.435559]\n",
      "1483 [D loss: 0.407779, op_acc: 76.56%] [G loss: 0.388507]\n",
      "1484 [D loss: 0.405859, op_acc: 78.12%] [G loss: 0.428583]\n",
      "1485 [D loss: 0.403170, op_acc: 73.44%] [G loss: 0.390392]\n",
      "1486 [D loss: 0.311069, op_acc: 89.06%] [G loss: 0.427572]\n",
      "1487 [D loss: 0.380546, op_acc: 79.69%] [G loss: 0.447708]\n",
      "1488 [D loss: 0.330865, op_acc: 82.81%] [G loss: 0.400162]\n",
      "1489 [D loss: 0.267952, op_acc: 89.06%] [G loss: 0.377709]\n",
      "1490 [D loss: 0.315453, op_acc: 85.94%] [G loss: 0.395690]\n",
      "1491 [D loss: 0.342836, op_acc: 85.94%] [G loss: 0.388022]\n",
      "1492 [D loss: 0.370676, op_acc: 84.38%] [G loss: 0.442953]\n",
      "1493 [D loss: 0.289396, op_acc: 90.62%] [G loss: 0.426211]\n",
      "1494 [D loss: 0.462229, op_acc: 68.75%] [G loss: 0.391007]\n",
      "1495 [D loss: 0.299241, op_acc: 89.06%] [G loss: 0.414852]\n",
      "1496 [D loss: 0.271780, op_acc: 90.62%] [G loss: 0.475648]\n",
      "1497 [D loss: 0.325775, op_acc: 81.25%] [G loss: 0.440741]\n",
      "1498 [D loss: 0.406487, op_acc: 78.12%] [G loss: 0.485681]\n",
      "1499 [D loss: 0.332814, op_acc: 84.38%] [G loss: 0.339504]\n",
      "1500 [D loss: 0.354364, op_acc: 82.81%] [G loss: 0.409628]\n",
      "1501 [D loss: 0.304302, op_acc: 85.94%] [G loss: 0.437057]\n",
      "1502 [D loss: 0.269137, op_acc: 90.62%] [G loss: 0.377643]\n",
      "1503 [D loss: 0.427564, op_acc: 71.88%] [G loss: 0.392917]\n",
      "1504 [D loss: 0.362578, op_acc: 78.12%] [G loss: 0.406034]\n",
      "1505 [D loss: 0.251125, op_acc: 95.31%] [G loss: 0.419016]\n",
      "1506 [D loss: 0.385802, op_acc: 82.81%] [G loss: 0.501731]\n",
      "1507 [D loss: 0.309525, op_acc: 89.06%] [G loss: 0.433628]\n",
      "1508 [D loss: 0.277132, op_acc: 92.19%] [G loss: 0.404346]\n",
      "1509 [D loss: 0.418927, op_acc: 73.44%] [G loss: 0.453379]\n",
      "1510 [D loss: 0.309255, op_acc: 89.06%] [G loss: 0.375339]\n",
      "1511 [D loss: 0.361027, op_acc: 82.81%] [G loss: 0.414299]\n",
      "1512 [D loss: 0.299154, op_acc: 87.50%] [G loss: 0.398936]\n",
      "1513 [D loss: 0.353608, op_acc: 82.81%] [G loss: 0.410462]\n",
      "1514 [D loss: 0.391447, op_acc: 82.81%] [G loss: 0.437592]\n",
      "1515 [D loss: 0.382156, op_acc: 89.06%] [G loss: 0.491660]\n",
      "1516 [D loss: 0.320459, op_acc: 82.81%] [G loss: 0.397565]\n",
      "1517 [D loss: 0.252866, op_acc: 92.19%] [G loss: 0.429600]\n",
      "1518 [D loss: 0.374039, op_acc: 81.25%] [G loss: 0.435367]\n",
      "1519 [D loss: 0.288398, op_acc: 85.94%] [G loss: 0.429271]\n",
      "1520 [D loss: 0.429325, op_acc: 78.12%] [G loss: 0.391817]\n",
      "1521 [D loss: 0.400520, op_acc: 76.56%] [G loss: 0.385407]\n",
      "1522 [D loss: 0.290551, op_acc: 89.06%] [G loss: 0.453865]\n",
      "1523 [D loss: 0.379994, op_acc: 78.12%] [G loss: 0.429105]\n",
      "1524 [D loss: 0.337484, op_acc: 85.94%] [G loss: 0.435647]\n",
      "1525 [D loss: 0.326380, op_acc: 81.25%] [G loss: 0.463456]\n",
      "1526 [D loss: 0.293370, op_acc: 82.81%] [G loss: 0.484633]\n",
      "1527 [D loss: 0.280121, op_acc: 89.06%] [G loss: 0.421376]\n",
      "1528 [D loss: 0.368530, op_acc: 81.25%] [G loss: 0.521976]\n",
      "1529 [D loss: 0.358683, op_acc: 79.69%] [G loss: 0.454179]\n",
      "1530 [D loss: 0.285277, op_acc: 87.50%] [G loss: 0.328389]\n",
      "1531 [D loss: 0.421328, op_acc: 73.44%] [G loss: 0.414926]\n",
      "1532 [D loss: 0.462376, op_acc: 75.00%] [G loss: 0.392873]\n",
      "1533 [D loss: 0.351072, op_acc: 82.81%] [G loss: 0.421193]\n",
      "1534 [D loss: 0.377514, op_acc: 79.69%] [G loss: 0.460846]\n",
      "1535 [D loss: 0.436262, op_acc: 81.25%] [G loss: 0.445917]\n",
      "1536 [D loss: 0.308463, op_acc: 85.94%] [G loss: 0.490992]\n",
      "1537 [D loss: 0.359696, op_acc: 82.81%] [G loss: 0.516237]\n",
      "1538 [D loss: 0.313644, op_acc: 84.38%] [G loss: 0.419843]\n",
      "1539 [D loss: 0.309058, op_acc: 85.94%] [G loss: 0.438547]\n",
      "1540 [D loss: 0.352200, op_acc: 84.38%] [G loss: 0.423921]\n",
      "1541 [D loss: 0.369338, op_acc: 81.25%] [G loss: 0.400986]\n",
      "1542 [D loss: 0.405133, op_acc: 81.25%] [G loss: 0.374315]\n",
      "1543 [D loss: 0.386372, op_acc: 79.69%] [G loss: 0.427803]\n",
      "1544 [D loss: 0.482144, op_acc: 78.12%] [G loss: 0.444327]\n",
      "1545 [D loss: 0.290856, op_acc: 87.50%] [G loss: 0.417999]\n",
      "1546 [D loss: 0.535257, op_acc: 68.75%] [G loss: 0.444791]\n",
      "1547 [D loss: 0.357752, op_acc: 84.38%] [G loss: 0.380260]\n",
      "1548 [D loss: 0.324917, op_acc: 89.06%] [G loss: 0.464894]\n",
      "1549 [D loss: 0.333766, op_acc: 85.94%] [G loss: 0.443742]\n",
      "1550 [D loss: 0.505807, op_acc: 71.88%] [G loss: 0.415284]\n",
      "1551 [D loss: 0.337222, op_acc: 81.25%] [G loss: 0.401335]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1552 [D loss: 0.260657, op_acc: 89.06%] [G loss: 0.426429]\n",
      "1553 [D loss: 0.341332, op_acc: 85.94%] [G loss: 0.488595]\n",
      "1554 [D loss: 0.361917, op_acc: 81.25%] [G loss: 0.474794]\n",
      "1555 [D loss: 0.362880, op_acc: 85.94%] [G loss: 0.396622]\n",
      "1556 [D loss: 0.389248, op_acc: 84.38%] [G loss: 0.481634]\n",
      "1557 [D loss: 0.368219, op_acc: 79.69%] [G loss: 0.345576]\n",
      "1558 [D loss: 0.333893, op_acc: 82.81%] [G loss: 0.371412]\n",
      "1559 [D loss: 0.421440, op_acc: 68.75%] [G loss: 0.476861]\n",
      "1560 [D loss: 0.327491, op_acc: 85.94%] [G loss: 0.465118]\n",
      "1561 [D loss: 0.357904, op_acc: 81.25%] [G loss: 0.382478]\n",
      "1562 [D loss: 0.253902, op_acc: 89.06%] [G loss: 0.427649]\n",
      "1563 [D loss: 0.335577, op_acc: 79.69%] [G loss: 0.439422]\n",
      "1564 [D loss: 0.379100, op_acc: 81.25%] [G loss: 0.454672]\n",
      "1565 [D loss: 0.312091, op_acc: 81.25%] [G loss: 0.421919]\n",
      "1566 [D loss: 0.351587, op_acc: 82.81%] [G loss: 0.417647]\n",
      "1567 [D loss: 0.374475, op_acc: 75.00%] [G loss: 0.444694]\n",
      "1568 [D loss: 0.240380, op_acc: 95.31%] [G loss: 0.486167]\n",
      "1569 [D loss: 0.330232, op_acc: 84.38%] [G loss: 0.450658]\n",
      "1570 [D loss: 0.326302, op_acc: 82.81%] [G loss: 0.458261]\n",
      "1571 [D loss: 0.369031, op_acc: 82.81%] [G loss: 0.428729]\n",
      "1572 [D loss: 0.422756, op_acc: 70.31%] [G loss: 0.478160]\n",
      "1573 [D loss: 0.361740, op_acc: 84.38%] [G loss: 0.467487]\n",
      "1574 [D loss: 0.329874, op_acc: 85.94%] [G loss: 0.402151]\n",
      "1575 [D loss: 0.278282, op_acc: 89.06%] [G loss: 0.400802]\n",
      "1576 [D loss: 0.381839, op_acc: 75.00%] [G loss: 0.431744]\n",
      "1577 [D loss: 0.260908, op_acc: 90.62%] [G loss: 0.553035]\n",
      "1578 [D loss: 0.293202, op_acc: 85.94%] [G loss: 0.429987]\n",
      "1579 [D loss: 0.261251, op_acc: 89.06%] [G loss: 0.467107]\n",
      "1580 [D loss: 0.314499, op_acc: 79.69%] [G loss: 0.421822]\n",
      "1581 [D loss: 0.385011, op_acc: 79.69%] [G loss: 0.464453]\n",
      "1582 [D loss: 0.360072, op_acc: 78.12%] [G loss: 0.464699]\n",
      "1583 [D loss: 0.378104, op_acc: 79.69%] [G loss: 0.433002]\n",
      "1584 [D loss: 0.277287, op_acc: 87.50%] [G loss: 0.453700]\n",
      "1585 [D loss: 0.347524, op_acc: 84.38%] [G loss: 0.400785]\n",
      "1586 [D loss: 0.261428, op_acc: 87.50%] [G loss: 0.431366]\n",
      "1587 [D loss: 0.285306, op_acc: 90.62%] [G loss: 0.440274]\n",
      "1588 [D loss: 0.375531, op_acc: 81.25%] [G loss: 0.507607]\n",
      "1589 [D loss: 0.272253, op_acc: 92.19%] [G loss: 0.472935]\n",
      "1590 [D loss: 0.333456, op_acc: 89.06%] [G loss: 0.458883]\n",
      "1591 [D loss: 0.294125, op_acc: 90.62%] [G loss: 0.494075]\n",
      "1592 [D loss: 0.327341, op_acc: 89.06%] [G loss: 0.474433]\n",
      "1593 [D loss: 0.324646, op_acc: 84.38%] [G loss: 0.442236]\n",
      "1594 [D loss: 0.366553, op_acc: 81.25%] [G loss: 0.440192]\n",
      "1595 [D loss: 0.308319, op_acc: 87.50%] [G loss: 0.506224]\n",
      "1596 [D loss: 0.264995, op_acc: 92.19%] [G loss: 0.448682]\n",
      "1597 [D loss: 0.272713, op_acc: 87.50%] [G loss: 0.477277]\n",
      "1598 [D loss: 0.272791, op_acc: 87.50%] [G loss: 0.490641]\n",
      "1599 [D loss: 0.337010, op_acc: 84.38%] [G loss: 0.422743]\n",
      "1600 [D loss: 0.271093, op_acc: 90.62%] [G loss: 0.484632]\n",
      "1601 [D loss: 0.332436, op_acc: 84.38%] [G loss: 0.486328]\n",
      "1602 [D loss: 0.315813, op_acc: 82.81%] [G loss: 0.480486]\n",
      "1603 [D loss: 0.428801, op_acc: 76.56%] [G loss: 0.461815]\n",
      "1604 [D loss: 0.305754, op_acc: 85.94%] [G loss: 0.449465]\n",
      "1605 [D loss: 0.411218, op_acc: 76.56%] [G loss: 0.456561]\n",
      "1606 [D loss: 0.270641, op_acc: 89.06%] [G loss: 0.485744]\n",
      "1607 [D loss: 0.393737, op_acc: 81.25%] [G loss: 0.431801]\n",
      "1608 [D loss: 0.280235, op_acc: 90.62%] [G loss: 0.419589]\n",
      "1609 [D loss: 0.373860, op_acc: 85.94%] [G loss: 0.457947]\n",
      "1610 [D loss: 0.328478, op_acc: 82.81%] [G loss: 0.523169]\n",
      "1611 [D loss: 0.363821, op_acc: 85.94%] [G loss: 0.590044]\n",
      "1612 [D loss: 0.478964, op_acc: 76.56%] [G loss: 0.384681]\n",
      "1613 [D loss: 0.324471, op_acc: 85.94%] [G loss: 0.521319]\n",
      "1614 [D loss: 0.270630, op_acc: 84.38%] [G loss: 0.559574]\n",
      "1615 [D loss: 0.337032, op_acc: 87.50%] [G loss: 0.474692]\n",
      "1616 [D loss: 0.359621, op_acc: 76.56%] [G loss: 0.390457]\n",
      "1617 [D loss: 0.364935, op_acc: 76.56%] [G loss: 0.448692]\n",
      "1618 [D loss: 0.267348, op_acc: 89.06%] [G loss: 0.499144]\n",
      "1619 [D loss: 0.264089, op_acc: 87.50%] [G loss: 0.506934]\n",
      "1620 [D loss: 0.356469, op_acc: 76.56%] [G loss: 0.471766]\n",
      "1621 [D loss: 0.279878, op_acc: 84.38%] [G loss: 0.533153]\n",
      "1622 [D loss: 0.364669, op_acc: 79.69%] [G loss: 0.581503]\n",
      "1623 [D loss: 0.226852, op_acc: 90.62%] [G loss: 0.580557]\n",
      "1624 [D loss: 0.374487, op_acc: 78.12%] [G loss: 0.412731]\n",
      "1625 [D loss: 0.326373, op_acc: 89.06%] [G loss: 0.432024]\n",
      "1626 [D loss: 0.375952, op_acc: 81.25%] [G loss: 0.448018]\n",
      "1627 [D loss: 0.250777, op_acc: 92.19%] [G loss: 0.442485]\n",
      "1628 [D loss: 0.430602, op_acc: 75.00%] [G loss: 0.562333]\n",
      "1629 [D loss: 0.299039, op_acc: 87.50%] [G loss: 0.480641]\n",
      "1630 [D loss: 0.260179, op_acc: 90.62%] [G loss: 0.495598]\n",
      "1631 [D loss: 0.248819, op_acc: 89.06%] [G loss: 0.463802]\n",
      "1632 [D loss: 0.248672, op_acc: 92.19%] [G loss: 0.450517]\n",
      "1633 [D loss: 0.409172, op_acc: 84.38%] [G loss: 0.475819]\n",
      "1634 [D loss: 0.290125, op_acc: 90.62%] [G loss: 0.469864]\n",
      "1635 [D loss: 0.367128, op_acc: 85.94%] [G loss: 0.451004]\n",
      "1636 [D loss: 0.304615, op_acc: 84.38%] [G loss: 0.462453]\n",
      "1637 [D loss: 0.310366, op_acc: 85.94%] [G loss: 0.532608]\n",
      "1638 [D loss: 0.263584, op_acc: 87.50%] [G loss: 0.462912]\n",
      "1639 [D loss: 0.227349, op_acc: 93.75%] [G loss: 0.553456]\n",
      "1640 [D loss: 0.267494, op_acc: 90.62%] [G loss: 0.595415]\n",
      "1641 [D loss: 0.256755, op_acc: 93.75%] [G loss: 0.503495]\n",
      "1642 [D loss: 0.334158, op_acc: 85.94%] [G loss: 0.441869]\n",
      "1643 [D loss: 0.262719, op_acc: 90.62%] [G loss: 0.459791]\n",
      "1644 [D loss: 0.289876, op_acc: 82.81%] [G loss: 0.591854]\n",
      "1645 [D loss: 0.248722, op_acc: 93.75%] [G loss: 0.529670]\n",
      "1646 [D loss: 0.338867, op_acc: 81.25%] [G loss: 0.374238]\n",
      "1647 [D loss: 0.257329, op_acc: 90.62%] [G loss: 0.479954]\n",
      "1648 [D loss: 0.372945, op_acc: 79.69%] [G loss: 0.512929]\n",
      "1649 [D loss: 0.321835, op_acc: 82.81%] [G loss: 0.534216]\n",
      "1650 [D loss: 0.306405, op_acc: 87.50%] [G loss: 0.489107]\n",
      "1651 [D loss: 0.351378, op_acc: 78.12%] [G loss: 0.542550]\n",
      "1652 [D loss: 0.295616, op_acc: 90.62%] [G loss: 0.503385]\n",
      "1653 [D loss: 0.282538, op_acc: 85.94%] [G loss: 0.496366]\n",
      "1654 [D loss: 0.442152, op_acc: 73.44%] [G loss: 0.535767]\n",
      "1655 [D loss: 0.288265, op_acc: 92.19%] [G loss: 0.619188]\n",
      "1656 [D loss: 0.235037, op_acc: 92.19%] [G loss: 0.820768]\n",
      "1657 [D loss: 0.383682, op_acc: 87.50%] [G loss: 0.311740]\n",
      "1658 [D loss: 0.423849, op_acc: 70.31%] [G loss: 0.465202]\n",
      "1659 [D loss: 0.334292, op_acc: 71.88%] [G loss: 0.497237]\n",
      "1660 [D loss: 0.294306, op_acc: 87.50%] [G loss: 0.526049]\n",
      "1661 [D loss: 0.313359, op_acc: 85.94%] [G loss: 0.517175]\n",
      "1662 [D loss: 0.292989, op_acc: 82.81%] [G loss: 0.572756]\n",
      "1663 [D loss: 0.353093, op_acc: 79.69%] [G loss: 0.486805]\n",
      "1664 [D loss: 0.252875, op_acc: 90.62%] [G loss: 0.523924]\n",
      "1665 [D loss: 0.319324, op_acc: 82.81%] [G loss: 0.475926]\n",
      "1666 [D loss: 0.257915, op_acc: 89.06%] [G loss: 0.534123]\n",
      "1667 [D loss: 0.422649, op_acc: 79.69%] [G loss: 0.536703]\n",
      "1668 [D loss: 0.360249, op_acc: 85.94%] [G loss: 0.503656]\n",
      "1669 [D loss: 0.280309, op_acc: 82.81%] [G loss: 0.536161]\n",
      "1670 [D loss: 0.334331, op_acc: 84.38%] [G loss: 0.488686]\n",
      "1671 [D loss: 0.507679, op_acc: 68.75%] [G loss: 0.531383]\n",
      "1672 [D loss: 0.231763, op_acc: 89.06%] [G loss: 0.493006]\n",
      "1673 [D loss: 0.354580, op_acc: 81.25%] [G loss: 0.533877]\n",
      "1674 [D loss: 0.376292, op_acc: 71.88%] [G loss: 0.558109]\n",
      "1675 [D loss: 0.263817, op_acc: 92.19%] [G loss: 0.541313]\n",
      "1676 [D loss: 0.300955, op_acc: 84.38%] [G loss: 0.534514]\n",
      "1677 [D loss: 0.232373, op_acc: 92.19%] [G loss: 0.506781]\n",
      "1678 [D loss: 0.298907, op_acc: 85.94%] [G loss: 0.524001]\n",
      "1679 [D loss: 0.248100, op_acc: 92.19%] [G loss: 0.458345]\n",
      "1680 [D loss: 0.230909, op_acc: 93.75%] [G loss: 0.459050]\n",
      "1681 [D loss: 0.334912, op_acc: 82.81%] [G loss: 0.538995]\n",
      "1682 [D loss: 0.230752, op_acc: 90.62%] [G loss: 0.489014]\n",
      "1683 [D loss: 0.274502, op_acc: 85.94%] [G loss: 0.484147]\n",
      "1684 [D loss: 0.283113, op_acc: 89.06%] [G loss: 0.595884]\n",
      "1685 [D loss: 0.278446, op_acc: 90.62%] [G loss: 0.609413]\n",
      "1686 [D loss: 0.250860, op_acc: 90.62%] [G loss: 0.470794]\n",
      "1687 [D loss: 0.261517, op_acc: 87.50%] [G loss: 0.544160]\n",
      "1688 [D loss: 0.393501, op_acc: 81.25%] [G loss: 0.548985]\n",
      "1689 [D loss: 0.282378, op_acc: 85.94%] [G loss: 0.515693]\n",
      "1690 [D loss: 0.279975, op_acc: 84.38%] [G loss: 0.486473]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1691 [D loss: 0.342165, op_acc: 82.81%] [G loss: 0.520071]\n",
      "1692 [D loss: 0.323113, op_acc: 87.50%] [G loss: 0.532368]\n",
      "1693 [D loss: 0.251542, op_acc: 89.06%] [G loss: 0.587755]\n",
      "1694 [D loss: 0.256590, op_acc: 93.75%] [G loss: 0.480126]\n",
      "1695 [D loss: 0.373529, op_acc: 82.81%] [G loss: 0.502120]\n",
      "1696 [D loss: 0.229397, op_acc: 89.06%] [G loss: 0.548071]\n",
      "1697 [D loss: 0.289548, op_acc: 85.94%] [G loss: 0.579861]\n",
      "1698 [D loss: 0.277227, op_acc: 87.50%] [G loss: 0.478697]\n",
      "1699 [D loss: 0.294214, op_acc: 84.38%] [G loss: 0.566612]\n",
      "1700 [D loss: 0.338949, op_acc: 82.81%] [G loss: 0.526461]\n",
      "1701 [D loss: 0.379968, op_acc: 76.56%] [G loss: 0.509016]\n",
      "1702 [D loss: 0.269149, op_acc: 87.50%] [G loss: 0.543044]\n",
      "1703 [D loss: 0.346773, op_acc: 81.25%] [G loss: 0.567940]\n",
      "1704 [D loss: 0.316893, op_acc: 90.62%] [G loss: 0.466441]\n",
      "1705 [D loss: 0.322241, op_acc: 81.25%] [G loss: 0.523298]\n",
      "1706 [D loss: 0.276262, op_acc: 85.94%] [G loss: 0.575234]\n",
      "1707 [D loss: 0.283661, op_acc: 85.94%] [G loss: 0.557049]\n",
      "1708 [D loss: 0.230688, op_acc: 93.75%] [G loss: 0.535752]\n",
      "1709 [D loss: 0.289163, op_acc: 92.19%] [G loss: 0.605642]\n",
      "1710 [D loss: 0.307934, op_acc: 82.81%] [G loss: 1.003737]\n",
      "1711 [D loss: 0.391813, op_acc: 87.50%] [G loss: 0.646979]\n",
      "1712 [D loss: 0.261835, op_acc: 93.75%] [G loss: 0.431921]\n",
      "1713 [D loss: 0.310086, op_acc: 79.69%] [G loss: 0.570066]\n",
      "1714 [D loss: 0.254635, op_acc: 87.50%] [G loss: 0.504740]\n",
      "1715 [D loss: 0.246729, op_acc: 89.06%] [G loss: 0.527684]\n",
      "1716 [D loss: 0.226273, op_acc: 95.31%] [G loss: 0.552607]\n",
      "1717 [D loss: 0.240743, op_acc: 90.62%] [G loss: 0.636963]\n",
      "1718 [D loss: 0.300825, op_acc: 90.62%] [G loss: 0.525696]\n",
      "1719 [D loss: 0.216874, op_acc: 89.06%] [G loss: 0.559351]\n",
      "1720 [D loss: 0.321213, op_acc: 82.81%] [G loss: 0.568519]\n",
      "1721 [D loss: 0.317866, op_acc: 87.50%] [G loss: 0.504062]\n",
      "1722 [D loss: 0.351462, op_acc: 79.69%] [G loss: 0.621174]\n",
      "1723 [D loss: 0.350778, op_acc: 78.12%] [G loss: 0.575966]\n",
      "1724 [D loss: 0.229496, op_acc: 89.06%] [G loss: 0.578246]\n",
      "1725 [D loss: 0.285737, op_acc: 82.81%] [G loss: 0.561087]\n",
      "1726 [D loss: 0.276553, op_acc: 82.81%] [G loss: 0.543269]\n",
      "1727 [D loss: 0.207036, op_acc: 95.31%] [G loss: 0.538977]\n",
      "1728 [D loss: 0.295469, op_acc: 84.38%] [G loss: 0.524787]\n",
      "1729 [D loss: 0.323800, op_acc: 89.06%] [G loss: 0.518339]\n",
      "1730 [D loss: 0.245729, op_acc: 90.62%] [G loss: 0.646561]\n",
      "1731 [D loss: 0.268057, op_acc: 89.06%] [G loss: 0.687149]\n",
      "1732 [D loss: 0.319774, op_acc: 90.62%] [G loss: 0.475093]\n",
      "1733 [D loss: 0.268990, op_acc: 84.38%] [G loss: 0.572662]\n",
      "1734 [D loss: 0.259325, op_acc: 85.94%] [G loss: 0.617847]\n",
      "1735 [D loss: 0.282859, op_acc: 87.50%] [G loss: 0.523317]\n",
      "1736 [D loss: 0.239391, op_acc: 89.06%] [G loss: 0.592831]\n",
      "1737 [D loss: 0.258877, op_acc: 87.50%] [G loss: 0.550374]\n",
      "1738 [D loss: 0.253783, op_acc: 90.62%] [G loss: 0.505719]\n",
      "1739 [D loss: 0.272344, op_acc: 90.62%] [G loss: 0.603559]\n",
      "1740 [D loss: 0.319430, op_acc: 82.81%] [G loss: 0.575485]\n",
      "1741 [D loss: 0.232479, op_acc: 87.50%] [G loss: 0.583661]\n",
      "1742 [D loss: 0.309286, op_acc: 82.81%] [G loss: 0.578705]\n",
      "1743 [D loss: 0.181771, op_acc: 93.75%] [G loss: 0.803890]\n",
      "1744 [D loss: 0.304224, op_acc: 89.06%] [G loss: 0.571107]\n",
      "1745 [D loss: 0.268789, op_acc: 93.75%] [G loss: 0.643816]\n",
      "1746 [D loss: 0.262960, op_acc: 85.94%] [G loss: 0.631923]\n",
      "1747 [D loss: 0.291302, op_acc: 85.94%] [G loss: 0.623753]\n",
      "1748 [D loss: 0.247691, op_acc: 87.50%] [G loss: 0.599074]\n",
      "1749 [D loss: 0.321513, op_acc: 84.38%] [G loss: 0.613247]\n",
      "1750 [D loss: 0.286913, op_acc: 90.62%] [G loss: 0.566661]\n",
      "1751 [D loss: 0.223568, op_acc: 92.19%] [G loss: 0.550408]\n",
      "1752 [D loss: 0.289688, op_acc: 89.06%] [G loss: 0.605958]\n",
      "1753 [D loss: 0.293122, op_acc: 84.38%] [G loss: 0.714663]\n",
      "1754 [D loss: 0.317339, op_acc: 90.62%] [G loss: 0.582407]\n",
      "1755 [D loss: 0.246004, op_acc: 84.38%] [G loss: 0.608773]\n",
      "1756 [D loss: 0.326190, op_acc: 75.00%] [G loss: 0.703930]\n",
      "1757 [D loss: 0.237468, op_acc: 89.06%] [G loss: 0.654614]\n",
      "1758 [D loss: 0.308356, op_acc: 84.38%] [G loss: 0.567484]\n",
      "1759 [D loss: 0.261016, op_acc: 90.62%] [G loss: 0.530083]\n",
      "1760 [D loss: 0.260175, op_acc: 87.50%] [G loss: 0.620373]\n",
      "1761 [D loss: 0.272168, op_acc: 85.94%] [G loss: 0.534759]\n",
      "1762 [D loss: 0.276493, op_acc: 90.62%] [G loss: 0.660423]\n",
      "1763 [D loss: 0.320016, op_acc: 85.94%] [G loss: 0.654719]\n",
      "1764 [D loss: 0.303776, op_acc: 89.06%] [G loss: 0.617323]\n",
      "1765 [D loss: 0.253688, op_acc: 89.06%] [G loss: 0.582563]\n",
      "1766 [D loss: 0.308776, op_acc: 82.81%] [G loss: 0.574402]\n",
      "1767 [D loss: 0.229350, op_acc: 87.50%] [G loss: 0.599095]\n",
      "1768 [D loss: 0.227979, op_acc: 92.19%] [G loss: 0.598872]\n",
      "1769 [D loss: 0.368320, op_acc: 76.56%] [G loss: 0.626405]\n",
      "1770 [D loss: 0.367767, op_acc: 85.94%] [G loss: 0.594958]\n",
      "1771 [D loss: 0.352678, op_acc: 81.25%] [G loss: 0.554272]\n",
      "1772 [D loss: 0.403694, op_acc: 81.25%] [G loss: 0.506902]\n",
      "1773 [D loss: 0.255084, op_acc: 87.50%] [G loss: 0.611866]\n",
      "1774 [D loss: 0.252784, op_acc: 93.75%] [G loss: 0.598046]\n",
      "1775 [D loss: 0.237337, op_acc: 93.75%] [G loss: 0.542055]\n",
      "1776 [D loss: 0.287823, op_acc: 87.50%] [G loss: 0.537539]\n",
      "1777 [D loss: 0.251012, op_acc: 89.06%] [G loss: 0.555717]\n",
      "1778 [D loss: 0.274264, op_acc: 84.38%] [G loss: 0.562324]\n",
      "1779 [D loss: 0.237599, op_acc: 89.06%] [G loss: 0.660811]\n",
      "1780 [D loss: 0.255580, op_acc: 89.06%] [G loss: 0.575674]\n",
      "1781 [D loss: 0.225004, op_acc: 89.06%] [G loss: 0.545282]\n",
      "1782 [D loss: 0.226527, op_acc: 92.19%] [G loss: 0.610177]\n",
      "1783 [D loss: 0.300524, op_acc: 87.50%] [G loss: 0.677536]\n",
      "1784 [D loss: 0.261178, op_acc: 89.06%] [G loss: 0.608997]\n",
      "1785 [D loss: 0.281852, op_acc: 89.06%] [G loss: 0.626443]\n",
      "1786 [D loss: 0.334348, op_acc: 84.38%] [G loss: 0.633071]\n",
      "1787 [D loss: 0.264283, op_acc: 87.50%] [G loss: 0.720290]\n",
      "1788 [D loss: 0.309468, op_acc: 79.69%] [G loss: 0.589100]\n",
      "1789 [D loss: 0.222934, op_acc: 90.62%] [G loss: 0.757601]\n",
      "1790 [D loss: 0.366795, op_acc: 84.38%] [G loss: 0.732636]\n",
      "1791 [D loss: 0.433864, op_acc: 76.56%] [G loss: 1.282289]\n",
      "1792 [D loss: 0.401937, op_acc: 95.31%] [G loss: 0.342195]\n",
      "1793 [D loss: 0.362432, op_acc: 81.25%] [G loss: 0.933264]\n",
      "1794 [D loss: 0.455600, op_acc: 82.81%] [G loss: 0.630377]\n",
      "1795 [D loss: 0.329355, op_acc: 87.50%] [G loss: 0.721459]\n",
      "1796 [D loss: 0.377468, op_acc: 84.38%] [G loss: 0.392526]\n",
      "1797 [D loss: 0.262872, op_acc: 85.94%] [G loss: 0.629578]\n",
      "1798 [D loss: 0.300673, op_acc: 85.94%] [G loss: 0.672283]\n",
      "1799 [D loss: 0.281714, op_acc: 82.81%] [G loss: 0.583391]\n",
      "1800 [D loss: 0.288475, op_acc: 87.50%] [G loss: 0.581588]\n",
      "1801 [D loss: 0.202259, op_acc: 96.88%] [G loss: 0.604128]\n",
      "1802 [D loss: 0.255367, op_acc: 85.94%] [G loss: 0.547246]\n",
      "1803 [D loss: 0.213633, op_acc: 92.19%] [G loss: 0.616265]\n",
      "1804 [D loss: 0.320082, op_acc: 82.81%] [G loss: 0.583444]\n",
      "1805 [D loss: 0.231582, op_acc: 90.62%] [G loss: 0.558671]\n",
      "1806 [D loss: 0.256628, op_acc: 87.50%] [G loss: 0.558271]\n",
      "1807 [D loss: 0.295136, op_acc: 85.94%] [G loss: 0.597626]\n",
      "1808 [D loss: 0.236533, op_acc: 87.50%] [G loss: 0.630356]\n",
      "1809 [D loss: 0.252960, op_acc: 90.62%] [G loss: 0.580796]\n",
      "1810 [D loss: 0.326292, op_acc: 84.38%] [G loss: 0.640745]\n",
      "1811 [D loss: 0.299788, op_acc: 87.50%] [G loss: 0.596904]\n",
      "1812 [D loss: 0.284458, op_acc: 87.50%] [G loss: 0.571206]\n",
      "1813 [D loss: 0.263719, op_acc: 89.06%] [G loss: 0.656761]\n",
      "1814 [D loss: 0.276331, op_acc: 93.75%] [G loss: 0.602681]\n",
      "1815 [D loss: 0.253660, op_acc: 85.94%] [G loss: 0.651779]\n",
      "1816 [D loss: 0.316461, op_acc: 84.38%] [G loss: 0.577574]\n",
      "1817 [D loss: 0.284011, op_acc: 84.38%] [G loss: 0.539318]\n",
      "1818 [D loss: 0.302614, op_acc: 81.25%] [G loss: 0.654850]\n",
      "1819 [D loss: 0.292005, op_acc: 87.50%] [G loss: 0.634182]\n",
      "1820 [D loss: 0.248117, op_acc: 92.19%] [G loss: 0.520681]\n",
      "1821 [D loss: 0.256635, op_acc: 85.94%] [G loss: 0.657223]\n",
      "1822 [D loss: 0.279362, op_acc: 84.38%] [G loss: 0.638466]\n",
      "1823 [D loss: 0.284382, op_acc: 84.38%] [G loss: 0.685912]\n",
      "1824 [D loss: 0.269193, op_acc: 90.62%] [G loss: 0.600114]\n",
      "1825 [D loss: 0.317568, op_acc: 85.94%] [G loss: 0.633105]\n",
      "1826 [D loss: 0.260064, op_acc: 90.62%] [G loss: 0.597801]\n",
      "1827 [D loss: 0.291027, op_acc: 84.38%] [G loss: 0.639513]\n",
      "1828 [D loss: 0.223418, op_acc: 92.19%] [G loss: 0.574835]\n",
      "1829 [D loss: 0.250903, op_acc: 84.38%] [G loss: 0.696124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1830 [D loss: 0.196884, op_acc: 96.88%] [G loss: 0.635091]\n",
      "1831 [D loss: 0.297002, op_acc: 82.81%] [G loss: 0.762833]\n",
      "1832 [D loss: 0.203047, op_acc: 95.31%] [G loss: 0.657521]\n",
      "1833 [D loss: 0.147812, op_acc: 96.88%] [G loss: 0.727230]\n",
      "1834 [D loss: 0.313186, op_acc: 84.38%] [G loss: 0.758905]\n",
      "1835 [D loss: 0.194062, op_acc: 92.19%] [G loss: 0.667955]\n",
      "1836 [D loss: 0.226202, op_acc: 90.62%] [G loss: 0.618884]\n",
      "1837 [D loss: 0.282934, op_acc: 82.81%] [G loss: 0.638042]\n",
      "1838 [D loss: 0.320414, op_acc: 79.69%] [G loss: 0.643883]\n",
      "1839 [D loss: 0.247264, op_acc: 87.50%] [G loss: 0.660890]\n",
      "1840 [D loss: 0.227239, op_acc: 92.19%] [G loss: 0.663292]\n",
      "1841 [D loss: 0.240978, op_acc: 87.50%] [G loss: 0.677588]\n",
      "1842 [D loss: 0.165295, op_acc: 95.31%] [G loss: 0.740919]\n",
      "1843 [D loss: 0.353553, op_acc: 81.25%] [G loss: 0.655349]\n",
      "1844 [D loss: 0.226809, op_acc: 90.62%] [G loss: 0.668256]\n",
      "1845 [D loss: 0.304903, op_acc: 84.38%] [G loss: 0.799607]\n",
      "1846 [D loss: 0.227083, op_acc: 92.19%] [G loss: 0.660919]\n",
      "1847 [D loss: 0.294634, op_acc: 82.81%] [G loss: 0.654965]\n",
      "1848 [D loss: 0.265696, op_acc: 85.94%] [G loss: 0.657020]\n",
      "1849 [D loss: 0.214969, op_acc: 90.62%] [G loss: 0.794741]\n",
      "1850 [D loss: 0.232443, op_acc: 89.06%] [G loss: 0.727884]\n",
      "1851 [D loss: 0.280032, op_acc: 87.50%] [G loss: 0.724319]\n",
      "1852 [D loss: 0.217204, op_acc: 90.62%] [G loss: 0.921795]\n",
      "1853 [D loss: 0.321786, op_acc: 82.81%] [G loss: 0.844322]\n",
      "1854 [D loss: 0.287373, op_acc: 89.06%] [G loss: 0.978461]\n",
      "1855 [D loss: 0.430760, op_acc: 84.38%] [G loss: 0.647115]\n",
      "1856 [D loss: 0.244097, op_acc: 90.62%] [G loss: 0.695381]\n",
      "1857 [D loss: 0.212227, op_acc: 89.06%] [G loss: 0.647026]\n",
      "1858 [D loss: 0.284848, op_acc: 85.94%] [G loss: 0.663960]\n",
      "1859 [D loss: 0.179535, op_acc: 90.62%] [G loss: 0.770211]\n",
      "1860 [D loss: 0.264863, op_acc: 89.06%] [G loss: 0.731988]\n",
      "1861 [D loss: 0.279089, op_acc: 85.94%] [G loss: 0.657502]\n",
      "1862 [D loss: 0.183008, op_acc: 93.75%] [G loss: 0.746776]\n",
      "1863 [D loss: 0.291509, op_acc: 85.94%] [G loss: 0.708519]\n",
      "1864 [D loss: 0.240393, op_acc: 89.06%] [G loss: 0.651363]\n",
      "1865 [D loss: 0.360476, op_acc: 82.81%] [G loss: 0.637671]\n",
      "1866 [D loss: 0.276278, op_acc: 84.38%] [G loss: 0.706667]\n",
      "1867 [D loss: 0.319982, op_acc: 89.06%] [G loss: 0.700806]\n",
      "1868 [D loss: 0.229054, op_acc: 92.19%] [G loss: 0.747327]\n",
      "1869 [D loss: 0.225470, op_acc: 89.06%] [G loss: 0.733614]\n",
      "1870 [D loss: 0.201703, op_acc: 92.19%] [G loss: 0.687425]\n",
      "1871 [D loss: 0.249922, op_acc: 87.50%] [G loss: 0.683051]\n",
      "1872 [D loss: 0.226785, op_acc: 89.06%] [G loss: 0.753337]\n",
      "1873 [D loss: 0.216774, op_acc: 92.19%] [G loss: 0.736055]\n",
      "1874 [D loss: 0.195008, op_acc: 92.19%] [G loss: 0.697430]\n",
      "1875 [D loss: 0.241332, op_acc: 90.62%] [G loss: 0.721401]\n",
      "1876 [D loss: 0.256212, op_acc: 89.06%] [G loss: 0.768954]\n",
      "1877 [D loss: 0.272646, op_acc: 87.50%] [G loss: 0.740818]\n",
      "1878 [D loss: 0.216957, op_acc: 90.62%] [G loss: 0.734807]\n",
      "1879 [D loss: 0.359314, op_acc: 82.81%] [G loss: 0.720364]\n",
      "1880 [D loss: 0.186083, op_acc: 90.62%] [G loss: 0.806045]\n",
      "1881 [D loss: 0.211762, op_acc: 92.19%] [G loss: 0.772733]\n",
      "1882 [D loss: 0.268889, op_acc: 89.06%] [G loss: 0.741498]\n",
      "1883 [D loss: 0.310178, op_acc: 84.38%] [G loss: 0.840014]\n",
      "1884 [D loss: 0.253338, op_acc: 89.06%] [G loss: 0.790418]\n",
      "1885 [D loss: 0.230575, op_acc: 92.19%] [G loss: 0.651151]\n",
      "1886 [D loss: 0.167661, op_acc: 95.31%] [G loss: 0.727952]\n",
      "1887 [D loss: 0.217574, op_acc: 90.62%] [G loss: 0.728618]\n",
      "1888 [D loss: 0.206154, op_acc: 96.88%] [G loss: 0.691112]\n",
      "1889 [D loss: 0.267310, op_acc: 84.38%] [G loss: 0.899027]\n",
      "1890 [D loss: 0.246028, op_acc: 92.19%] [G loss: 0.787763]\n",
      "1891 [D loss: 0.219486, op_acc: 89.06%] [G loss: 0.739144]\n",
      "1892 [D loss: 0.164692, op_acc: 95.31%] [G loss: 0.853941]\n",
      "1893 [D loss: 0.230356, op_acc: 89.06%] [G loss: 0.731292]\n",
      "1894 [D loss: 0.190509, op_acc: 95.31%] [G loss: 0.670907]\n",
      "1895 [D loss: 0.320016, op_acc: 81.25%] [G loss: 0.672872]\n",
      "1896 [D loss: 0.242748, op_acc: 89.06%] [G loss: 0.821770]\n",
      "1897 [D loss: 0.255046, op_acc: 87.50%] [G loss: 0.830581]\n",
      "1898 [D loss: 0.304049, op_acc: 87.50%] [G loss: 1.113448]\n",
      "1899 [D loss: 0.257980, op_acc: 84.38%] [G loss: 0.786429]\n",
      "1900 [D loss: 0.338196, op_acc: 81.25%] [G loss: 0.837208]\n",
      "1901 [D loss: 0.401940, op_acc: 81.25%] [G loss: 0.701115]\n",
      "1902 [D loss: 0.146010, op_acc: 96.88%] [G loss: 0.799098]\n",
      "1903 [D loss: 0.244006, op_acc: 85.94%] [G loss: 0.821600]\n",
      "1904 [D loss: 0.338866, op_acc: 82.81%] [G loss: 0.921148]\n",
      "1905 [D loss: 0.332570, op_acc: 81.25%] [G loss: 0.819951]\n",
      "1906 [D loss: 0.236214, op_acc: 93.75%] [G loss: 0.589639]\n",
      "1907 [D loss: 0.369534, op_acc: 84.38%] [G loss: 0.852445]\n",
      "1908 [D loss: 0.245210, op_acc: 90.62%] [G loss: 0.797393]\n",
      "1909 [D loss: 0.224473, op_acc: 92.19%] [G loss: 0.749028]\n",
      "1910 [D loss: 0.323665, op_acc: 84.38%] [G loss: 0.888600]\n",
      "1911 [D loss: 0.328057, op_acc: 84.38%] [G loss: 0.601753]\n",
      "1912 [D loss: 0.236091, op_acc: 85.94%] [G loss: 0.766765]\n",
      "1913 [D loss: 0.308041, op_acc: 82.81%] [G loss: 0.638789]\n",
      "1914 [D loss: 0.202793, op_acc: 92.19%] [G loss: 0.779840]\n",
      "1915 [D loss: 0.288678, op_acc: 82.81%] [G loss: 0.697525]\n",
      "1916 [D loss: 0.176794, op_acc: 93.75%] [G loss: 0.720985]\n",
      "1917 [D loss: 0.262681, op_acc: 87.50%] [G loss: 0.742056]\n",
      "1918 [D loss: 0.203525, op_acc: 90.62%] [G loss: 0.714433]\n",
      "1919 [D loss: 0.177955, op_acc: 92.19%] [G loss: 0.831831]\n",
      "1920 [D loss: 0.236101, op_acc: 84.38%] [G loss: 0.771332]\n",
      "1921 [D loss: 0.184838, op_acc: 90.62%] [G loss: 0.742340]\n",
      "1922 [D loss: 0.177082, op_acc: 93.75%] [G loss: 0.680277]\n",
      "1923 [D loss: 0.216997, op_acc: 92.19%] [G loss: 0.823004]\n",
      "1924 [D loss: 0.260051, op_acc: 84.38%] [G loss: 0.912280]\n",
      "1925 [D loss: 0.245842, op_acc: 93.75%] [G loss: 0.799371]\n",
      "1926 [D loss: 0.291272, op_acc: 89.06%] [G loss: 0.833739]\n",
      "1927 [D loss: 0.204109, op_acc: 95.31%] [G loss: 0.778721]\n",
      "1928 [D loss: 0.362754, op_acc: 78.12%] [G loss: 0.903019]\n",
      "1929 [D loss: 0.230129, op_acc: 93.75%] [G loss: 1.055912]\n",
      "1930 [D loss: 0.452259, op_acc: 84.38%] [G loss: 0.948843]\n",
      "1931 [D loss: 0.307834, op_acc: 87.50%] [G loss: 0.725035]\n",
      "1932 [D loss: 0.249264, op_acc: 84.38%] [G loss: 0.763575]\n",
      "1933 [D loss: 0.302575, op_acc: 79.69%] [G loss: 0.705376]\n",
      "1934 [D loss: 0.243743, op_acc: 87.50%] [G loss: 0.707704]\n",
      "1935 [D loss: 0.151342, op_acc: 96.88%] [G loss: 0.858942]\n",
      "1936 [D loss: 0.338307, op_acc: 85.94%] [G loss: 0.661651]\n",
      "1937 [D loss: 0.292519, op_acc: 87.50%] [G loss: 0.804194]\n",
      "1938 [D loss: 0.243425, op_acc: 92.19%] [G loss: 0.833209]\n",
      "1939 [D loss: 0.174296, op_acc: 90.62%] [G loss: 0.832324]\n",
      "1940 [D loss: 0.255364, op_acc: 89.06%] [G loss: 0.669576]\n",
      "1941 [D loss: 0.331398, op_acc: 85.94%] [G loss: 0.828977]\n",
      "1942 [D loss: 0.286221, op_acc: 87.50%] [G loss: 0.855247]\n",
      "1943 [D loss: 0.144876, op_acc: 95.31%] [G loss: 0.766069]\n",
      "1944 [D loss: 0.220539, op_acc: 89.06%] [G loss: 0.837914]\n",
      "1945 [D loss: 0.265339, op_acc: 82.81%] [G loss: 0.920353]\n",
      "1946 [D loss: 0.225178, op_acc: 89.06%] [G loss: 0.808332]\n",
      "1947 [D loss: 0.220172, op_acc: 92.19%] [G loss: 0.674827]\n",
      "1948 [D loss: 0.266172, op_acc: 85.94%] [G loss: 0.863452]\n",
      "1949 [D loss: 0.203907, op_acc: 93.75%] [G loss: 0.799523]\n",
      "1950 [D loss: 0.222716, op_acc: 87.50%] [G loss: 0.794900]\n",
      "1951 [D loss: 0.247672, op_acc: 90.62%] [G loss: 0.787619]\n",
      "1952 [D loss: 0.254111, op_acc: 87.50%] [G loss: 0.794760]\n",
      "1953 [D loss: 0.217500, op_acc: 89.06%] [G loss: 0.786253]\n",
      "1954 [D loss: 0.246114, op_acc: 85.94%] [G loss: 0.681107]\n",
      "1955 [D loss: 0.225626, op_acc: 84.38%] [G loss: 0.920421]\n",
      "1956 [D loss: 0.343133, op_acc: 84.38%] [G loss: 0.669411]\n",
      "1957 [D loss: 0.302646, op_acc: 81.25%] [G loss: 0.781147]\n",
      "1958 [D loss: 0.337421, op_acc: 79.69%] [G loss: 0.856241]\n",
      "1959 [D loss: 0.278785, op_acc: 85.94%] [G loss: 0.982548]\n",
      "1960 [D loss: 0.336117, op_acc: 81.25%] [G loss: 0.968167]\n",
      "1961 [D loss: 0.291329, op_acc: 82.81%] [G loss: 0.775998]\n",
      "1962 [D loss: 0.192116, op_acc: 89.06%] [G loss: 0.854441]\n",
      "1963 [D loss: 0.229019, op_acc: 82.81%] [G loss: 1.031631]\n",
      "1964 [D loss: 0.171849, op_acc: 95.31%] [G loss: 0.834911]\n",
      "1965 [D loss: 0.377797, op_acc: 75.00%] [G loss: 1.043238]\n",
      "1966 [D loss: 0.266174, op_acc: 90.62%] [G loss: 1.032518]\n",
      "1967 [D loss: 0.310594, op_acc: 79.69%] [G loss: 1.473219]\n",
      "1968 [D loss: 0.449817, op_acc: 87.50%] [G loss: 0.542802]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1969 [D loss: 0.327299, op_acc: 78.12%] [G loss: 1.577039]\n",
      "1970 [D loss: 0.420105, op_acc: 78.12%] [G loss: 2.924873]\n",
      "1971 [D loss: 1.308781, op_acc: 51.56%] [G loss: 2.507387]\n",
      "1972 [D loss: 1.408239, op_acc: 56.25%] [G loss: 0.110993]\n",
      "1973 [D loss: 0.372515, op_acc: 82.81%] [G loss: 0.473363]\n",
      "1974 [D loss: 0.267704, op_acc: 82.81%] [G loss: 0.579070]\n",
      "1975 [D loss: 0.360953, op_acc: 84.38%] [G loss: 0.541567]\n",
      "1976 [D loss: 0.262330, op_acc: 93.75%] [G loss: 0.460581]\n",
      "1977 [D loss: 0.267685, op_acc: 87.50%] [G loss: 0.482623]\n",
      "1978 [D loss: 0.209019, op_acc: 92.19%] [G loss: 0.452829]\n",
      "1979 [D loss: 0.287572, op_acc: 87.50%] [G loss: 0.470546]\n",
      "1980 [D loss: 0.257111, op_acc: 89.06%] [G loss: 0.509553]\n",
      "1981 [D loss: 0.221032, op_acc: 93.75%] [G loss: 0.507702]\n",
      "1982 [D loss: 0.288946, op_acc: 82.81%] [G loss: 0.510867]\n",
      "1983 [D loss: 0.235731, op_acc: 92.19%] [G loss: 0.520701]\n",
      "1984 [D loss: 0.360071, op_acc: 90.62%] [G loss: 0.508567]\n",
      "1985 [D loss: 0.198748, op_acc: 93.75%] [G loss: 0.504161]\n",
      "1986 [D loss: 0.250803, op_acc: 87.50%] [G loss: 0.567771]\n",
      "1987 [D loss: 0.249506, op_acc: 89.06%] [G loss: 0.511312]\n",
      "1988 [D loss: 0.234090, op_acc: 87.50%] [G loss: 0.512599]\n",
      "1989 [D loss: 0.265680, op_acc: 85.94%] [G loss: 0.489950]\n",
      "1990 [D loss: 0.230305, op_acc: 90.62%] [G loss: 0.542643]\n",
      "1991 [D loss: 0.190801, op_acc: 92.19%] [G loss: 0.490670]\n",
      "1992 [D loss: 0.207323, op_acc: 90.62%] [G loss: 0.531991]\n",
      "1993 [D loss: 0.231391, op_acc: 93.75%] [G loss: 0.552252]\n",
      "1994 [D loss: 0.270003, op_acc: 89.06%] [G loss: 0.502234]\n",
      "1995 [D loss: 0.159791, op_acc: 98.44%] [G loss: 0.559978]\n",
      "1996 [D loss: 0.221352, op_acc: 87.50%] [G loss: 0.583290]\n",
      "1997 [D loss: 0.288173, op_acc: 87.50%] [G loss: 0.543065]\n",
      "1998 [D loss: 0.245788, op_acc: 89.06%] [G loss: 0.535865]\n",
      "1999 [D loss: 0.176606, op_acc: 89.06%] [G loss: 0.626384]\n",
      "2000 [D loss: 0.281504, op_acc: 85.94%] [G loss: 0.601456]\n",
      "2001 [D loss: 0.254409, op_acc: 89.06%] [G loss: 0.605958]\n",
      "2002 [D loss: 0.372149, op_acc: 81.25%] [G loss: 0.546752]\n",
      "2003 [D loss: 0.190338, op_acc: 93.75%] [G loss: 0.620567]\n",
      "2004 [D loss: 0.218849, op_acc: 90.62%] [G loss: 0.640441]\n",
      "2005 [D loss: 0.188184, op_acc: 92.19%] [G loss: 0.578590]\n",
      "2006 [D loss: 0.225637, op_acc: 90.62%] [G loss: 0.643328]\n",
      "2007 [D loss: 0.207341, op_acc: 92.19%] [G loss: 0.612841]\n",
      "2008 [D loss: 0.309736, op_acc: 89.06%] [G loss: 0.606083]\n",
      "2009 [D loss: 0.275139, op_acc: 82.81%] [G loss: 0.628918]\n",
      "2010 [D loss: 0.213923, op_acc: 93.75%] [G loss: 0.618480]\n",
      "2011 [D loss: 0.185505, op_acc: 93.75%] [G loss: 0.613194]\n",
      "2012 [D loss: 0.258054, op_acc: 85.94%] [G loss: 0.630154]\n",
      "2013 [D loss: 0.192831, op_acc: 93.75%] [G loss: 0.581591]\n",
      "2014 [D loss: 0.219574, op_acc: 92.19%] [G loss: 0.658488]\n",
      "2015 [D loss: 0.177126, op_acc: 93.75%] [G loss: 0.682325]\n",
      "2016 [D loss: 0.275741, op_acc: 84.38%] [G loss: 0.570619]\n",
      "2017 [D loss: 0.286659, op_acc: 89.06%] [G loss: 0.681578]\n",
      "2018 [D loss: 0.187532, op_acc: 90.62%] [G loss: 0.680031]\n",
      "2019 [D loss: 0.244128, op_acc: 84.38%] [G loss: 0.713140]\n",
      "2020 [D loss: 0.188379, op_acc: 93.75%] [G loss: 0.619723]\n",
      "2021 [D loss: 0.322185, op_acc: 82.81%] [G loss: 0.623069]\n",
      "2022 [D loss: 0.199529, op_acc: 90.62%] [G loss: 0.653125]\n",
      "2023 [D loss: 0.151493, op_acc: 98.44%] [G loss: 0.670785]\n",
      "2024 [D loss: 0.203104, op_acc: 93.75%] [G loss: 0.663647]\n",
      "2025 [D loss: 0.179149, op_acc: 92.19%] [G loss: 0.738239]\n",
      "2026 [D loss: 0.217896, op_acc: 89.06%] [G loss: 0.635303]\n",
      "2027 [D loss: 0.287846, op_acc: 87.50%] [G loss: 0.700985]\n",
      "2028 [D loss: 0.127062, op_acc: 98.44%] [G loss: 0.716668]\n",
      "2029 [D loss: 0.265084, op_acc: 82.81%] [G loss: 0.631392]\n",
      "2030 [D loss: 0.227454, op_acc: 89.06%] [G loss: 0.791208]\n",
      "2031 [D loss: 0.231692, op_acc: 89.06%] [G loss: 0.699839]\n",
      "2032 [D loss: 0.209638, op_acc: 92.19%] [G loss: 0.776394]\n",
      "2033 [D loss: 0.124795, op_acc: 98.44%] [G loss: 0.729811]\n",
      "2034 [D loss: 0.346746, op_acc: 78.12%] [G loss: 0.747207]\n",
      "2035 [D loss: 0.205439, op_acc: 89.06%] [G loss: 0.721814]\n",
      "2036 [D loss: 0.351152, op_acc: 81.25%] [G loss: 0.763233]\n",
      "2037 [D loss: 0.166361, op_acc: 92.19%] [G loss: 0.733709]\n",
      "2038 [D loss: 0.299221, op_acc: 85.94%] [G loss: 0.720544]\n",
      "2039 [D loss: 0.146949, op_acc: 90.62%] [G loss: 0.728012]\n",
      "2040 [D loss: 0.274736, op_acc: 85.94%] [G loss: 0.641029]\n",
      "2041 [D loss: 0.218830, op_acc: 93.75%] [G loss: 0.833364]\n",
      "2042 [D loss: 0.220857, op_acc: 90.62%] [G loss: 0.714478]\n",
      "2043 [D loss: 0.309605, op_acc: 85.94%] [G loss: 0.798851]\n",
      "2044 [D loss: 0.257410, op_acc: 89.06%] [G loss: 0.739035]\n",
      "2045 [D loss: 0.193613, op_acc: 93.75%] [G loss: 0.680110]\n",
      "2046 [D loss: 0.178344, op_acc: 90.62%] [G loss: 0.753293]\n",
      "2047 [D loss: 0.203791, op_acc: 89.06%] [G loss: 0.685055]\n",
      "2048 [D loss: 0.329436, op_acc: 78.12%] [G loss: 0.706489]\n",
      "2049 [D loss: 0.133746, op_acc: 95.31%] [G loss: 0.800428]\n",
      "2050 [D loss: 0.182397, op_acc: 90.62%] [G loss: 0.804216]\n",
      "2051 [D loss: 0.149196, op_acc: 95.31%] [G loss: 0.850260]\n",
      "2052 [D loss: 0.221357, op_acc: 90.62%] [G loss: 0.791855]\n",
      "2053 [D loss: 0.187888, op_acc: 96.88%] [G loss: 0.716640]\n",
      "2054 [D loss: 0.181635, op_acc: 90.62%] [G loss: 0.804739]\n",
      "2055 [D loss: 0.206251, op_acc: 87.50%] [G loss: 0.749571]\n",
      "2056 [D loss: 0.291843, op_acc: 82.81%] [G loss: 0.817624]\n",
      "2057 [D loss: 0.153771, op_acc: 93.75%] [G loss: 0.789044]\n",
      "2058 [D loss: 0.264834, op_acc: 87.50%] [G loss: 0.752454]\n",
      "2059 [D loss: 0.343330, op_acc: 81.25%] [G loss: 0.705844]\n",
      "2060 [D loss: 0.175433, op_acc: 92.19%] [G loss: 0.813119]\n",
      "2061 [D loss: 0.283986, op_acc: 85.94%] [G loss: 0.797433]\n",
      "2062 [D loss: 0.292595, op_acc: 82.81%] [G loss: 0.723653]\n",
      "2063 [D loss: 0.243574, op_acc: 90.62%] [G loss: 0.764176]\n",
      "2064 [D loss: 0.212652, op_acc: 90.62%] [G loss: 0.828461]\n",
      "2065 [D loss: 0.199588, op_acc: 90.62%] [G loss: 0.923843]\n",
      "2066 [D loss: 0.209714, op_acc: 92.19%] [G loss: 0.751212]\n",
      "2067 [D loss: 0.229381, op_acc: 87.50%] [G loss: 0.852357]\n",
      "2068 [D loss: 0.223524, op_acc: 92.19%] [G loss: 0.704466]\n",
      "2069 [D loss: 0.173094, op_acc: 90.62%] [G loss: 0.932872]\n",
      "2070 [D loss: 0.216447, op_acc: 90.62%] [G loss: 0.694495]\n",
      "2071 [D loss: 0.167127, op_acc: 95.31%] [G loss: 0.835785]\n",
      "2072 [D loss: 0.183167, op_acc: 90.62%] [G loss: 0.788430]\n",
      "2073 [D loss: 0.160977, op_acc: 93.75%] [G loss: 0.809642]\n",
      "2074 [D loss: 0.219887, op_acc: 90.62%] [G loss: 0.856232]\n",
      "2075 [D loss: 0.366511, op_acc: 78.12%] [G loss: 0.875962]\n",
      "2076 [D loss: 0.186112, op_acc: 95.31%] [G loss: 0.736752]\n",
      "2077 [D loss: 0.295952, op_acc: 75.00%] [G loss: 0.955885]\n",
      "2078 [D loss: 0.230274, op_acc: 87.50%] [G loss: 0.766768]\n",
      "2079 [D loss: 0.279087, op_acc: 81.25%] [G loss: 0.794943]\n",
      "2080 [D loss: 0.151970, op_acc: 96.88%] [G loss: 0.872004]\n",
      "2081 [D loss: 0.186715, op_acc: 92.19%] [G loss: 0.887000]\n",
      "2082 [D loss: 0.251929, op_acc: 87.50%] [G loss: 0.878229]\n",
      "2083 [D loss: 0.193071, op_acc: 90.62%] [G loss: 0.885802]\n",
      "2084 [D loss: 0.305248, op_acc: 79.69%] [G loss: 0.913269]\n",
      "2085 [D loss: 0.204355, op_acc: 92.19%] [G loss: 0.748640]\n",
      "2086 [D loss: 0.280558, op_acc: 84.38%] [G loss: 0.809262]\n",
      "2087 [D loss: 0.177952, op_acc: 93.75%] [G loss: 0.858583]\n",
      "2088 [D loss: 0.234931, op_acc: 84.38%] [G loss: 0.738878]\n",
      "2089 [D loss: 0.209696, op_acc: 90.62%] [G loss: 0.809202]\n",
      "2090 [D loss: 0.145638, op_acc: 93.75%] [G loss: 0.916405]\n",
      "2091 [D loss: 0.156245, op_acc: 92.19%] [G loss: 0.838921]\n",
      "2092 [D loss: 0.212558, op_acc: 92.19%] [G loss: 0.787820]\n",
      "2093 [D loss: 0.203946, op_acc: 87.50%] [G loss: 0.971061]\n",
      "2094 [D loss: 0.230087, op_acc: 89.06%] [G loss: 0.838438]\n",
      "2095 [D loss: 0.265881, op_acc: 87.50%] [G loss: 0.768157]\n",
      "2096 [D loss: 0.143210, op_acc: 93.75%] [G loss: 0.851881]\n",
      "2097 [D loss: 0.209091, op_acc: 85.94%] [G loss: 0.850850]\n",
      "2098 [D loss: 0.179692, op_acc: 93.75%] [G loss: 0.765214]\n",
      "2099 [D loss: 0.172432, op_acc: 93.75%] [G loss: 0.834530]\n",
      "2100 [D loss: 0.234204, op_acc: 85.94%] [G loss: 0.919403]\n",
      "2101 [D loss: 0.208555, op_acc: 89.06%] [G loss: 0.872978]\n",
      "2102 [D loss: 0.209820, op_acc: 90.62%] [G loss: 0.952927]\n",
      "2103 [D loss: 0.343883, op_acc: 79.69%] [G loss: 0.993893]\n",
      "2104 [D loss: 0.244799, op_acc: 82.81%] [G loss: 0.855537]\n",
      "2105 [D loss: 0.256960, op_acc: 87.50%] [G loss: 0.778551]\n",
      "2106 [D loss: 0.181113, op_acc: 89.06%] [G loss: 0.890742]\n",
      "2107 [D loss: 0.203262, op_acc: 90.62%] [G loss: 0.805058]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2108 [D loss: 0.187541, op_acc: 89.06%] [G loss: 0.887614]\n",
      "2109 [D loss: 0.264789, op_acc: 82.81%] [G loss: 0.883090]\n",
      "2110 [D loss: 0.165198, op_acc: 93.75%] [G loss: 0.921768]\n",
      "2111 [D loss: 0.201282, op_acc: 87.50%] [G loss: 0.970988]\n",
      "2112 [D loss: 0.161558, op_acc: 89.06%] [G loss: 0.873917]\n",
      "2113 [D loss: 0.308503, op_acc: 81.25%] [G loss: 0.992765]\n",
      "2114 [D loss: 0.102605, op_acc: 100.00%] [G loss: 0.890361]\n",
      "2115 [D loss: 0.190563, op_acc: 90.62%] [G loss: 0.939315]\n",
      "2116 [D loss: 0.188330, op_acc: 90.62%] [G loss: 0.975050]\n",
      "2117 [D loss: 0.232693, op_acc: 90.62%] [G loss: 1.225670]\n",
      "2118 [D loss: 0.312613, op_acc: 89.06%] [G loss: 0.785484]\n",
      "2119 [D loss: 0.133251, op_acc: 95.31%] [G loss: 1.126082]\n",
      "2120 [D loss: 0.215861, op_acc: 90.62%] [G loss: 0.731124]\n",
      "2121 [D loss: 0.223445, op_acc: 84.38%] [G loss: 0.753640]\n",
      "2122 [D loss: 0.230823, op_acc: 87.50%] [G loss: 0.975948]\n",
      "2123 [D loss: 0.197848, op_acc: 93.75%] [G loss: 0.801992]\n",
      "2124 [D loss: 0.176751, op_acc: 93.75%] [G loss: 0.808546]\n",
      "2125 [D loss: 0.124520, op_acc: 95.31%] [G loss: 1.012127]\n",
      "2126 [D loss: 0.277615, op_acc: 82.81%] [G loss: 0.928757]\n",
      "2127 [D loss: 0.267702, op_acc: 84.38%] [G loss: 0.865674]\n",
      "2128 [D loss: 0.168649, op_acc: 93.75%] [G loss: 0.696730]\n",
      "2129 [D loss: 0.150384, op_acc: 95.31%] [G loss: 0.936622]\n",
      "2130 [D loss: 0.160838, op_acc: 95.31%] [G loss: 0.874031]\n",
      "2131 [D loss: 0.128043, op_acc: 96.88%] [G loss: 0.899102]\n",
      "2132 [D loss: 0.185151, op_acc: 95.31%] [G loss: 0.896771]\n",
      "2133 [D loss: 0.292570, op_acc: 85.94%] [G loss: 0.859487]\n",
      "2134 [D loss: 0.146140, op_acc: 95.31%] [G loss: 0.905335]\n",
      "2135 [D loss: 0.140519, op_acc: 95.31%] [G loss: 0.886958]\n",
      "2136 [D loss: 0.138497, op_acc: 96.88%] [G loss: 0.778445]\n",
      "2137 [D loss: 0.179600, op_acc: 92.19%] [G loss: 1.054798]\n",
      "2138 [D loss: 0.180010, op_acc: 92.19%] [G loss: 0.822621]\n",
      "2139 [D loss: 0.271585, op_acc: 92.19%] [G loss: 1.077165]\n",
      "2140 [D loss: 0.177167, op_acc: 92.19%] [G loss: 0.873299]\n",
      "2141 [D loss: 0.160338, op_acc: 92.19%] [G loss: 0.860487]\n",
      "2142 [D loss: 0.224617, op_acc: 87.50%] [G loss: 0.836779]\n",
      "2143 [D loss: 0.100287, op_acc: 98.44%] [G loss: 0.891383]\n",
      "2144 [D loss: 0.100207, op_acc: 100.00%] [G loss: 0.874081]\n",
      "2145 [D loss: 0.176238, op_acc: 93.75%] [G loss: 0.934050]\n",
      "2146 [D loss: 0.107233, op_acc: 96.88%] [G loss: 1.017827]\n",
      "2147 [D loss: 0.177538, op_acc: 90.62%] [G loss: 0.810139]\n",
      "2148 [D loss: 0.127071, op_acc: 95.31%] [G loss: 0.910710]\n",
      "2149 [D loss: 0.107405, op_acc: 96.88%] [G loss: 0.900135]\n",
      "2150 [D loss: 0.126329, op_acc: 98.44%] [G loss: 0.842510]\n",
      "2151 [D loss: 0.201719, op_acc: 93.75%] [G loss: 1.064476]\n",
      "2152 [D loss: 0.186221, op_acc: 90.62%] [G loss: 1.124905]\n",
      "2153 [D loss: 0.168012, op_acc: 95.31%] [G loss: 1.329295]\n",
      "2154 [D loss: 0.329674, op_acc: 78.12%] [G loss: 2.159271]\n",
      "2155 [D loss: 0.322862, op_acc: 90.62%] [G loss: 4.413079]\n",
      "2156 [D loss: 0.785207, op_acc: 92.19%] [G loss: 4.960088]\n",
      "2157 [D loss: 2.347892, op_acc: 65.62%] [G loss: 0.195846]\n",
      "2158 [D loss: 0.613154, op_acc: 54.69%] [G loss: 0.822986]\n",
      "2159 [D loss: 0.358498, op_acc: 96.88%] [G loss: 0.497311]\n",
      "2160 [D loss: 0.296344, op_acc: 90.62%] [G loss: 0.371516]\n",
      "2161 [D loss: 0.302060, op_acc: 82.81%] [G loss: 0.461857]\n",
      "2162 [D loss: 0.212205, op_acc: 95.31%] [G loss: 0.476473]\n",
      "2163 [D loss: 0.271571, op_acc: 92.19%] [G loss: 0.405365]\n",
      "2164 [D loss: 0.229895, op_acc: 93.75%] [G loss: 0.417905]\n",
      "2165 [D loss: 0.236194, op_acc: 92.19%] [G loss: 0.364147]\n",
      "2166 [D loss: 0.220899, op_acc: 93.75%] [G loss: 0.405625]\n",
      "2167 [D loss: 0.238617, op_acc: 89.06%] [G loss: 0.449826]\n",
      "2168 [D loss: 0.258136, op_acc: 93.75%] [G loss: 0.397017]\n",
      "2169 [D loss: 0.235306, op_acc: 93.75%] [G loss: 0.410524]\n",
      "2170 [D loss: 0.266256, op_acc: 89.06%] [G loss: 0.462935]\n",
      "2171 [D loss: 0.271428, op_acc: 87.50%] [G loss: 0.480674]\n",
      "2172 [D loss: 0.193688, op_acc: 96.88%] [G loss: 0.455056]\n",
      "2173 [D loss: 0.269613, op_acc: 92.19%] [G loss: 0.464991]\n",
      "2174 [D loss: 0.269826, op_acc: 87.50%] [G loss: 0.467858]\n",
      "2175 [D loss: 0.275959, op_acc: 87.50%] [G loss: 0.484107]\n",
      "2176 [D loss: 0.237710, op_acc: 89.06%] [G loss: 0.473288]\n",
      "2177 [D loss: 0.303385, op_acc: 85.94%] [G loss: 0.450044]\n",
      "2178 [D loss: 0.204323, op_acc: 93.75%] [G loss: 0.470572]\n",
      "2179 [D loss: 0.247637, op_acc: 89.06%] [G loss: 0.486156]\n",
      "2180 [D loss: 0.225577, op_acc: 93.75%] [G loss: 0.498582]\n",
      "2181 [D loss: 0.178798, op_acc: 95.31%] [G loss: 0.503703]\n",
      "2182 [D loss: 0.197921, op_acc: 93.75%] [G loss: 0.490586]\n",
      "2183 [D loss: 0.327132, op_acc: 76.56%] [G loss: 0.502957]\n",
      "2184 [D loss: 0.221028, op_acc: 92.19%] [G loss: 0.446562]\n",
      "2185 [D loss: 0.206497, op_acc: 92.19%] [G loss: 0.472174]\n",
      "2186 [D loss: 0.226574, op_acc: 90.62%] [G loss: 0.478188]\n",
      "2187 [D loss: 0.179399, op_acc: 98.44%] [G loss: 0.511954]\n",
      "2188 [D loss: 0.256539, op_acc: 92.19%] [G loss: 0.513987]\n",
      "2189 [D loss: 0.148845, op_acc: 95.31%] [G loss: 0.576279]\n",
      "2190 [D loss: 0.215650, op_acc: 92.19%] [G loss: 0.557778]\n",
      "2191 [D loss: 0.168388, op_acc: 93.75%] [G loss: 0.578016]\n",
      "2192 [D loss: 0.197387, op_acc: 92.19%] [G loss: 0.523155]\n",
      "2193 [D loss: 0.171785, op_acc: 96.88%] [G loss: 0.534727]\n",
      "2194 [D loss: 0.145521, op_acc: 96.88%] [G loss: 0.570952]\n",
      "2195 [D loss: 0.250827, op_acc: 85.94%] [G loss: 0.593856]\n",
      "2196 [D loss: 0.177360, op_acc: 93.75%] [G loss: 0.585680]\n",
      "2197 [D loss: 0.182998, op_acc: 92.19%] [G loss: 0.563398]\n",
      "2198 [D loss: 0.203326, op_acc: 90.62%] [G loss: 0.683004]\n",
      "2199 [D loss: 0.189088, op_acc: 93.75%] [G loss: 0.587148]\n",
      "2200 [D loss: 0.165710, op_acc: 95.31%] [G loss: 0.587007]\n",
      "2201 [D loss: 0.180103, op_acc: 89.06%] [G loss: 0.564693]\n",
      "2202 [D loss: 0.202300, op_acc: 92.19%] [G loss: 0.627626]\n",
      "2203 [D loss: 0.216596, op_acc: 89.06%] [G loss: 0.617232]\n",
      "2204 [D loss: 0.250306, op_acc: 87.50%] [G loss: 0.633057]\n",
      "2205 [D loss: 0.397360, op_acc: 84.38%] [G loss: 0.532409]\n",
      "2206 [D loss: 0.162140, op_acc: 92.19%] [G loss: 0.675774]\n",
      "2207 [D loss: 0.220061, op_acc: 89.06%] [G loss: 0.654281]\n",
      "2208 [D loss: 0.268043, op_acc: 89.06%] [G loss: 0.606361]\n",
      "2209 [D loss: 0.255015, op_acc: 85.94%] [G loss: 0.731843]\n",
      "2210 [D loss: 0.155797, op_acc: 90.62%] [G loss: 0.685263]\n",
      "2211 [D loss: 0.271186, op_acc: 85.94%] [G loss: 0.636617]\n",
      "2212 [D loss: 0.145414, op_acc: 96.88%] [G loss: 0.637568]\n",
      "2213 [D loss: 0.204340, op_acc: 89.06%] [G loss: 0.731264]\n",
      "2214 [D loss: 0.204698, op_acc: 90.62%] [G loss: 0.707580]\n",
      "2215 [D loss: 0.198855, op_acc: 92.19%] [G loss: 0.608156]\n",
      "2216 [D loss: 0.200614, op_acc: 89.06%] [G loss: 0.798862]\n",
      "2217 [D loss: 0.241425, op_acc: 85.94%] [G loss: 0.656285]\n",
      "2218 [D loss: 0.275286, op_acc: 87.50%] [G loss: 0.676289]\n",
      "2219 [D loss: 0.249287, op_acc: 84.38%] [G loss: 0.667320]\n",
      "2220 [D loss: 0.298716, op_acc: 93.75%] [G loss: 0.767293]\n",
      "2221 [D loss: 0.161082, op_acc: 95.31%] [G loss: 0.710582]\n",
      "2222 [D loss: 0.155490, op_acc: 90.62%] [G loss: 0.734356]\n",
      "2223 [D loss: 0.145379, op_acc: 95.31%] [G loss: 0.764366]\n",
      "2224 [D loss: 0.194237, op_acc: 92.19%] [G loss: 0.672385]\n",
      "2225 [D loss: 0.192397, op_acc: 95.31%] [G loss: 0.653729]\n",
      "2226 [D loss: 0.231835, op_acc: 90.62%] [G loss: 0.683702]\n",
      "2227 [D loss: 0.242952, op_acc: 85.94%] [G loss: 0.736647]\n",
      "2228 [D loss: 0.148218, op_acc: 96.88%] [G loss: 0.668121]\n",
      "2229 [D loss: 0.181779, op_acc: 92.19%] [G loss: 0.770910]\n",
      "2230 [D loss: 0.109561, op_acc: 96.88%] [G loss: 0.822758]\n",
      "2231 [D loss: 0.203579, op_acc: 93.75%] [G loss: 0.673188]\n",
      "2232 [D loss: 0.215311, op_acc: 90.62%] [G loss: 0.819157]\n",
      "2233 [D loss: 0.277290, op_acc: 89.06%] [G loss: 0.717158]\n",
      "2234 [D loss: 0.304009, op_acc: 85.94%] [G loss: 0.759607]\n",
      "2235 [D loss: 0.250456, op_acc: 85.94%] [G loss: 0.814160]\n",
      "2236 [D loss: 0.141728, op_acc: 93.75%] [G loss: 0.766801]\n",
      "2237 [D loss: 0.245632, op_acc: 85.94%] [G loss: 0.737831]\n",
      "2238 [D loss: 0.184400, op_acc: 92.19%] [G loss: 0.775652]\n",
      "2239 [D loss: 0.239757, op_acc: 84.38%] [G loss: 0.859510]\n",
      "2240 [D loss: 0.305524, op_acc: 85.94%] [G loss: 0.684797]\n",
      "2241 [D loss: 0.246836, op_acc: 89.06%] [G loss: 0.718270]\n",
      "2242 [D loss: 0.199372, op_acc: 92.19%] [G loss: 0.737230]\n",
      "2243 [D loss: 0.184907, op_acc: 89.06%] [G loss: 0.838254]\n",
      "2244 [D loss: 0.169972, op_acc: 93.75%] [G loss: 0.805799]\n",
      "2245 [D loss: 0.173223, op_acc: 95.31%] [G loss: 0.773728]\n",
      "2246 [D loss: 0.297015, op_acc: 85.94%] [G loss: 0.686759]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2247 [D loss: 0.203635, op_acc: 89.06%] [G loss: 0.777457]\n",
      "2248 [D loss: 0.244538, op_acc: 92.19%] [G loss: 0.707810]\n",
      "2249 [D loss: 0.154700, op_acc: 95.31%] [G loss: 0.846555]\n",
      "2250 [D loss: 0.208392, op_acc: 90.62%] [G loss: 0.776986]\n",
      "2251 [D loss: 0.137806, op_acc: 93.75%] [G loss: 0.823601]\n",
      "2252 [D loss: 0.175724, op_acc: 93.75%] [G loss: 0.833999]\n",
      "2253 [D loss: 0.155753, op_acc: 93.75%] [G loss: 0.815535]\n",
      "2254 [D loss: 0.181194, op_acc: 92.19%] [G loss: 0.795403]\n",
      "2255 [D loss: 0.088679, op_acc: 100.00%] [G loss: 0.816043]\n",
      "2256 [D loss: 0.149386, op_acc: 93.75%] [G loss: 0.857788]\n",
      "2257 [D loss: 0.210938, op_acc: 87.50%] [G loss: 0.839593]\n",
      "2258 [D loss: 0.264013, op_acc: 84.38%] [G loss: 0.861076]\n",
      "2259 [D loss: 0.207790, op_acc: 90.62%] [G loss: 0.841506]\n",
      "2260 [D loss: 0.262404, op_acc: 84.38%] [G loss: 0.818478]\n",
      "2261 [D loss: 0.224160, op_acc: 90.62%] [G loss: 0.849885]\n",
      "2262 [D loss: 0.206437, op_acc: 90.62%] [G loss: 0.780640]\n",
      "2263 [D loss: 0.127599, op_acc: 98.44%] [G loss: 0.885504]\n",
      "2264 [D loss: 0.238038, op_acc: 89.06%] [G loss: 0.780773]\n",
      "2265 [D loss: 0.160986, op_acc: 92.19%] [G loss: 0.750350]\n",
      "2266 [D loss: 0.123190, op_acc: 98.44%] [G loss: 0.810222]\n",
      "2267 [D loss: 0.186728, op_acc: 90.62%] [G loss: 0.794503]\n",
      "2268 [D loss: 0.094367, op_acc: 98.44%] [G loss: 0.761434]\n",
      "2269 [D loss: 0.105481, op_acc: 98.44%] [G loss: 0.780779]\n",
      "2270 [D loss: 0.138869, op_acc: 98.44%] [G loss: 0.880207]\n",
      "2271 [D loss: 0.170363, op_acc: 92.19%] [G loss: 0.908736]\n",
      "2272 [D loss: 0.199715, op_acc: 90.62%] [G loss: 0.808385]\n",
      "2273 [D loss: 0.227470, op_acc: 90.62%] [G loss: 0.781033]\n",
      "2274 [D loss: 0.156772, op_acc: 98.44%] [G loss: 0.824567]\n",
      "2275 [D loss: 0.267260, op_acc: 89.06%] [G loss: 0.846240]\n",
      "2276 [D loss: 0.125765, op_acc: 93.75%] [G loss: 1.041615]\n",
      "2277 [D loss: 0.205031, op_acc: 93.75%] [G loss: 0.713776]\n",
      "2278 [D loss: 0.233537, op_acc: 87.50%] [G loss: 0.736059]\n",
      "2279 [D loss: 0.192739, op_acc: 87.50%] [G loss: 1.122344]\n",
      "2280 [D loss: 0.109877, op_acc: 100.00%] [G loss: 0.840296]\n",
      "2281 [D loss: 0.243833, op_acc: 85.94%] [G loss: 0.650359]\n",
      "2282 [D loss: 0.144398, op_acc: 92.19%] [G loss: 0.951049]\n",
      "2283 [D loss: 0.168384, op_acc: 93.75%] [G loss: 0.877868]\n",
      "2284 [D loss: 0.142086, op_acc: 95.31%] [G loss: 0.796880]\n",
      "2285 [D loss: 0.154553, op_acc: 92.19%] [G loss: 0.965536]\n",
      "2286 [D loss: 0.162740, op_acc: 93.75%] [G loss: 0.829091]\n",
      "2287 [D loss: 0.171560, op_acc: 92.19%] [G loss: 0.925099]\n",
      "2288 [D loss: 0.152255, op_acc: 95.31%] [G loss: 0.740648]\n",
      "2289 [D loss: 0.117801, op_acc: 95.31%] [G loss: 0.820124]\n",
      "2290 [D loss: 0.201128, op_acc: 89.06%] [G loss: 0.867883]\n",
      "2291 [D loss: 0.195275, op_acc: 95.31%] [G loss: 1.022847]\n",
      "2292 [D loss: 0.175735, op_acc: 93.75%] [G loss: 0.875810]\n",
      "2293 [D loss: 0.157414, op_acc: 95.31%] [G loss: 0.861928]\n",
      "2294 [D loss: 0.149394, op_acc: 90.62%] [G loss: 0.838943]\n",
      "2295 [D loss: 0.234198, op_acc: 87.50%] [G loss: 0.917216]\n",
      "2296 [D loss: 0.155503, op_acc: 95.31%] [G loss: 0.929740]\n",
      "2297 [D loss: 0.218402, op_acc: 85.94%] [G loss: 0.852758]\n",
      "2298 [D loss: 0.188530, op_acc: 90.62%] [G loss: 0.956896]\n",
      "2299 [D loss: 0.206894, op_acc: 92.19%] [G loss: 0.806340]\n",
      "2300 [D loss: 0.161674, op_acc: 92.19%] [G loss: 0.981802]\n",
      "2301 [D loss: 0.159441, op_acc: 92.19%] [G loss: 0.789588]\n",
      "2302 [D loss: 0.171791, op_acc: 93.75%] [G loss: 1.031918]\n",
      "2303 [D loss: 0.101536, op_acc: 96.88%] [G loss: 0.987335]\n",
      "2304 [D loss: 0.325621, op_acc: 79.69%] [G loss: 0.776449]\n",
      "2305 [D loss: 0.169980, op_acc: 92.19%] [G loss: 1.010848]\n",
      "2306 [D loss: 0.142185, op_acc: 93.75%] [G loss: 0.780760]\n",
      "2307 [D loss: 0.147316, op_acc: 93.75%] [G loss: 1.039156]\n",
      "2308 [D loss: 0.144698, op_acc: 92.19%] [G loss: 1.123104]\n",
      "2309 [D loss: 0.149454, op_acc: 93.75%] [G loss: 0.910158]\n",
      "2310 [D loss: 0.139271, op_acc: 95.31%] [G loss: 0.846364]\n",
      "2311 [D loss: 0.126776, op_acc: 95.31%] [G loss: 0.931143]\n",
      "2312 [D loss: 0.175178, op_acc: 93.75%] [G loss: 1.077362]\n",
      "2313 [D loss: 0.269802, op_acc: 85.94%] [G loss: 0.845372]\n",
      "2314 [D loss: 0.186584, op_acc: 90.62%] [G loss: 0.823558]\n",
      "2315 [D loss: 0.164489, op_acc: 95.31%] [G loss: 0.876944]\n",
      "2316 [D loss: 0.123168, op_acc: 95.31%] [G loss: 0.870520]\n",
      "2317 [D loss: 0.103508, op_acc: 93.75%] [G loss: 0.891988]\n",
      "2318 [D loss: 0.167792, op_acc: 93.75%] [G loss: 0.831264]\n",
      "2319 [D loss: 0.161647, op_acc: 95.31%] [G loss: 0.977979]\n",
      "2320 [D loss: 0.184444, op_acc: 89.06%] [G loss: 0.817486]\n",
      "2321 [D loss: 0.128220, op_acc: 95.31%] [G loss: 1.365250]\n",
      "2322 [D loss: 0.287948, op_acc: 84.38%] [G loss: 0.896033]\n",
      "2323 [D loss: 0.196101, op_acc: 95.31%] [G loss: 1.167125]\n",
      "2324 [D loss: 0.239841, op_acc: 92.19%] [G loss: 0.847465]\n",
      "2325 [D loss: 0.136212, op_acc: 95.31%] [G loss: 1.044973]\n",
      "2326 [D loss: 0.251616, op_acc: 90.62%] [G loss: 1.247562]\n",
      "2327 [D loss: 0.191409, op_acc: 93.75%] [G loss: 0.730834]\n",
      "2328 [D loss: 0.107501, op_acc: 100.00%] [G loss: 0.849998]\n",
      "2329 [D loss: 0.183702, op_acc: 90.62%] [G loss: 0.881371]\n",
      "2330 [D loss: 0.129662, op_acc: 95.31%] [G loss: 0.889373]\n",
      "2331 [D loss: 0.126579, op_acc: 96.88%] [G loss: 0.856205]\n",
      "2332 [D loss: 0.121506, op_acc: 96.88%] [G loss: 0.863747]\n",
      "2333 [D loss: 0.137176, op_acc: 96.88%] [G loss: 0.797878]\n",
      "2334 [D loss: 0.122351, op_acc: 93.75%] [G loss: 1.090132]\n",
      "2335 [D loss: 0.143434, op_acc: 93.75%] [G loss: 0.896072]\n",
      "2336 [D loss: 0.121497, op_acc: 93.75%] [G loss: 0.847234]\n",
      "2337 [D loss: 0.139839, op_acc: 95.31%] [G loss: 0.850028]\n",
      "2338 [D loss: 0.136763, op_acc: 95.31%] [G loss: 1.011927]\n",
      "2339 [D loss: 0.119297, op_acc: 95.31%] [G loss: 0.894726]\n",
      "2340 [D loss: 0.146035, op_acc: 93.75%] [G loss: 0.799470]\n",
      "2341 [D loss: 0.163218, op_acc: 93.75%] [G loss: 0.923381]\n",
      "2342 [D loss: 0.157312, op_acc: 92.19%] [G loss: 1.082581]\n",
      "2343 [D loss: 0.195776, op_acc: 89.06%] [G loss: 0.869741]\n",
      "2344 [D loss: 0.146318, op_acc: 90.62%] [G loss: 0.927132]\n",
      "2345 [D loss: 0.123695, op_acc: 96.88%] [G loss: 1.052937]\n",
      "2346 [D loss: 0.144407, op_acc: 95.31%] [G loss: 0.913974]\n",
      "2347 [D loss: 0.119523, op_acc: 98.44%] [G loss: 0.934251]\n",
      "2348 [D loss: 0.129101, op_acc: 96.88%] [G loss: 0.798037]\n",
      "2349 [D loss: 0.125387, op_acc: 95.31%] [G loss: 0.871919]\n",
      "2350 [D loss: 0.122205, op_acc: 95.31%] [G loss: 0.944393]\n",
      "2351 [D loss: 0.135789, op_acc: 95.31%] [G loss: 0.846477]\n",
      "2352 [D loss: 0.235162, op_acc: 93.75%] [G loss: 1.012093]\n",
      "2353 [D loss: 0.101985, op_acc: 98.44%] [G loss: 0.903450]\n",
      "2354 [D loss: 0.161093, op_acc: 93.75%] [G loss: 0.927507]\n",
      "2355 [D loss: 0.266255, op_acc: 85.94%] [G loss: 0.865877]\n",
      "2356 [D loss: 0.184145, op_acc: 92.19%] [G loss: 1.129092]\n",
      "2357 [D loss: 0.225678, op_acc: 90.62%] [G loss: 1.007516]\n",
      "2358 [D loss: 0.279165, op_acc: 84.38%] [G loss: 1.054621]\n",
      "2359 [D loss: 0.292023, op_acc: 87.50%] [G loss: 1.017344]\n",
      "2360 [D loss: 0.202789, op_acc: 90.62%] [G loss: 1.093837]\n",
      "2361 [D loss: 0.122393, op_acc: 98.44%] [G loss: 0.961421]\n",
      "2362 [D loss: 0.156556, op_acc: 93.75%] [G loss: 0.932393]\n",
      "2363 [D loss: 0.227222, op_acc: 90.62%] [G loss: 0.876622]\n",
      "2364 [D loss: 0.164755, op_acc: 92.19%] [G loss: 1.067329]\n",
      "2365 [D loss: 0.191758, op_acc: 95.31%] [G loss: 0.817224]\n",
      "2366 [D loss: 0.094966, op_acc: 98.44%] [G loss: 0.958332]\n",
      "2367 [D loss: 0.103423, op_acc: 100.00%] [G loss: 0.982347]\n",
      "2368 [D loss: 0.109295, op_acc: 95.31%] [G loss: 0.964564]\n",
      "2369 [D loss: 0.114444, op_acc: 96.88%] [G loss: 0.863533]\n",
      "2370 [D loss: 0.301559, op_acc: 85.94%] [G loss: 0.885877]\n",
      "2371 [D loss: 0.152025, op_acc: 95.31%] [G loss: 0.984576]\n",
      "2372 [D loss: 0.147266, op_acc: 90.62%] [G loss: 1.070187]\n",
      "2373 [D loss: 0.191051, op_acc: 89.06%] [G loss: 1.054431]\n",
      "2374 [D loss: 0.210890, op_acc: 87.50%] [G loss: 0.813662]\n",
      "2375 [D loss: 0.175690, op_acc: 95.31%] [G loss: 0.780315]\n",
      "2376 [D loss: 0.092419, op_acc: 95.31%] [G loss: 1.047205]\n",
      "2377 [D loss: 0.206033, op_acc: 90.62%] [G loss: 0.871166]\n",
      "2378 [D loss: 0.208121, op_acc: 90.62%] [G loss: 0.835441]\n",
      "2379 [D loss: 0.116069, op_acc: 95.31%] [G loss: 1.019252]\n",
      "2380 [D loss: 0.179826, op_acc: 92.19%] [G loss: 0.810566]\n",
      "2381 [D loss: 0.189737, op_acc: 90.62%] [G loss: 1.147033]\n",
      "2382 [D loss: 0.182473, op_acc: 93.75%] [G loss: 0.976824]\n",
      "2383 [D loss: 0.232829, op_acc: 87.50%] [G loss: 0.897566]\n",
      "2384 [D loss: 0.176970, op_acc: 93.75%] [G loss: 0.906855]\n",
      "2385 [D loss: 0.140163, op_acc: 90.62%] [G loss: 1.134343]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2386 [D loss: 0.149277, op_acc: 95.31%] [G loss: 0.859628]\n",
      "2387 [D loss: 0.162246, op_acc: 96.88%] [G loss: 0.987689]\n",
      "2388 [D loss: 0.105576, op_acc: 96.88%] [G loss: 0.958728]\n",
      "2389 [D loss: 0.141283, op_acc: 96.88%] [G loss: 0.971078]\n",
      "2390 [D loss: 0.093591, op_acc: 96.88%] [G loss: 0.911812]\n",
      "2391 [D loss: 0.086870, op_acc: 98.44%] [G loss: 0.920205]\n",
      "2392 [D loss: 0.115077, op_acc: 93.75%] [G loss: 0.936309]\n",
      "2393 [D loss: 0.098988, op_acc: 98.44%] [G loss: 1.072043]\n",
      "2394 [D loss: 0.113520, op_acc: 98.44%] [G loss: 1.061578]\n",
      "2395 [D loss: 0.173074, op_acc: 92.19%] [G loss: 1.155962]\n",
      "2396 [D loss: 0.142325, op_acc: 96.88%] [G loss: 0.927493]\n",
      "2397 [D loss: 0.134000, op_acc: 95.31%] [G loss: 0.956870]\n",
      "2398 [D loss: 0.100784, op_acc: 98.44%] [G loss: 0.868582]\n",
      "2399 [D loss: 0.091407, op_acc: 98.44%] [G loss: 0.996746]\n",
      "2400 [D loss: 0.135056, op_acc: 95.31%] [G loss: 0.891559]\n",
      "2401 [D loss: 0.122325, op_acc: 98.44%] [G loss: 1.019544]\n",
      "2402 [D loss: 0.139568, op_acc: 93.75%] [G loss: 1.129928]\n",
      "2403 [D loss: 0.115333, op_acc: 95.31%] [G loss: 0.959042]\n",
      "2404 [D loss: 0.226497, op_acc: 93.75%] [G loss: 0.864161]\n",
      "2405 [D loss: 0.147477, op_acc: 93.75%] [G loss: 1.104182]\n",
      "2406 [D loss: 0.143765, op_acc: 95.31%] [G loss: 1.031103]\n",
      "2407 [D loss: 0.121123, op_acc: 96.88%] [G loss: 0.934896]\n",
      "2408 [D loss: 0.153758, op_acc: 93.75%] [G loss: 1.030405]\n",
      "2409 [D loss: 0.139471, op_acc: 95.31%] [G loss: 1.090251]\n",
      "2410 [D loss: 0.190209, op_acc: 89.06%] [G loss: 0.851394]\n",
      "2411 [D loss: 0.184907, op_acc: 90.62%] [G loss: 0.998244]\n",
      "2412 [D loss: 0.126864, op_acc: 93.75%] [G loss: 0.964121]\n",
      "2413 [D loss: 0.123562, op_acc: 95.31%] [G loss: 0.948310]\n",
      "2414 [D loss: 0.124188, op_acc: 93.75%] [G loss: 1.009241]\n",
      "2415 [D loss: 0.095915, op_acc: 96.88%] [G loss: 1.025968]\n",
      "2416 [D loss: 0.100247, op_acc: 100.00%] [G loss: 0.994240]\n",
      "2417 [D loss: 0.192422, op_acc: 90.62%] [G loss: 0.927206]\n",
      "2418 [D loss: 0.093981, op_acc: 96.88%] [G loss: 1.015056]\n",
      "2419 [D loss: 0.090018, op_acc: 96.88%] [G loss: 1.093002]\n",
      "2420 [D loss: 0.205920, op_acc: 87.50%] [G loss: 0.803986]\n",
      "2421 [D loss: 0.105958, op_acc: 100.00%] [G loss: 0.946125]\n",
      "2422 [D loss: 0.249948, op_acc: 84.38%] [G loss: 1.065580]\n",
      "2423 [D loss: 0.149374, op_acc: 90.62%] [G loss: 0.881040]\n",
      "2424 [D loss: 0.125098, op_acc: 96.88%] [G loss: 0.991898]\n",
      "2425 [D loss: 0.128879, op_acc: 95.31%] [G loss: 0.912493]\n",
      "2426 [D loss: 0.097233, op_acc: 96.88%] [G loss: 1.034176]\n",
      "2427 [D loss: 0.097705, op_acc: 98.44%] [G loss: 0.973589]\n",
      "2428 [D loss: 0.192715, op_acc: 87.50%] [G loss: 1.006565]\n",
      "2429 [D loss: 0.154105, op_acc: 95.31%] [G loss: 1.092060]\n",
      "2430 [D loss: 0.095318, op_acc: 96.88%] [G loss: 0.960402]\n",
      "2431 [D loss: 0.154665, op_acc: 95.31%] [G loss: 1.075397]\n",
      "2432 [D loss: 0.101568, op_acc: 96.88%] [G loss: 0.948589]\n",
      "2433 [D loss: 0.101680, op_acc: 95.31%] [G loss: 0.957702]\n",
      "2434 [D loss: 0.117928, op_acc: 95.31%] [G loss: 0.984596]\n",
      "2435 [D loss: 0.134925, op_acc: 98.44%] [G loss: 0.839048]\n",
      "2436 [D loss: 0.090831, op_acc: 96.88%] [G loss: 1.108590]\n",
      "2437 [D loss: 0.149389, op_acc: 95.31%] [G loss: 0.989264]\n",
      "2438 [D loss: 0.080888, op_acc: 98.44%] [G loss: 0.967333]\n",
      "2439 [D loss: 0.181822, op_acc: 93.75%] [G loss: 1.000654]\n",
      "2440 [D loss: 0.080042, op_acc: 100.00%] [G loss: 0.965652]\n",
      "2441 [D loss: 0.127169, op_acc: 93.75%] [G loss: 0.968426]\n",
      "2442 [D loss: 0.126351, op_acc: 95.31%] [G loss: 0.897756]\n",
      "2443 [D loss: 0.085182, op_acc: 100.00%] [G loss: 1.046227]\n",
      "2444 [D loss: 0.205529, op_acc: 87.50%] [G loss: 0.922019]\n",
      "2445 [D loss: 0.121375, op_acc: 96.88%] [G loss: 0.964285]\n",
      "2446 [D loss: 0.127921, op_acc: 96.88%] [G loss: 0.929349]\n",
      "2447 [D loss: 0.075609, op_acc: 100.00%] [G loss: 1.030090]\n",
      "2448 [D loss: 0.150033, op_acc: 93.75%] [G loss: 0.832546]\n",
      "2449 [D loss: 0.128367, op_acc: 96.88%] [G loss: 1.260692]\n",
      "2450 [D loss: 0.235559, op_acc: 89.06%] [G loss: 1.204023]\n",
      "2451 [D loss: 0.235744, op_acc: 89.06%] [G loss: 1.034145]\n",
      "2452 [D loss: 0.198506, op_acc: 92.19%] [G loss: 0.950489]\n",
      "2453 [D loss: 0.153558, op_acc: 92.19%] [G loss: 1.050225]\n",
      "2454 [D loss: 0.121886, op_acc: 96.88%] [G loss: 1.006686]\n",
      "2455 [D loss: 0.130279, op_acc: 96.88%] [G loss: 0.871062]\n",
      "2456 [D loss: 0.095021, op_acc: 96.88%] [G loss: 0.948731]\n",
      "2457 [D loss: 0.167891, op_acc: 89.06%] [G loss: 1.009477]\n",
      "2458 [D loss: 0.091369, op_acc: 98.44%] [G loss: 1.003352]\n",
      "2459 [D loss: 0.079251, op_acc: 98.44%] [G loss: 0.931390]\n",
      "2460 [D loss: 0.186529, op_acc: 93.75%] [G loss: 0.890059]\n",
      "2461 [D loss: 0.196341, op_acc: 89.06%] [G loss: 0.948828]\n",
      "2462 [D loss: 0.096052, op_acc: 98.44%] [G loss: 0.919717]\n",
      "2463 [D loss: 0.111569, op_acc: 95.31%] [G loss: 1.037252]\n",
      "2464 [D loss: 0.110720, op_acc: 93.75%] [G loss: 0.977062]\n",
      "2465 [D loss: 0.188850, op_acc: 96.88%] [G loss: 0.880705]\n",
      "2466 [D loss: 0.141751, op_acc: 95.31%] [G loss: 0.973538]\n",
      "2467 [D loss: 0.174310, op_acc: 90.62%] [G loss: 1.150331]\n",
      "2468 [D loss: 0.249087, op_acc: 90.62%] [G loss: 1.117600]\n",
      "2469 [D loss: 0.139388, op_acc: 95.31%] [G loss: 0.825060]\n",
      "2470 [D loss: 0.098082, op_acc: 98.44%] [G loss: 1.016457]\n",
      "2471 [D loss: 0.226061, op_acc: 87.50%] [G loss: 0.994241]\n",
      "2472 [D loss: 0.177982, op_acc: 89.06%] [G loss: 1.370897]\n",
      "2473 [D loss: 0.188751, op_acc: 93.75%] [G loss: 0.914872]\n",
      "2474 [D loss: 0.118250, op_acc: 96.88%] [G loss: 1.036797]\n",
      "2475 [D loss: 0.209526, op_acc: 92.19%] [G loss: 1.010044]\n",
      "2476 [D loss: 0.146679, op_acc: 95.31%] [G loss: 0.925690]\n",
      "2477 [D loss: 0.060806, op_acc: 98.44%] [G loss: 1.015928]\n",
      "2478 [D loss: 0.136228, op_acc: 95.31%] [G loss: 0.883172]\n",
      "2479 [D loss: 0.129374, op_acc: 93.75%] [G loss: 0.977084]\n",
      "2480 [D loss: 0.105298, op_acc: 96.88%] [G loss: 0.907651]\n",
      "2481 [D loss: 0.149516, op_acc: 92.19%] [G loss: 0.887457]\n",
      "2482 [D loss: 0.088839, op_acc: 98.44%] [G loss: 1.003302]\n",
      "2483 [D loss: 0.111761, op_acc: 98.44%] [G loss: 0.969867]\n",
      "2484 [D loss: 0.117149, op_acc: 95.31%] [G loss: 1.078676]\n",
      "2485 [D loss: 0.103628, op_acc: 96.88%] [G loss: 0.853368]\n",
      "2486 [D loss: 0.182164, op_acc: 92.19%] [G loss: 0.996404]\n",
      "2487 [D loss: 0.194632, op_acc: 87.50%] [G loss: 0.901545]\n",
      "2488 [D loss: 0.166647, op_acc: 93.75%] [G loss: 0.917535]\n",
      "2489 [D loss: 0.146757, op_acc: 93.75%] [G loss: 1.061515]\n",
      "2490 [D loss: 0.165014, op_acc: 93.75%] [G loss: 1.031883]\n",
      "2491 [D loss: 0.128058, op_acc: 93.75%] [G loss: 1.018460]\n",
      "2492 [D loss: 0.125299, op_acc: 96.88%] [G loss: 0.916880]\n",
      "2493 [D loss: 0.116089, op_acc: 96.88%] [G loss: 0.889994]\n",
      "2494 [D loss: 0.256796, op_acc: 90.62%] [G loss: 0.999736]\n",
      "2495 [D loss: 0.091583, op_acc: 96.88%] [G loss: 1.003954]\n",
      "2496 [D loss: 0.284328, op_acc: 82.81%] [G loss: 1.063775]\n",
      "2497 [D loss: 0.101661, op_acc: 96.88%] [G loss: 1.084801]\n",
      "2498 [D loss: 0.171270, op_acc: 93.75%] [G loss: 0.976552]\n",
      "2499 [D loss: 0.237058, op_acc: 85.94%] [G loss: 1.076312]\n",
      "2500 [D loss: 0.161687, op_acc: 95.31%] [G loss: 0.968125]\n",
      "2501 [D loss: 0.163013, op_acc: 95.31%] [G loss: 0.859660]\n",
      "2502 [D loss: 0.156785, op_acc: 93.75%] [G loss: 1.018491]\n",
      "2503 [D loss: 0.191263, op_acc: 87.50%] [G loss: 0.816163]\n",
      "2504 [D loss: 0.192081, op_acc: 89.06%] [G loss: 1.364809]\n",
      "2505 [D loss: 0.180406, op_acc: 93.75%] [G loss: 0.872667]\n",
      "2506 [D loss: 0.249681, op_acc: 87.50%] [G loss: 0.947766]\n",
      "2507 [D loss: 0.065274, op_acc: 100.00%] [G loss: 0.958628]\n",
      "2508 [D loss: 0.152187, op_acc: 96.88%] [G loss: 0.989092]\n",
      "2509 [D loss: 0.140616, op_acc: 93.75%] [G loss: 1.133696]\n",
      "2510 [D loss: 0.103337, op_acc: 98.44%] [G loss: 0.910475]\n",
      "2511 [D loss: 0.058932, op_acc: 100.00%] [G loss: 1.038323]\n",
      "2512 [D loss: 0.139623, op_acc: 92.19%] [G loss: 1.131725]\n",
      "2513 [D loss: 0.163231, op_acc: 92.19%] [G loss: 0.847211]\n",
      "2514 [D loss: 0.134553, op_acc: 93.75%] [G loss: 0.994856]\n",
      "2515 [D loss: 0.100272, op_acc: 96.88%] [G loss: 0.963287]\n",
      "2516 [D loss: 0.075830, op_acc: 98.44%] [G loss: 0.913924]\n",
      "2517 [D loss: 0.153565, op_acc: 95.31%] [G loss: 1.148675]\n",
      "2518 [D loss: 0.088132, op_acc: 98.44%] [G loss: 0.933852]\n",
      "2519 [D loss: 0.147830, op_acc: 92.19%] [G loss: 0.862969]\n",
      "2520 [D loss: 0.121152, op_acc: 95.31%] [G loss: 0.936166]\n",
      "2521 [D loss: 0.096285, op_acc: 96.88%] [G loss: 0.966742]\n",
      "2522 [D loss: 0.162837, op_acc: 90.62%] [G loss: 0.918068]\n",
      "2523 [D loss: 0.119999, op_acc: 96.88%] [G loss: 0.987058]\n",
      "2524 [D loss: 0.129933, op_acc: 96.88%] [G loss: 0.994717]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2525 [D loss: 0.156157, op_acc: 90.62%] [G loss: 0.901143]\n",
      "2526 [D loss: 0.090913, op_acc: 95.31%] [G loss: 1.038191]\n",
      "2527 [D loss: 0.108776, op_acc: 95.31%] [G loss: 0.908628]\n",
      "2528 [D loss: 0.134864, op_acc: 95.31%] [G loss: 0.956519]\n",
      "2529 [D loss: 0.086740, op_acc: 95.31%] [G loss: 1.232923]\n",
      "2530 [D loss: 0.149573, op_acc: 92.19%] [G loss: 0.919661]\n",
      "2531 [D loss: 0.109899, op_acc: 95.31%] [G loss: 1.009123]\n",
      "2532 [D loss: 0.116864, op_acc: 95.31%] [G loss: 0.991922]\n",
      "2533 [D loss: 0.117634, op_acc: 96.88%] [G loss: 0.956795]\n",
      "2534 [D loss: 0.099083, op_acc: 96.88%] [G loss: 1.004516]\n",
      "2535 [D loss: 0.113199, op_acc: 96.88%] [G loss: 1.087182]\n",
      "2536 [D loss: 0.178496, op_acc: 89.06%] [G loss: 1.109569]\n",
      "2537 [D loss: 0.091898, op_acc: 100.00%] [G loss: 0.865681]\n",
      "2538 [D loss: 0.147731, op_acc: 92.19%] [G loss: 0.981030]\n",
      "2539 [D loss: 0.140611, op_acc: 96.88%] [G loss: 1.051774]\n",
      "2540 [D loss: 0.251395, op_acc: 89.06%] [G loss: 1.205632]\n",
      "2541 [D loss: 0.189624, op_acc: 92.19%] [G loss: 1.027920]\n",
      "2542 [D loss: 0.102233, op_acc: 98.44%] [G loss: 1.143408]\n",
      "2543 [D loss: 0.273072, op_acc: 87.50%] [G loss: 1.016384]\n",
      "2544 [D loss: 0.091954, op_acc: 96.88%] [G loss: 1.024055]\n",
      "2545 [D loss: 0.189451, op_acc: 89.06%] [G loss: 0.998372]\n",
      "2546 [D loss: 0.168112, op_acc: 93.75%] [G loss: 0.910941]\n",
      "2547 [D loss: 0.113178, op_acc: 92.19%] [G loss: 1.040072]\n",
      "2548 [D loss: 0.134404, op_acc: 96.88%] [G loss: 0.885303]\n",
      "2549 [D loss: 0.072001, op_acc: 100.00%] [G loss: 1.013485]\n",
      "2550 [D loss: 0.157984, op_acc: 92.19%] [G loss: 0.898036]\n",
      "2551 [D loss: 0.128997, op_acc: 96.88%] [G loss: 1.007571]\n",
      "2552 [D loss: 0.082494, op_acc: 96.88%] [G loss: 0.949643]\n",
      "2553 [D loss: 0.114534, op_acc: 95.31%] [G loss: 0.928703]\n",
      "2554 [D loss: 0.160229, op_acc: 93.75%] [G loss: 1.082317]\n",
      "2555 [D loss: 0.142080, op_acc: 93.75%] [G loss: 0.945393]\n",
      "2556 [D loss: 0.150958, op_acc: 93.75%] [G loss: 0.954998]\n",
      "2557 [D loss: 0.138524, op_acc: 93.75%] [G loss: 1.035460]\n",
      "2558 [D loss: 0.102606, op_acc: 96.88%] [G loss: 0.957152]\n",
      "2559 [D loss: 0.309503, op_acc: 84.38%] [G loss: 1.042137]\n",
      "2560 [D loss: 0.186995, op_acc: 87.50%] [G loss: 0.950570]\n",
      "2561 [D loss: 0.237949, op_acc: 85.94%] [G loss: 1.094832]\n",
      "2562 [D loss: 0.148994, op_acc: 92.19%] [G loss: 1.026940]\n",
      "2563 [D loss: 0.155788, op_acc: 95.31%] [G loss: 0.931196]\n",
      "2564 [D loss: 0.112071, op_acc: 96.88%] [G loss: 1.024060]\n",
      "2565 [D loss: 0.174912, op_acc: 93.75%] [G loss: 0.988922]\n",
      "2566 [D loss: 0.163690, op_acc: 93.75%] [G loss: 1.019003]\n",
      "2567 [D loss: 0.089422, op_acc: 98.44%] [G loss: 0.967738]\n",
      "2568 [D loss: 0.108404, op_acc: 98.44%] [G loss: 0.979187]\n",
      "2569 [D loss: 0.115949, op_acc: 93.75%] [G loss: 1.054631]\n",
      "2570 [D loss: 0.161249, op_acc: 92.19%] [G loss: 1.003775]\n",
      "2571 [D loss: 0.085236, op_acc: 95.31%] [G loss: 0.993791]\n",
      "2572 [D loss: 0.209756, op_acc: 87.50%] [G loss: 1.118297]\n",
      "2573 [D loss: 0.123322, op_acc: 93.75%] [G loss: 1.005370]\n",
      "2574 [D loss: 0.094155, op_acc: 98.44%] [G loss: 1.016145]\n",
      "2575 [D loss: 0.229857, op_acc: 87.50%] [G loss: 1.117717]\n",
      "2576 [D loss: 0.124511, op_acc: 95.31%] [G loss: 1.007328]\n",
      "2577 [D loss: 0.087085, op_acc: 96.88%] [G loss: 1.054362]\n",
      "2578 [D loss: 0.188703, op_acc: 93.75%] [G loss: 0.974443]\n",
      "2579 [D loss: 0.094262, op_acc: 96.88%] [G loss: 1.095254]\n",
      "2580 [D loss: 0.128226, op_acc: 93.75%] [G loss: 1.058706]\n",
      "2581 [D loss: 0.080210, op_acc: 95.31%] [G loss: 1.032655]\n",
      "2582 [D loss: 0.208028, op_acc: 92.19%] [G loss: 0.883650]\n",
      "2583 [D loss: 0.102279, op_acc: 95.31%] [G loss: 1.020022]\n",
      "2584 [D loss: 0.214929, op_acc: 92.19%] [G loss: 1.237260]\n",
      "2585 [D loss: 0.170862, op_acc: 89.06%] [G loss: 0.980551]\n",
      "2586 [D loss: 0.146242, op_acc: 89.06%] [G loss: 1.195923]\n",
      "2587 [D loss: 0.178124, op_acc: 92.19%] [G loss: 1.041295]\n",
      "2588 [D loss: 0.119138, op_acc: 95.31%] [G loss: 0.933456]\n",
      "2589 [D loss: 0.103224, op_acc: 93.75%] [G loss: 0.997333]\n",
      "2590 [D loss: 0.098590, op_acc: 95.31%] [G loss: 1.111304]\n",
      "2591 [D loss: 0.095786, op_acc: 95.31%] [G loss: 0.975429]\n",
      "2592 [D loss: 0.130547, op_acc: 93.75%] [G loss: 1.257278]\n",
      "2593 [D loss: 0.139868, op_acc: 93.75%] [G loss: 0.903197]\n",
      "2594 [D loss: 0.187182, op_acc: 95.31%] [G loss: 1.041293]\n",
      "2595 [D loss: 0.194765, op_acc: 90.62%] [G loss: 1.198956]\n",
      "2596 [D loss: 0.120035, op_acc: 96.88%] [G loss: 0.762861]\n",
      "2597 [D loss: 0.138891, op_acc: 92.19%] [G loss: 1.052346]\n",
      "2598 [D loss: 0.163487, op_acc: 93.75%] [G loss: 0.985533]\n",
      "2599 [D loss: 0.113246, op_acc: 95.31%] [G loss: 0.942943]\n",
      "2600 [D loss: 0.092997, op_acc: 98.44%] [G loss: 1.001719]\n",
      "2601 [D loss: 0.146091, op_acc: 95.31%] [G loss: 1.248082]\n",
      "2602 [D loss: 0.160550, op_acc: 95.31%] [G loss: 0.853056]\n",
      "2603 [D loss: 0.068565, op_acc: 100.00%] [G loss: 1.046968]\n",
      "2604 [D loss: 0.271019, op_acc: 85.94%] [G loss: 2.027596]\n",
      "2605 [D loss: 0.341167, op_acc: 85.94%] [G loss: 4.514390]\n",
      "2606 [D loss: 2.530573, op_acc: 43.75%] [G loss: 3.592183]\n",
      "2607 [D loss: 3.589520, op_acc: 45.31%] [G loss: 0.187460]\n",
      "2608 [D loss: 1.246208, op_acc: 43.75%] [G loss: 0.383783]\n",
      "2609 [D loss: 0.868603, op_acc: 48.44%] [G loss: 0.367411]\n",
      "2610 [D loss: 0.692196, op_acc: 48.44%] [G loss: 0.297731]\n",
      "2611 [D loss: 0.551660, op_acc: 68.75%] [G loss: 0.357105]\n",
      "2612 [D loss: 0.507851, op_acc: 68.75%] [G loss: 0.315873]\n",
      "2613 [D loss: 0.581383, op_acc: 51.56%] [G loss: 0.335645]\n",
      "2614 [D loss: 0.460236, op_acc: 75.00%] [G loss: 0.297370]\n",
      "2615 [D loss: 0.473835, op_acc: 81.25%] [G loss: 0.318779]\n",
      "2616 [D loss: 0.550555, op_acc: 57.81%] [G loss: 0.332569]\n",
      "2617 [D loss: 0.513812, op_acc: 65.62%] [G loss: 0.302239]\n",
      "2618 [D loss: 0.456718, op_acc: 73.44%] [G loss: 0.289961]\n",
      "2619 [D loss: 0.337471, op_acc: 84.38%] [G loss: 0.327755]\n",
      "2620 [D loss: 0.381911, op_acc: 81.25%] [G loss: 0.357721]\n",
      "2621 [D loss: 0.430578, op_acc: 78.12%] [G loss: 0.358125]\n",
      "2622 [D loss: 0.264715, op_acc: 93.75%] [G loss: 0.359430]\n",
      "2623 [D loss: 0.281487, op_acc: 90.62%] [G loss: 0.390781]\n",
      "2624 [D loss: 0.328342, op_acc: 81.25%] [G loss: 0.360994]\n",
      "2625 [D loss: 0.268368, op_acc: 92.19%] [G loss: 0.371508]\n",
      "2626 [D loss: 0.317714, op_acc: 87.50%] [G loss: 0.376342]\n",
      "2627 [D loss: 0.384987, op_acc: 84.38%] [G loss: 0.346744]\n",
      "2628 [D loss: 0.274636, op_acc: 85.94%] [G loss: 0.375775]\n",
      "2629 [D loss: 0.250822, op_acc: 92.19%] [G loss: 0.398008]\n",
      "2630 [D loss: 0.331397, op_acc: 87.50%] [G loss: 0.372151]\n",
      "2631 [D loss: 0.248279, op_acc: 92.19%] [G loss: 0.401739]\n",
      "2632 [D loss: 0.294966, op_acc: 82.81%] [G loss: 0.436046]\n",
      "2633 [D loss: 0.221830, op_acc: 92.19%] [G loss: 0.413193]\n",
      "2634 [D loss: 0.228492, op_acc: 90.62%] [G loss: 0.442644]\n",
      "2635 [D loss: 0.282647, op_acc: 85.94%] [G loss: 0.408012]\n",
      "2636 [D loss: 0.200707, op_acc: 93.75%] [G loss: 0.420041]\n",
      "2637 [D loss: 0.231887, op_acc: 87.50%] [G loss: 0.495289]\n",
      "2638 [D loss: 0.291812, op_acc: 82.81%] [G loss: 0.488066]\n",
      "2639 [D loss: 0.237084, op_acc: 84.38%] [G loss: 0.512486]\n",
      "2640 [D loss: 0.272184, op_acc: 87.50%] [G loss: 0.515055]\n",
      "2641 [D loss: 0.160355, op_acc: 95.31%] [G loss: 0.555755]\n",
      "2642 [D loss: 0.203678, op_acc: 90.62%] [G loss: 0.560004]\n",
      "2643 [D loss: 0.281629, op_acc: 81.25%] [G loss: 0.531417]\n",
      "2644 [D loss: 0.317580, op_acc: 79.69%] [G loss: 0.530987]\n",
      "2645 [D loss: 0.189303, op_acc: 90.62%] [G loss: 0.595417]\n",
      "2646 [D loss: 0.284833, op_acc: 82.81%] [G loss: 0.571739]\n",
      "2647 [D loss: 0.153295, op_acc: 93.75%] [G loss: 0.670547]\n",
      "2648 [D loss: 0.158606, op_acc: 90.62%] [G loss: 0.602572]\n",
      "2649 [D loss: 0.121879, op_acc: 98.44%] [G loss: 0.677009]\n",
      "2650 [D loss: 0.155410, op_acc: 90.62%] [G loss: 0.631117]\n",
      "2651 [D loss: 0.166911, op_acc: 90.62%] [G loss: 0.697681]\n",
      "2652 [D loss: 0.146263, op_acc: 95.31%] [G loss: 0.739189]\n",
      "2653 [D loss: 0.257179, op_acc: 90.62%] [G loss: 0.602482]\n",
      "2654 [D loss: 0.304362, op_acc: 85.94%] [G loss: 0.636218]\n",
      "2655 [D loss: 0.111559, op_acc: 96.88%] [G loss: 0.699220]\n",
      "2656 [D loss: 0.235245, op_acc: 87.50%] [G loss: 0.639847]\n",
      "2657 [D loss: 0.333078, op_acc: 79.69%] [G loss: 0.758780]\n",
      "2658 [D loss: 0.147705, op_acc: 100.00%] [G loss: 0.671387]\n",
      "2659 [D loss: 0.188799, op_acc: 93.75%] [G loss: 0.636948]\n",
      "2660 [D loss: 0.165753, op_acc: 92.19%] [G loss: 0.748866]\n",
      "2661 [D loss: 0.149168, op_acc: 96.88%] [G loss: 0.695136]\n",
      "2662 [D loss: 0.228589, op_acc: 85.94%] [G loss: 0.722364]\n",
      "2663 [D loss: 0.162122, op_acc: 92.19%] [G loss: 0.734171]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2664 [D loss: 0.190597, op_acc: 92.19%] [G loss: 0.695614]\n",
      "2665 [D loss: 0.108180, op_acc: 96.88%] [G loss: 0.800634]\n",
      "2666 [D loss: 0.179498, op_acc: 89.06%] [G loss: 0.663267]\n",
      "2667 [D loss: 0.164749, op_acc: 93.75%] [G loss: 0.767382]\n",
      "2668 [D loss: 0.125306, op_acc: 96.88%] [G loss: 0.816368]\n",
      "2669 [D loss: 0.175655, op_acc: 95.31%] [G loss: 0.663517]\n",
      "2670 [D loss: 0.285546, op_acc: 82.81%] [G loss: 0.688886]\n",
      "2671 [D loss: 0.148442, op_acc: 96.88%] [G loss: 0.820897]\n",
      "2672 [D loss: 0.171141, op_acc: 89.06%] [G loss: 0.785578]\n",
      "2673 [D loss: 0.214204, op_acc: 92.19%] [G loss: 0.750062]\n",
      "2674 [D loss: 0.159604, op_acc: 90.62%] [G loss: 0.862670]\n",
      "2675 [D loss: 0.198811, op_acc: 90.62%] [G loss: 0.774220]\n",
      "2676 [D loss: 0.239687, op_acc: 89.06%] [G loss: 0.847229]\n",
      "2677 [D loss: 0.114008, op_acc: 96.88%] [G loss: 0.889655]\n",
      "2678 [D loss: 0.147908, op_acc: 95.31%] [G loss: 0.721325]\n",
      "2679 [D loss: 0.270236, op_acc: 84.38%] [G loss: 0.650034]\n",
      "2680 [D loss: 0.063600, op_acc: 100.00%] [G loss: 0.810857]\n",
      "2681 [D loss: 0.207690, op_acc: 89.06%] [G loss: 0.777467]\n",
      "2682 [D loss: 0.152600, op_acc: 93.75%] [G loss: 0.851562]\n",
      "2683 [D loss: 0.152715, op_acc: 92.19%] [G loss: 0.709970]\n",
      "2684 [D loss: 0.150887, op_acc: 92.19%] [G loss: 0.908020]\n",
      "2685 [D loss: 0.118016, op_acc: 95.31%] [G loss: 0.857698]\n",
      "2686 [D loss: 0.163541, op_acc: 93.75%] [G loss: 0.763984]\n",
      "2687 [D loss: 0.123716, op_acc: 96.88%] [G loss: 0.775121]\n",
      "2688 [D loss: 0.123313, op_acc: 92.19%] [G loss: 0.860096]\n",
      "2689 [D loss: 0.162213, op_acc: 96.88%] [G loss: 0.817975]\n",
      "2690 [D loss: 0.148554, op_acc: 92.19%] [G loss: 0.839188]\n",
      "2691 [D loss: 0.084612, op_acc: 96.88%] [G loss: 0.908997]\n",
      "2692 [D loss: 0.197970, op_acc: 89.06%] [G loss: 0.792810]\n",
      "2693 [D loss: 0.126294, op_acc: 92.19%] [G loss: 0.899932]\n",
      "2694 [D loss: 0.095215, op_acc: 98.44%] [G loss: 0.840253]\n",
      "2695 [D loss: 0.196498, op_acc: 90.62%] [G loss: 1.023544]\n",
      "2696 [D loss: 0.204613, op_acc: 89.06%] [G loss: 0.784730]\n",
      "2697 [D loss: 0.150734, op_acc: 93.75%] [G loss: 0.882232]\n",
      "2698 [D loss: 0.102305, op_acc: 96.88%] [G loss: 0.914374]\n",
      "2699 [D loss: 0.233090, op_acc: 87.50%] [G loss: 0.826411]\n",
      "2700 [D loss: 0.138049, op_acc: 93.75%] [G loss: 1.011401]\n",
      "2701 [D loss: 0.211112, op_acc: 89.06%] [G loss: 0.783414]\n",
      "2702 [D loss: 0.187683, op_acc: 90.62%] [G loss: 0.909122]\n",
      "2703 [D loss: 0.190393, op_acc: 93.75%] [G loss: 0.860903]\n",
      "2704 [D loss: 0.146614, op_acc: 90.62%] [G loss: 0.775724]\n",
      "2705 [D loss: 0.217271, op_acc: 89.06%] [G loss: 0.837739]\n",
      "2706 [D loss: 0.175640, op_acc: 90.62%] [G loss: 0.847788]\n",
      "2707 [D loss: 0.101182, op_acc: 96.88%] [G loss: 0.928522]\n",
      "2708 [D loss: 0.419239, op_acc: 76.56%] [G loss: 0.886591]\n",
      "2709 [D loss: 0.112963, op_acc: 96.88%] [G loss: 0.844683]\n",
      "2710 [D loss: 0.074295, op_acc: 100.00%] [G loss: 0.924873]\n",
      "2711 [D loss: 0.216323, op_acc: 89.06%] [G loss: 0.775073]\n",
      "2712 [D loss: 0.171154, op_acc: 93.75%] [G loss: 0.814136]\n",
      "2713 [D loss: 0.288029, op_acc: 87.50%] [G loss: 0.915789]\n",
      "2714 [D loss: 0.106231, op_acc: 96.88%] [G loss: 1.003704]\n",
      "2715 [D loss: 0.145575, op_acc: 95.31%] [G loss: 0.774673]\n",
      "2716 [D loss: 0.105455, op_acc: 96.88%] [G loss: 0.910371]\n",
      "2717 [D loss: 0.202372, op_acc: 89.06%] [G loss: 0.781452]\n",
      "2718 [D loss: 0.136272, op_acc: 96.88%] [G loss: 1.021363]\n",
      "2719 [D loss: 0.131376, op_acc: 95.31%] [G loss: 0.891850]\n",
      "2720 [D loss: 0.116945, op_acc: 98.44%] [G loss: 0.770816]\n",
      "2721 [D loss: 0.182739, op_acc: 90.62%] [G loss: 0.891687]\n",
      "2722 [D loss: 0.084681, op_acc: 100.00%] [G loss: 0.882350]\n",
      "2723 [D loss: 0.228144, op_acc: 90.62%] [G loss: 0.876853]\n",
      "2724 [D loss: 0.154191, op_acc: 93.75%] [G loss: 0.804160]\n",
      "2725 [D loss: 0.099158, op_acc: 95.31%] [G loss: 0.905845]\n",
      "2726 [D loss: 0.116632, op_acc: 95.31%] [G loss: 0.876632]\n",
      "2727 [D loss: 0.196568, op_acc: 89.06%] [G loss: 0.872797]\n",
      "2728 [D loss: 0.098476, op_acc: 98.44%] [G loss: 0.985490]\n",
      "2729 [D loss: 0.177057, op_acc: 95.31%] [G loss: 0.815300]\n",
      "2730 [D loss: 0.095341, op_acc: 96.88%] [G loss: 0.888526]\n",
      "2731 [D loss: 0.115180, op_acc: 98.44%] [G loss: 0.845056]\n",
      "2732 [D loss: 0.149868, op_acc: 95.31%] [G loss: 0.928512]\n",
      "2733 [D loss: 0.240725, op_acc: 84.38%] [G loss: 1.093651]\n",
      "2734 [D loss: 0.324645, op_acc: 82.81%] [G loss: 0.711181]\n",
      "2735 [D loss: 0.112159, op_acc: 95.31%] [G loss: 1.005941]\n",
      "2736 [D loss: 0.169508, op_acc: 92.19%] [G loss: 0.918534]\n",
      "2737 [D loss: 0.158449, op_acc: 93.75%] [G loss: 0.908433]\n",
      "2738 [D loss: 0.136312, op_acc: 96.88%] [G loss: 0.809957]\n",
      "2739 [D loss: 0.219932, op_acc: 87.50%] [G loss: 0.915860]\n",
      "2740 [D loss: 0.151792, op_acc: 92.19%] [G loss: 0.850691]\n",
      "2741 [D loss: 0.199496, op_acc: 89.06%] [G loss: 0.826787]\n",
      "2742 [D loss: 0.173490, op_acc: 89.06%] [G loss: 0.836483]\n",
      "2743 [D loss: 0.151691, op_acc: 93.75%] [G loss: 1.114253]\n",
      "2744 [D loss: 0.170523, op_acc: 90.62%] [G loss: 0.796765]\n",
      "2745 [D loss: 0.141735, op_acc: 98.44%] [G loss: 0.800561]\n",
      "2746 [D loss: 0.105829, op_acc: 95.31%] [G loss: 0.974567]\n",
      "2747 [D loss: 0.109789, op_acc: 96.88%] [G loss: 0.799399]\n",
      "2748 [D loss: 0.144446, op_acc: 95.31%] [G loss: 0.919567]\n",
      "2749 [D loss: 0.114243, op_acc: 95.31%] [G loss: 0.861921]\n",
      "2750 [D loss: 0.131051, op_acc: 96.88%] [G loss: 0.910090]\n",
      "2751 [D loss: 0.126512, op_acc: 98.44%] [G loss: 0.935172]\n",
      "2752 [D loss: 0.180745, op_acc: 92.19%] [G loss: 0.961378]\n",
      "2753 [D loss: 0.154735, op_acc: 93.75%] [G loss: 0.960727]\n",
      "2754 [D loss: 0.189633, op_acc: 93.75%] [G loss: 0.878920]\n",
      "2755 [D loss: 0.144722, op_acc: 92.19%] [G loss: 0.917216]\n",
      "2756 [D loss: 0.151791, op_acc: 92.19%] [G loss: 0.916286]\n",
      "2757 [D loss: 0.147159, op_acc: 92.19%] [G loss: 0.973308]\n",
      "2758 [D loss: 0.249910, op_acc: 87.50%] [G loss: 0.791759]\n",
      "2759 [D loss: 0.199073, op_acc: 84.38%] [G loss: 0.976844]\n",
      "2760 [D loss: 0.088995, op_acc: 98.44%] [G loss: 0.971046]\n",
      "2761 [D loss: 0.110932, op_acc: 96.88%] [G loss: 0.871770]\n",
      "2762 [D loss: 0.273662, op_acc: 81.25%] [G loss: 0.953014]\n",
      "2763 [D loss: 0.102790, op_acc: 98.44%] [G loss: 0.979737]\n",
      "2764 [D loss: 0.161206, op_acc: 90.62%] [G loss: 0.888446]\n",
      "2765 [D loss: 0.095236, op_acc: 98.44%] [G loss: 0.941296]\n",
      "2766 [D loss: 0.145399, op_acc: 95.31%] [G loss: 0.910390]\n",
      "2767 [D loss: 0.153500, op_acc: 92.19%] [G loss: 0.928516]\n",
      "2768 [D loss: 0.125815, op_acc: 96.88%] [G loss: 0.879226]\n",
      "2769 [D loss: 0.136463, op_acc: 92.19%] [G loss: 0.975192]\n",
      "2770 [D loss: 0.141006, op_acc: 93.75%] [G loss: 0.857998]\n",
      "2771 [D loss: 0.118356, op_acc: 95.31%] [G loss: 0.901593]\n",
      "2772 [D loss: 0.183263, op_acc: 90.62%] [G loss: 1.073929]\n",
      "2773 [D loss: 0.122845, op_acc: 95.31%] [G loss: 0.932674]\n",
      "2774 [D loss: 0.221145, op_acc: 85.94%] [G loss: 0.917381]\n",
      "2775 [D loss: 0.134365, op_acc: 90.62%] [G loss: 0.967508]\n",
      "2776 [D loss: 0.105635, op_acc: 95.31%] [G loss: 0.912984]\n",
      "2777 [D loss: 0.191774, op_acc: 87.50%] [G loss: 0.904357]\n",
      "2778 [D loss: 0.097441, op_acc: 96.88%] [G loss: 1.088208]\n",
      "2779 [D loss: 0.135698, op_acc: 93.75%] [G loss: 0.903684]\n",
      "2780 [D loss: 0.107718, op_acc: 93.75%] [G loss: 0.936435]\n",
      "2781 [D loss: 0.105330, op_acc: 98.44%] [G loss: 0.895424]\n",
      "2782 [D loss: 0.144089, op_acc: 93.75%] [G loss: 1.007025]\n",
      "2783 [D loss: 0.108730, op_acc: 96.88%] [G loss: 0.999248]\n",
      "2784 [D loss: 0.150592, op_acc: 92.19%] [G loss: 0.910053]\n",
      "2785 [D loss: 0.143891, op_acc: 90.62%] [G loss: 0.988842]\n",
      "2786 [D loss: 0.162896, op_acc: 98.44%] [G loss: 0.897702]\n",
      "2787 [D loss: 0.176649, op_acc: 93.75%] [G loss: 0.776867]\n",
      "2788 [D loss: 0.113897, op_acc: 96.88%] [G loss: 1.026449]\n",
      "2789 [D loss: 0.089193, op_acc: 98.44%] [G loss: 0.914235]\n",
      "2790 [D loss: 0.163580, op_acc: 92.19%] [G loss: 0.998460]\n",
      "2791 [D loss: 0.143201, op_acc: 96.88%] [G loss: 0.977654]\n",
      "2792 [D loss: 0.081621, op_acc: 96.88%] [G loss: 0.909171]\n",
      "2793 [D loss: 0.075639, op_acc: 100.00%] [G loss: 0.917751]\n",
      "2794 [D loss: 0.108180, op_acc: 95.31%] [G loss: 1.038969]\n",
      "2795 [D loss: 0.184482, op_acc: 90.62%] [G loss: 1.144097]\n",
      "2796 [D loss: 0.156655, op_acc: 89.06%] [G loss: 1.030005]\n",
      "2797 [D loss: 0.126486, op_acc: 95.31%] [G loss: 0.838141]\n",
      "2798 [D loss: 0.178783, op_acc: 90.62%] [G loss: 1.009829]\n",
      "2799 [D loss: 0.117678, op_acc: 96.88%] [G loss: 1.003811]\n",
      "2800 [D loss: 0.135992, op_acc: 96.88%] [G loss: 0.824943]\n",
      "2801 [D loss: 0.102326, op_acc: 96.88%] [G loss: 1.045902]\n",
      "2802 [D loss: 0.190370, op_acc: 92.19%] [G loss: 1.054209]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2803 [D loss: 0.119762, op_acc: 96.88%] [G loss: 0.851676]\n",
      "2804 [D loss: 0.112109, op_acc: 96.88%] [G loss: 0.973145]\n",
      "2805 [D loss: 0.265670, op_acc: 92.19%] [G loss: 1.041838]\n",
      "2806 [D loss: 0.191156, op_acc: 93.75%] [G loss: 0.788104]\n",
      "2807 [D loss: 0.095534, op_acc: 98.44%] [G loss: 1.048316]\n",
      "2808 [D loss: 0.170259, op_acc: 90.62%] [G loss: 0.920654]\n",
      "2809 [D loss: 0.162779, op_acc: 95.31%] [G loss: 1.000414]\n",
      "2810 [D loss: 0.130106, op_acc: 96.88%] [G loss: 0.829729]\n",
      "2811 [D loss: 0.228068, op_acc: 84.38%] [G loss: 1.129400]\n",
      "2812 [D loss: 0.276186, op_acc: 82.81%] [G loss: 0.913815]\n",
      "2813 [D loss: 0.189661, op_acc: 90.62%] [G loss: 0.888274]\n",
      "2814 [D loss: 0.119625, op_acc: 95.31%] [G loss: 0.980866]\n",
      "2815 [D loss: 0.107508, op_acc: 98.44%] [G loss: 0.967553]\n",
      "2816 [D loss: 0.105204, op_acc: 96.88%] [G loss: 1.016960]\n",
      "2817 [D loss: 0.126896, op_acc: 98.44%] [G loss: 0.890526]\n",
      "2818 [D loss: 0.099676, op_acc: 95.31%] [G loss: 0.957825]\n",
      "2819 [D loss: 0.095008, op_acc: 95.31%] [G loss: 0.842436]\n",
      "2820 [D loss: 0.084494, op_acc: 96.88%] [G loss: 0.958696]\n",
      "2821 [D loss: 0.166998, op_acc: 92.19%] [G loss: 0.883154]\n",
      "2822 [D loss: 0.072512, op_acc: 100.00%] [G loss: 0.969259]\n",
      "2823 [D loss: 0.287875, op_acc: 90.62%] [G loss: 0.918829]\n",
      "2824 [D loss: 0.109511, op_acc: 93.75%] [G loss: 1.116280]\n",
      "2825 [D loss: 0.133249, op_acc: 96.88%] [G loss: 0.890450]\n",
      "2826 [D loss: 0.160737, op_acc: 87.50%] [G loss: 0.885683]\n",
      "2827 [D loss: 0.111117, op_acc: 92.19%] [G loss: 1.135717]\n",
      "2828 [D loss: 0.159355, op_acc: 93.75%] [G loss: 0.867990]\n",
      "2829 [D loss: 0.200001, op_acc: 89.06%] [G loss: 1.070748]\n",
      "2830 [D loss: 0.105399, op_acc: 95.31%] [G loss: 0.974501]\n",
      "2831 [D loss: 0.154066, op_acc: 93.75%] [G loss: 0.872482]\n",
      "2832 [D loss: 0.097844, op_acc: 98.44%] [G loss: 0.966517]\n",
      "2833 [D loss: 0.099245, op_acc: 95.31%] [G loss: 0.975099]\n",
      "2834 [D loss: 0.153961, op_acc: 93.75%] [G loss: 1.023704]\n",
      "2835 [D loss: 0.104583, op_acc: 98.44%] [G loss: 0.881784]\n",
      "2836 [D loss: 0.099893, op_acc: 98.44%] [G loss: 0.967984]\n",
      "2837 [D loss: 0.135759, op_acc: 98.44%] [G loss: 1.070676]\n",
      "2838 [D loss: 0.094186, op_acc: 96.88%] [G loss: 0.948196]\n",
      "2839 [D loss: 0.078692, op_acc: 100.00%] [G loss: 0.867400]\n",
      "2840 [D loss: 0.175520, op_acc: 95.31%] [G loss: 0.954332]\n",
      "2841 [D loss: 0.116881, op_acc: 92.19%] [G loss: 1.054769]\n",
      "2842 [D loss: 0.106273, op_acc: 96.88%] [G loss: 1.026512]\n",
      "2843 [D loss: 0.188578, op_acc: 90.62%] [G loss: 0.887919]\n",
      "2844 [D loss: 0.079789, op_acc: 98.44%] [G loss: 1.015071]\n",
      "2845 [D loss: 0.105961, op_acc: 98.44%] [G loss: 0.960102]\n",
      "2846 [D loss: 0.075029, op_acc: 100.00%] [G loss: 0.977115]\n",
      "2847 [D loss: 0.144785, op_acc: 92.19%] [G loss: 1.038963]\n",
      "2848 [D loss: 0.100453, op_acc: 98.44%] [G loss: 0.953646]\n",
      "2849 [D loss: 0.111266, op_acc: 95.31%] [G loss: 0.948779]\n",
      "2850 [D loss: 0.160411, op_acc: 93.75%] [G loss: 1.111163]\n",
      "2851 [D loss: 0.108503, op_acc: 98.44%] [G loss: 0.896339]\n",
      "2852 [D loss: 0.120143, op_acc: 96.88%] [G loss: 1.018958]\n",
      "2853 [D loss: 0.102742, op_acc: 98.44%] [G loss: 0.948665]\n"
     ]
    }
   ],
   "source": [
    "epochs=20000\n",
    "epochs=4000\n",
    "train(G, D, combined, \n",
    "      img_rows, mask_height,\n",
    "      num_classes,\n",
    "      epochs=epochs, batch_size=32, sample_interval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
