{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DualGAN\n",
    "\n",
    "ref. YI, Zili et al.  \n",
    "     Dualgan: Unsupervised dual learning for image-to-image translation.  \n",
    "     In: Proceedings of the IEEE international conference on computer vision. 2017. p. 2849-2857.\n",
    "     \n",
    "![Dual GAN architecture](arch.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(img_dim):\n",
    "\n",
    "    X = Input(shape=(img_dim,))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=img_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1024))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(img_dim, activation='tanh'))\n",
    "\n",
    "    X_translated = model(X)\n",
    "\n",
    "    return Model(X, X_translated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(img_dim):\n",
    "\n",
    "    img = Input(shape=(img_dim,))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_dim=img_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    validity = model(img)\n",
    "\n",
    "    return Model(img, validity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_generator_input(X, batch_size):\n",
    "    # Sample random batch of images from X\n",
    "    idx = np.random.randint(0, X.shape[0], batch_size)\n",
    "    return X[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true * y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_imgs(G_AB, G_BA, epoch, \n",
    "              X_A, X_B, \n",
    "              img_rows, img_cols):\n",
    "    r, c = 4, 4\n",
    "\n",
    "    # Sample generator inputs\n",
    "    imgs_A = sample_generator_input(X_A, c)\n",
    "    imgs_B = sample_generator_input(X_B, c)\n",
    "\n",
    "    # Images translated to their opposite domain\n",
    "    fake_B = G_AB.predict(imgs_A)\n",
    "    fake_A = G_BA.predict(imgs_B)\n",
    "\n",
    "    gen_imgs = np.concatenate([imgs_A, fake_B, imgs_B, fake_A])\n",
    "    gen_imgs = gen_imgs.reshape((r, c, img_rows, img_cols, 1))\n",
    "\n",
    "    # Rescale images 0 - 1\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i,j].imshow(gen_imgs[i, j, :,:,0], cmap='gray')\n",
    "            axs[i,j].axis('off')\n",
    "            cnt += 1\n",
    "    fig.savefig(\"images/mnist_%d.png\" % epoch)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(D_A, D_B, G_AB, G_BA, combined,\n",
    "          img_dim, img_rows, img_cols,\n",
    "          epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "    # Load the dataset\n",
    "    (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "    # Rescale -1 to 1\n",
    "    X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "\n",
    "    # Domain A and B (rotated)\n",
    "    X_A = X_train[:int(X_train.shape[0]/2)]\n",
    "    X_B = scipy.ndimage.interpolation.rotate(X_train[int(X_train.shape[0]/2):], 90, axes=(1, 2))\n",
    "\n",
    "    X_A = X_A.reshape(X_A.shape[0], img_dim)\n",
    "    X_B = X_B.reshape(X_B.shape[0], img_dim)\n",
    "\n",
    "    clip_value = 0.01\n",
    "    n_critic = 4\n",
    "\n",
    "    # Adversarial ground truths\n",
    "    valid = -np.ones((batch_size, 1))\n",
    "    fake = np.ones((batch_size, 1))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # Train the discriminator for n_critic iterations\n",
    "        for _ in range(n_critic):\n",
    "\n",
    "            # ----------------------\n",
    "            #  Train Discriminators\n",
    "            # ----------------------\n",
    "\n",
    "            # Sample generator inputs\n",
    "            imgs_A = sample_generator_input(X_A, batch_size)\n",
    "            imgs_B = sample_generator_input(X_B, batch_size)\n",
    "\n",
    "            # Translate images to their opposite domain\n",
    "            fake_B = G_AB.predict(imgs_A)\n",
    "            fake_A = G_BA.predict(imgs_B)\n",
    "\n",
    "            # Train the discriminators\n",
    "            D_A_loss_real = D_A.train_on_batch(imgs_A, valid)\n",
    "            D_A_loss_fake = D_A.train_on_batch(fake_A, fake)\n",
    "\n",
    "            D_B_loss_real = D_B.train_on_batch(imgs_B, valid)\n",
    "            D_B_loss_fake = D_B.train_on_batch(fake_B, fake)\n",
    "\n",
    "            D_A_loss = 0.5 * np.add(D_A_loss_real, D_A_loss_fake)\n",
    "            D_B_loss = 0.5 * np.add(D_B_loss_real, D_B_loss_fake)\n",
    "\n",
    "            # Clip discriminator weights\n",
    "            for d in [D_A, D_B]:\n",
    "                for l in d.layers:\n",
    "                    weights = l.get_weights()\n",
    "                    weights = [np.clip(w, -clip_value, clip_value) for w in weights]\n",
    "                    l.set_weights(weights)\n",
    "\n",
    "        # ------------------\n",
    "        #  Train Generators\n",
    "        # ------------------\n",
    "\n",
    "        # Train the generators\n",
    "        g_loss = combined.train_on_batch([imgs_A, imgs_B], [valid, valid, imgs_A, imgs_B])\n",
    "\n",
    "        # Plot the progress\n",
    "        print (\"%d [D1 loss: %f] [D2 loss: %f] [G loss: %f]\" \\\n",
    "            % (epoch, D_A_loss[0], D_B_loss[0], g_loss[0]))\n",
    "\n",
    "        # If at save interval => save generated image samples\n",
    "        if epoch % sample_interval == 0:\n",
    "            save_imgs(G_AB, G_BA, epoch, \n",
    "                      X_A, X_B, \n",
    "                      img_rows, img_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('images'):\n",
    "    os.makedirs('images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 28\n",
    "img_cols = 28\n",
    "channels = 1\n",
    "img_dim = img_rows * img_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\henri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# create optimizer\n",
    "optimizer = Adam(0.0002, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and compile the discriminators\n",
    "D_A = build_discriminator(img_dim)\n",
    "D_A.compile(loss=wasserstein_loss,\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "D_B = build_discriminator(img_dim)\n",
    "D_B.compile(loss=wasserstein_loss,\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------\n",
    "# Construct Computational\n",
    "#   Graph of Generators\n",
    "#-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the generators\n",
    "G_AB = build_generator(img_dim)\n",
    "G_BA = build_generator(img_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the combined model we will only train the generators\n",
    "D_A.trainable = False\n",
    "D_B.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The generator takes images from their respective domains as inputs\n",
    "imgs_A = Input(shape=(img_dim,))\n",
    "imgs_B = Input(shape=(img_dim,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generators translates the images to the opposite domain\n",
    "fake_B = G_AB(imgs_A)\n",
    "fake_A = G_BA(imgs_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The discriminators determines validity of translated images\n",
    "valid_A = D_A(fake_A)\n",
    "valid_B = D_B(fake_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generators translate the images back to their original domain\n",
    "recov_A = G_BA(fake_B)\n",
    "recov_B = G_AB(fake_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The combined model  (stacked generators and discriminators)\n",
    "combined = Model(inputs=[imgs_A, imgs_B], outputs=[valid_A, valid_B, recov_A, recov_B])\n",
    "combined.compile(loss=[wasserstein_loss, wasserstein_loss, 'mae', 'mae'],\n",
    "                 optimizer=optimizer,\n",
    "                 loss_weights=[1, 1, 100, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\henri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\henri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "c:\\users\\henri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "c:\\users\\henri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D1 loss: 0.000081] [D2 loss: 0.000089] [G loss: 195.662094]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\henri\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [D1 loss: 0.000091] [D2 loss: 0.000095] [G loss: 193.996979]\n",
      "2 [D1 loss: 0.000093] [D2 loss: 0.000096] [G loss: 193.581238]\n",
      "3 [D1 loss: 0.000093] [D2 loss: 0.000095] [G loss: 193.942459]\n",
      "4 [D1 loss: 0.000090] [D2 loss: 0.000091] [G loss: 192.923416]\n",
      "5 [D1 loss: 0.000086] [D2 loss: 0.000086] [G loss: 192.663849]\n",
      "6 [D1 loss: 0.000082] [D2 loss: 0.000081] [G loss: 192.518951]\n",
      "7 [D1 loss: 0.000078] [D2 loss: 0.000076] [G loss: 193.187866]\n",
      "8 [D1 loss: 0.000074] [D2 loss: 0.000071] [G loss: 192.921753]\n",
      "9 [D1 loss: 0.000070] [D2 loss: 0.000067] [G loss: 191.755005]\n",
      "10 [D1 loss: 0.000066] [D2 loss: 0.000063] [G loss: 191.921646]\n",
      "11 [D1 loss: 0.000063] [D2 loss: 0.000060] [G loss: 191.658981]\n",
      "12 [D1 loss: 0.000060] [D2 loss: 0.000057] [G loss: 191.580139]\n",
      "13 [D1 loss: 0.000057] [D2 loss: 0.000055] [G loss: 190.972107]\n",
      "14 [D1 loss: 0.000055] [D2 loss: 0.000053] [G loss: 190.847275]\n",
      "15 [D1 loss: 0.000053] [D2 loss: 0.000051] [G loss: 189.069412]\n",
      "16 [D1 loss: 0.000051] [D2 loss: 0.000050] [G loss: 189.301651]\n",
      "17 [D1 loss: 0.000050] [D2 loss: 0.000049] [G loss: 190.000824]\n",
      "18 [D1 loss: 0.000049] [D2 loss: 0.000048] [G loss: 189.505219]\n",
      "19 [D1 loss: 0.000048] [D2 loss: 0.000048] [G loss: 188.344604]\n",
      "20 [D1 loss: 0.000048] [D2 loss: 0.000047] [G loss: 187.973816]\n",
      "21 [D1 loss: 0.000047] [D2 loss: 0.000047] [G loss: 186.500153]\n",
      "22 [D1 loss: 0.000047] [D2 loss: 0.000047] [G loss: 186.173676]\n",
      "23 [D1 loss: 0.000047] [D2 loss: 0.000046] [G loss: 185.330444]\n",
      "24 [D1 loss: 0.000046] [D2 loss: 0.000046] [G loss: 184.968933]\n",
      "25 [D1 loss: 0.000046] [D2 loss: 0.000046] [G loss: 184.333176]\n",
      "26 [D1 loss: 0.000046] [D2 loss: 0.000046] [G loss: 183.436295]\n",
      "27 [D1 loss: 0.000046] [D2 loss: 0.000046] [G loss: 182.842896]\n",
      "28 [D1 loss: 0.000046] [D2 loss: 0.000046] [G loss: 183.293457]\n",
      "29 [D1 loss: 0.000046] [D2 loss: 0.000046] [G loss: 180.824524]\n",
      "30 [D1 loss: 0.000045] [D2 loss: 0.000046] [G loss: 180.355652]\n",
      "31 [D1 loss: 0.000045] [D2 loss: 0.000045] [G loss: 178.583893]\n",
      "32 [D1 loss: 0.000045] [D2 loss: 0.000045] [G loss: 179.749146]\n",
      "33 [D1 loss: 0.000045] [D2 loss: 0.000045] [G loss: 179.257904]\n"
     ]
    }
   ],
   "source": [
    "# epochs=30000\n",
    "epochs=5000\n",
    "train(D_A, D_B, G_AB, G_BA, combined,\n",
    "      img_dim, img_rows, img_cols,\n",
    "      epochs=epochs, batch_size=32, sample_interval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
